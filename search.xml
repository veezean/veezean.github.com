<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>CodeReview IDEA插件使用教程</title>
      <link href="//post/codereviewhelperdoc.html"/>
      <url>//post/codereviewhelperdoc.html</url>
      
        <content type="html"><![CDATA[<p>稍等，正在快马加鞭的编写中~~~<br>如果急的话，先联系作者咨询</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><p><strong>我是悟道，聊技术、又不仅仅聊技术~</strong></p><p>如果觉得有用，请<strong>点赞 + 关注</strong>让我感受到您的支持。也可以关注下我的公众号【架构悟道】，获取更及时的更新。</p><p>期待与你一起探讨，一起成长为更好的自己。</p><p><img src="https://pics.codingcoder.cn/pics/202207091317876.png"></p>]]></content>
      
      
      <categories>
          
          <category> CodeReview插件帮助文档 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CodeReview插件 </tag>
            
            <tag> IDEA插件 </tag>
            
            <tag> 帮助文档 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CodeReview IDEA插件版本更新记录</title>
      <link href="//post/codereviewversions.html"/>
      <url>//post/codereviewversions.html</url>
      
        <content type="html"><![CDATA[<hr><blockquote><p>当前最新版本：  <code>V3.0</code></p><p>您可以通过 <code>IDEA Plugin Market</code> 搜索 <strong>Code Review Helper</strong> 并升级或者新安装即可。</p><p>获取源码进行二次定制，请点击访问：</p><ul><li><p><a href="https://gitee.com/veezean/IntellijIDEA-CodeReview-Plugin">Gitee仓库</a></p></li><li><p><a href="https://github.com/veezean/IntellijIDEA-CodeReview-Plugin">Github仓库</a></p></li></ul></blockquote><hr><ul><li><p><strong>2023-03-12</strong>: <code>V3.0</code><br>  重构整个插件实现，并且提供全新的配套服务端（含管理界面），此版本支持自行定制需要的评审字段</p></li><li><p>** 2022-04-14**: <code>V2.6</code><br>  解决部分已知问题</p></li><li><p><strong>2021-06-14</strong>: <code>V2.5</code><br>  代码重构</p></li><li><p><strong>2021-06-12</strong>: <code>V2.4</code><br>  网络版本支持使用gitee作为服务端，支持直接将评审意见创建为GITEE的issue。</p></li><li><p><strong>2021-05-01</strong>: <code>V2.3</code><br>  提交IDEA plugin市场，要求必须英文界面，所有更改下语言界面显示。</p></li><li><p><strong>2021-05-01</strong>: <code>V2.2</code><br>  优化界面耗时操作逻辑，在子线程中操作，避免界面卡顿。</p></li><li><p><strong>2021-05-01</strong>: <code>V2.1</code><br>  优化部分lib依赖，大幅降低插件大小。</p></li><li><p><strong>2021-04-27</strong>: <code>V2.0</code><br>  增加网络版本的能力，支持提交评审意见、支持从服务端获取评审意见；优化了使用体验，支持对评审意见进行确认答复。</p></li><li><p><strong>2021-04-24</strong>: <code>V1.3</code><br>  功能优化，小bug修复，代码优化，评审字段中新增了关联需求、处理人之类的字段</p></li><li><p><strong>2020-12-07</strong>: <code>V1.2</code><br>  功能优化，删除与清空操作增加确认窗口，优化左侧行标显示精准度</p></li><li><p><strong>2019-10-08</strong>: <code>V1.1</code><br>  功能优化，支持同时打开多个IDEA窗口的情况下，相互之间review内容独立</p></li><li><p><strong>2019-10-04</strong>: <code>V1.0</code><br>  首个版本，提供代码标记、本地窗口查看，导出Excel、导入Excel等基本功能</p></li></ul><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><p><strong>我是悟道，聊技术、又不仅仅聊技术~</strong></p><p>如果觉得有用，请<strong>点赞 + 关注</strong>让我感受到您的支持。也可以关注下我的公众号【架构悟道】，获取更及时的更新。</p><p>期待与你一起探讨，一起成长为更好的自己。</p><p><img src="https://pics.codingcoder.cn/pics/202207091317876.png"></p>]]></content>
      
      
      <categories>
          
          <category> CodeReview插件帮助文档 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CodeReview插件 </tag>
            
            <tag> IDEA插件 </tag>
            
            <tag> 帮助文档 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>CodeReview IDEA插件配套服务端使用教程</title>
      <link href="//post/codereviewserverdeploydoc.html"/>
      <url>//post/codereviewserverdeploydoc.html</url>
      
        <content type="html"><![CDATA[<p>稍等，正在快马加鞭的编写中~~~<br>如果急的话，先联系作者咨询</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><p><strong>我是悟道，聊技术、又不仅仅聊技术~</strong></p><p>如果觉得有用，请<strong>点赞 + 关注</strong>让我感受到您的支持。也可以关注下我的公众号【架构悟道】，获取更及时的更新。</p><p>期待与你一起探讨，一起成长为更好的自己。</p><p><img src="https://pics.codingcoder.cn/pics/202207091317876.png"></p>]]></content>
      
      
      <categories>
          
          <category> CodeReview插件帮助文档 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CodeReview插件 </tag>
            
            <tag> IDEA插件 </tag>
            
            <tag> 帮助文档 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>自定义CodeReview的检视字段属性详情</title>
      <link href="//post/codereviewfieldmodifyhelper.html"/>
      <url>//post/codereviewfieldmodifyhelper.html</url>
      
        <content type="html"><![CDATA[<h2 id="字段定制参数说明"><a href="#字段定制参数说明" class="headerlink" title="字段定制参数说明"></a>字段定制参数说明</h2><p>配置字段的含义描述如下：</p><table><thead><tr><th>字段</th><th>取值约束</th><th>含义说明</th></tr></thead><tbody><tr><td>columnCode</td><td>字符串，不能重复</td><td>字段在代码层面处理时的唯一编码</td></tr><tr><td>showName</td><td>字符串</td><td>此字段在界面或者表格中显示的名称</td></tr><tr><td>systemInitialization</td><td>boolean</td><td>是否为系统内置字段，为true表示系统预置字段，此类字段不可修改其columnCode值</td></tr><tr><td>sortIndex</td><td>int</td><td>排序权重，编码越大排序越后</td></tr><tr><td>supportInExcel</td><td>boolean</td><td>是否支持导出到Excel中</td></tr><tr><td>excelColumnWidth</td><td>int</td><td>导出到Excel中时此字段宽度</td></tr><tr><td>editable</td><td>boolean</td><td>字段是否支持编辑</td></tr><tr><td>required</td><td>boolean</td><td>字段是否必填</td></tr><tr><td>showInAddPage</td><td>boolean</td><td>字段是否需要在添加评审意见界面呈现</td></tr><tr><td>showInComfirmPage</td><td>boolean</td><td>字段是否需要在确认评审意见界面呈现</td></tr><tr><td>showInTable</td><td>boolean</td><td>字段是否需要在IDEA表格界面显示</td></tr><tr><td>editableInConfirmPage</td><td>boolean</td><td>在编辑界面中是否支持编辑此字段</td></tr><tr><td>inputType</td><td>String枚举值</td><td>支持三个值：<code>TEXT</code>、<code>TEXTAREA</code>、<code>COMBO_BOX</code></td></tr><tr><td>enumValues</td><td>inputType为下拉框类型时的候选值（仅单机模式的时候支持）</td><td></td></tr><tr><td>confirmProp</td><td>boolean</td><td>此字段是否为确认界面独有</td></tr></tbody></table><p>配置文件示例如下：</p><pre class="line-numbers language-json" data-language="json"><code class="language-json">&#123;  &quot;columns&quot;: [    &#123;      &quot;columnCode&quot;: &quot;identifier&quot;,      &quot;showName&quot;: &quot;ID&quot;,      &quot;systemInitialization&quot;: true,      &quot;sortIndex&quot;: 0,      &quot;supportInExcel&quot;: true,      &quot;excelColumnWidth&quot;: 15,      &quot;inputType&quot;: &quot;TEXT&quot;,      &quot;editable&quot;: false,      &quot;required&quot;: true,      &quot;showInAddPage&quot;: false,      &quot;showInComfirmPage&quot;: false,      &quot;showInTable&quot;: true,      &quot;editableInConfirmPage&quot;: false    &#125;,    &#123;      &quot;columnCode&quot;: &quot;filePath&quot;,      &quot;showName&quot;: &quot;文件路径&quot;,      &quot;systemInitialization&quot;: true,      &quot;sortIndex&quot;: 1,      &quot;supportInExcel&quot;: true,      &quot;excelColumnWidth&quot;: 50,      &quot;inputType&quot;: &quot;TEXT&quot;,      &quot;editable&quot;: false,      &quot;required&quot;: true,      &quot;showInAddPage&quot;: true,      &quot;showInComfirmPage&quot;: true,      &quot;showInTable&quot;: true,      &quot;editableInConfirmPage&quot;: false    &#125;,    &#123;      &quot;columnCode&quot;: &quot;content&quot;,      &quot;showName&quot;: &quot;代码片段&quot;,      &quot;systemInitialization&quot;: true,      &quot;sortIndex&quot;: 2,      &quot;supportInExcel&quot;: true,      &quot;excelColumnWidth&quot;: 50,      &quot;inputType&quot;: &quot;TEXTAREA&quot;,      &quot;editable&quot;: false,      &quot;required&quot;: true,      &quot;showInAddPage&quot;: true,      &quot;showInComfirmPage&quot;: true,      &quot;showInTable&quot;: true,      &quot;editableInConfirmPage&quot;: false    &#125;,    &#123;      &quot;columnCode&quot;: &quot;lineRange&quot;,      &quot;showName&quot;: &quot;代码行号&quot;,      &quot;systemInitialization&quot;: true,      &quot;sortIndex&quot;: 3,      &quot;supportInExcel&quot;: true,      &quot;excelColumnWidth&quot;: 15,      &quot;inputType&quot;: &quot;TEXT&quot;,      &quot;editable&quot;: false,      &quot;required&quot;: true,      &quot;showInAddPage&quot;: true,      &quot;showInComfirmPage&quot;: true,      &quot;showInTable&quot;: true,      &quot;editableInConfirmPage&quot;: false    &#125;,    &#123;      &quot;columnCode&quot;: &quot;comment&quot;,      &quot;showName&quot;: &quot;检视意见&quot;,      &quot;systemInitialization&quot;: true,      &quot;sortIndex&quot;: 4,      &quot;supportInExcel&quot;: true,      &quot;excelColumnWidth&quot;: 50,      &quot;inputType&quot;: &quot;TEXTAREA&quot;,      &quot;editable&quot;: true,      &quot;required&quot;: true,      &quot;showInAddPage&quot;: true,      &quot;showInComfirmPage&quot;: true,      &quot;showInTable&quot;: true,      &quot;editableInConfirmPage&quot;: false    &#125;,    &#123;      &quot;columnCode&quot;: &quot;type&quot;,      &quot;showName&quot;: &quot;意见类型&quot;,      &quot;systemInitialization&quot;: false,      &quot;sortIndex&quot;: 5,      &quot;supportInExcel&quot;: true,      &quot;excelColumnWidth&quot;: 15,      &quot;inputType&quot;: &quot;COMBO_BOX&quot;,      &quot;enumValues&quot;: [        &quot;问题&quot;,        &quot;建议&quot;,        &quot;疑问&quot;      ],      &quot;editable&quot;: true,      &quot;required&quot;: false,      &quot;showInAddPage&quot;: true,      &quot;showInComfirmPage&quot;: true,      &quot;showInTable&quot;: true,      &quot;editableInConfirmPage&quot;: false    &#125;,    &#123;      &quot;columnCode&quot;: &quot;level&quot;,      &quot;showName&quot;: &quot;严重级别&quot;,      &quot;systemInitialization&quot;: false,      &quot;sortIndex&quot;: 6,      &quot;supportInExcel&quot;: true,      &quot;excelColumnWidth&quot;: 15,      &quot;inputType&quot;: &quot;COMBO_BOX&quot;,      &quot;enumValues&quot;: [        &quot;提示&quot;,        &quot;一般&quot;,        &quot;严重&quot;      ],      &quot;editable&quot;: true,      &quot;required&quot;: false,      &quot;showInAddPage&quot;: true,      &quot;showInComfirmPage&quot;: true,      &quot;showInTable&quot;: true,      &quot;editableInConfirmPage&quot;: false    &#125;,    &#123;      &quot;columnCode&quot;: &quot;belongingTo&quot;,      &quot;showName&quot;: &quot;问题归类&quot;,      &quot;systemInitialization&quot;: false,      &quot;sortIndex&quot;: 7,      &quot;supportInExcel&quot;: true,      &quot;excelColumnWidth&quot;: 20,      &quot;inputType&quot;: &quot;COMBO_BOX&quot;,      &quot;enumValues&quot;: [        &quot;编码基础类&quot;,        &quot;业务功能类&quot;,        &quot;安全可靠类&quot;,        &quot;其它&quot;      ],      &quot;editable&quot;: true,      &quot;required&quot;: false,      &quot;showInAddPage&quot;: true,      &quot;showInComfirmPage&quot;: true,      &quot;showInTable&quot;: true,      &quot;editableInConfirmPage&quot;: false    &#125;,    &#123;      &quot;columnCode&quot;: &quot;reviewDate&quot;,      &quot;showName&quot;: &quot;检视时间&quot;,      &quot;systemInitialization&quot;: true,      &quot;sortIndex&quot;: 8,      &quot;supportInExcel&quot;: true,      &quot;excelColumnWidth&quot;: 20,      &quot;inputType&quot;: &quot;TEXT&quot;,      &quot;editable&quot;: false,      &quot;required&quot;: true,      &quot;showInAddPage&quot;: false,      &quot;showInComfirmPage&quot;: false,      &quot;showInTable&quot;: false,      &quot;editableInConfirmPage&quot;: false    &#125;,    &#123;      &quot;columnCode&quot;: &quot;reviewer&quot;,      &quot;showName&quot;: &quot;检视人员&quot;,      &quot;systemInitialization&quot;: false,      &quot;sortIndex&quot;: 9,      &quot;supportInExcel&quot;: true,      &quot;excelColumnWidth&quot;: 20,      &quot;inputType&quot;: &quot;TEXT&quot;,      &quot;editable&quot;: true,      &quot;required&quot;: true,      &quot;showInAddPage&quot;: true,      &quot;showInComfirmPage&quot;: true,      &quot;showInTable&quot;: true,      &quot;editableInConfirmPage&quot;: false    &#125;,    &#123;      &quot;columnCode&quot;: &quot;confirmResult&quot;,      &quot;showName&quot;: &quot;确认结果&quot;,      &quot;systemInitialization&quot;: false,      &quot;sortIndex&quot;: 10,      &quot;supportInExcel&quot;: true,      &quot;excelColumnWidth&quot;: 20,      &quot;inputType&quot;: &quot;COMBO_BOX&quot;,      &quot;enumValues&quot;: [        &quot;未确认&quot;,        &quot;已修改&quot;,        &quot;待修改&quot;,        &quot;拒绝&quot;      ],      &quot;editable&quot;: true,      &quot;required&quot;: false,      &quot;showInAddPage&quot;: false,      &quot;showInComfirmPage&quot;: true,      &quot;showInTable&quot;: true,      &quot;editableInConfirmPage&quot;: true,      &quot;confirmProp&quot;: true    &#125;,    &#123;      &quot;columnCode&quot;: &quot;confirmNotes&quot;,      &quot;showName&quot;: &quot;确认说明&quot;,      &quot;systemInitialization&quot;: false,      &quot;sortIndex&quot;: 11,      &quot;supportInExcel&quot;: true,      &quot;excelColumnWidth&quot;: 50,      &quot;inputType&quot;: &quot;TEXTAREA&quot;,      &quot;editable&quot;: true,      &quot;required&quot;: false,      &quot;showInAddPage&quot;: false,      &quot;showInComfirmPage&quot;: true,      &quot;showInTable&quot;: true,      &quot;editableInConfirmPage&quot;: true,      &quot;confirmProp&quot;: true    &#125;,    &#123;      &quot;columnCode&quot;: &quot;projectVersion&quot;,      &quot;showName&quot;: &quot;项目版本&quot;,      &quot;systemInitialization&quot;: false,      &quot;sortIndex&quot;: 12,      &quot;supportInExcel&quot;: true,      &quot;excelColumnWidth&quot;: 30,      &quot;inputType&quot;: &quot;TEXT&quot;,      &quot;editable&quot;: true,      &quot;required&quot;: false,      &quot;showInAddPage&quot;: true,      &quot;showInComfirmPage&quot;: true,      &quot;showInTable&quot;: true,      &quot;editableInConfirmPage&quot;: true    &#125;,    &#123;      &quot;columnCode&quot;: &quot;blongingIssue&quot;,      &quot;showName&quot;: &quot;问题归属&quot;,      &quot;systemInitialization&quot;: false,      &quot;sortIndex&quot;: 13,      &quot;supportInExcel&quot;: true,      &quot;excelColumnWidth&quot;: 30,      &quot;inputType&quot;: &quot;TEXT&quot;,      &quot;editable&quot;: true,      &quot;required&quot;: false,      &quot;showInAddPage&quot;: true,      &quot;showInComfirmPage&quot;: true,      &quot;showInTable&quot;: true,      &quot;editableInConfirmPage&quot;: true,      &quot;confirmProp&quot;: true    &#125;,    &#123;      &quot;columnCode&quot;: &quot;confirmer&quot;,      &quot;showName&quot;: &quot;确认人员&quot;,      &quot;systemInitialization&quot;: false,      &quot;sortIndex&quot;: 14,      &quot;supportInExcel&quot;: true,      &quot;excelColumnWidth&quot;: 20,      &quot;inputType&quot;: &quot;TEXT&quot;,      &quot;editable&quot;: true,      &quot;required&quot;: false,      &quot;showInAddPage&quot;: false,      &quot;showInComfirmPage&quot;: true,      &quot;showInTable&quot;: true,      &quot;editableInConfirmPage&quot;: true,      &quot;confirmProp&quot;: true    &#125;  ]&#125;</code></pre><h2 id="单机版本自定义配置"><a href="#单机版本自定义配置" class="headerlink" title="单机版本自定义配置"></a>单机版本自定义配置</h2><p><img src="https://pics.codingcoder.cn/pics/202303132224837.png"></p><p><img src="https://pics.codingcoder.cn/pics/202303132227483.png"></p><h2 id="网络版本字段统一配置"><a href="#网络版本字段统一配置" class="headerlink" title="网络版本字段统一配置"></a>网络版本字段统一配置</h2><h3 id="客户端同步配置信息"><a href="#客户端同步配置信息" class="headerlink" title="客户端同步配置信息"></a>客户端同步配置信息</h3><p><img src="https://pics.codingcoder.cn/pics/202303132234350.png"></p><p><img src="https://pics.codingcoder.cn/pics/202303132235015.png"></p><h3 id="服务端配置字段数据"><a href="#服务端配置字段数据" class="headerlink" title="服务端配置字段数据"></a>服务端配置字段数据</h3><p><img src="https://pics.codingcoder.cn/pics/202303132238534.png"></p><p><img src="https://pics.codingcoder.cn/pics/202303132241675.png"></p><p><img src="https://pics.codingcoder.cn/pics/202303132242473.png"></p><h4 id="固定下拉框值内容设置"><a href="#固定下拉框值内容设置" class="headerlink" title="固定下拉框值内容设置"></a>固定下拉框值内容设置</h4><p><img src="https://pics.codingcoder.cn/pics/202303132244152.png"></p><p><img src="https://pics.codingcoder.cn/pics/202303132245290.png"></p><h4 id="动态定制下拉框内容"><a href="#动态定制下拉框内容" class="headerlink" title="动态定制下拉框内容"></a>动态定制下拉框内容</h4><p><img src="https://pics.codingcoder.cn/pics/202303132246275.png"></p><p>当前支持的动态下拉内容如下：</p><table><thead><tr><th>字典值</th><th>代码中动态收集器名</th><th>含义说明</th></tr></thead><tbody><tr><td>ServerDynamic_UserList</td><td>UserList</td><td>获取系统中的用户信息列表，用于下拉框中选择使用。</td></tr></tbody></table><p>如果需要定制其余动态下拉框内容，需要提供一个<code>IEnumDynamicCollector</code>实现类，并指定该收集器实现类的<code>name()</code>信息，然后通过界面上添加字典code即可（字典code规则： <code>ServerDynamic_ + name</code>）。</p><p>可以参考如下内容：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">&#x2F;** * 用户列表信息下拉框内容生成器 * * @author Veezean, 公众号 @架构悟道 * @since 2023&#x2F;3&#x2F;12 *&#x2F;@Componentpublic class UserEnumDynamicCollector implements IEnumDynamicCollector &#123;    private static final String SERVER_DYNAMIC_USERLIST &#x3D; &quot;UserList&quot;;    @Autowired    private UserService userService;    @Override    public String name() &#123;        return SERVER_DYNAMIC_USERLIST;    &#125;    @Override    public List&lt;String&gt; doCollect() &#123;        return userService.getUserShortInfoList()                .stream()                .map(userShortInfo -&gt; userShortInfo.getUserName() + &quot;|&quot; + userShortInfo.getAccount())                .collect(Collectors.toList());    &#125;&#125;</code></pre><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><p><strong>我是悟道，聊技术、又不仅仅聊技术~</strong></p><p>如果觉得有用，请<strong>点赞 + 关注</strong>让我感受到您的支持。也可以关注下我的公众号【架构悟道】，获取更及时的更新。</p><p>期待与你一起探讨，一起成长为更好的自己。</p><p><img src="https://pics.codingcoder.cn/pics/202207091317876.png"></p>]]></content>
      
      
      <categories>
          
          <category> CodeReview插件帮助文档 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> CodeReview插件 </tag>
            
            <tag> IDEA插件 </tag>
            
            <tag> 帮助文档 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>探讨下如何更好的使用缓存 —— Redis缓存的特殊用法以及与本地缓存一起构建多级缓存的实现</title>
      <link href="//post/20230118065917.html"/>
      <url>//post/20230118065917.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>本篇文章，我们就一起聊一聊如何来更好的使用缓存，探寻下如何降低缓存交互过程的性能损耗、如何压缩缓存的存储空间占用、如何保证多个操作命令原子性等问题的解决策略，让缓存在项目中可以发挥出更佳的效果。</p></blockquote><p><img src="https://pics.codingcoder.cn/pics/202210050807355.png"></p><p>大家好，又见面了。</p><hr><blockquote><p>本文是笔者作为掘金技术社区签约作者的身份输出的缓存专栏系列内容，将会通过系列专题，讲清楚缓存的方方面面。如果感兴趣，欢迎关注以获取后续更新。</p></blockquote><hr><p>通过前面的文章，我们一起剖析了<code>Guava Cache</code>、<code>Caffeine</code>、<code>Ehcache</code>等<strong>本地缓存</strong>框架的原理与使用场景，也一同领略了以<code>Redis</code>为代表的<strong>集中式缓存</strong>在分布式高并发场景下无可替代的价值。</p><p>现在的很多大型高并发系统都是采用的分布式部署方式，而作为高并发系统的基石，缓存是不可或缺的重要环节。项目中使用缓存的目的是为了提升整体的运算处理效率、降低对外的IO请求，而集中式缓存是独立于进程之外部署的远端服务，需要基于网络IO的方式交互。如果一个业务逻辑中涉及到非常频繁的缓存操作，势必会导致引入大量的<strong>网络IO</strong>交互，造成过大的性能损耗、加剧缓存服务器的压力。另外，对于现在互联网系统的海量用户数据，如何压缩缓存数据<strong>占用容量</strong>，也是需要面临的一个问题。</p><p>本篇文章，我们就一起聊一聊如何来更好的使用缓存，探寻下如何降低缓存交互过程的性能损耗、如何压缩缓存的存储空间占用、如何保证多个操作命令原子性等问题的解决策略，让缓存在项目中可以发挥出更佳的效果。</p><h2 id="通过BitMap降低Reids存储容量压力"><a href="#通过BitMap降低Reids存储容量压力" class="headerlink" title="通过BitMap降低Reids存储容量压力"></a>通过BitMap降低Reids存储容量压力</h2><p>在一些互联网类的项目中，经常会有一些签到相关功能。如果使用Redis来缓存用户的签到信息，我们一般而言会怎么存储呢？常见的会有下面2种思路：</p><ol><li>使用Set类型，每天生层1个Set，然后将签到用户添加到对应的Set中；</li><li>还是使用Set类型，每个用户一个Set，然后将签到的日期添加到Set中。</li></ol><p>对于海量用户的系统而言，按照上述的策略，那么每天仅签到信息这一项，就可能会有上千万的记录，一年累积下来的数据量更大 —— 这对Redis的存储而言是笔不小的开销。对于签到这种简单场景，只有签到和没签到两种情况，也即<code>0/1</code>的场景，我们也可以通过<strong>BitMap</strong>来进行存储以大大降低内存占用。</p><p><code>BitMap（位图）</code>可以理解为一个bit数组，对应bit位可以存放0或者1，最终这个bit数组被转换为一个字符串的形式存储在Redis中。比如签到这个场景，我们可以每天设定一个key，然后存储的时候，我们可以将数字格式的<em>userId</em>表示在BitMap中具体的位置信息，而BitMap中此位置对应的bit值为1则表示该用户已签到。</p><p><img src="https://pics.codingcoder.cn/pics/202211291524365.png"></p><p>Redis其实也提供了对BitMap存储的支持。前面我们提过Redis支持String、Set、List、ZSet、Hash等数据结构，而BitMap能力的支持，其实是<em>对String数据结构的一种扩展</em>，使用String数据类型来支持BitMap的能力实现。比如下面的代码逻辑：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public void userSignIn(long userId) &#123;    String today &#x3D; LocalDate.now().format(DateTimeFormatter.ofPattern(&quot;yyyy-MM-dd&quot;));    String redisKey &#x3D; &quot;UserSginIn_&quot; + today;    Boolean hasSigned &#x3D; stringRedisTemplate.opsForValue().getBit(redisKey, userId);    if (Boolean.TRUE.equals(hasSigned)) &#123;        System.out.println(&quot;今日已签过到！&quot;);    &#125; else &#123;        stringRedisTemplate.opsForValue().setBit(&quot;TodayUserSign&quot;, userId, true);        System.out.println(&quot;签到成功！&quot;);    &#125;&#125;</code></pre><p>对于Redis而言，每天就只有一条<code>key-value</code>数据。下面对比下使用BitMap与使用普通key-value模式的数据占用情况对比。模拟构造<em>10亿</em>用户数据量进行压测统计，结果如下：</p><ul><li>BitMap格式： 150M</li><li>key-value格式： 41G</li></ul><p>可以看出，在<strong>存储容量</strong>占用方面，BitMap完胜。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h2 id="关于pipeline管道批处理与multi事务原子性"><a href="#关于pipeline管道批处理与multi事务原子性" class="headerlink" title="关于pipeline管道批处理与multi事务原子性"></a>关于pipeline管道批处理与multi事务原子性</h2><h3 id="使用Pipeline降低与Reids的IO交互频率"><a href="#使用Pipeline降低与Reids的IO交互频率" class="headerlink" title="使用Pipeline降低与Reids的IO交互频率"></a>使用Pipeline降低与Reids的IO交互频率</h3><p>在很多的业务场景中，我们可能会涉及到同时去执行好多条redis命令的操作，比如系统启动的时候需要将DB中存量的数据全部加载到Redis中重建缓存的时候。如果业务流程需要频繁的与Redis交互并提交命令，可能会导致在网络IO交互层面消耗太大，导致整体的性能降低。</p><p>这种情况下，可以使用<code>pipeline</code>将各个具体的请求分批次提交到Redis服务器进行处理。</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">private void redisPipelineInsert() &#123;    stringRedisTemplate.executePipelined(new SessionCallback() &#123;        @Override        public Object execute(RedisOperations operations) throws DataAccessException &#123;            try &#123;                &#x2F;&#x2F; 具体的redis操作，多条操作都在此处理，最后会一起提交到Redis远端去执行            &#125; catch (Exception e) &#123;                log.error(&quot;failed to execute pipelined...&quot;, e);            &#125;            return null;        &#125;    &#125;);&#125;</code></pre><p>使用pipeline的方式，可以减少客户端与redis服务端之间的网络交互频次，但是pipeline也<em>只是负责将原本需要多次网络交互的请求封装一起提交</em>到redis上，在redis层面其执行命令的时候依旧是逐个去执行，并不会保证这一批次的所有请求一定是连贯被执行，其中可能会被插入其余的执行请求。</p><p><img src="https://pics.codingcoder.cn/pics/202211291653066.png"></p><p>也就是说，pipeline的操作是<strong>不具备原子性</strong>的。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h3 id="使用multi实现请求的事务"><a href="#使用multi实现请求的事务" class="headerlink" title="使用multi实现请求的事务"></a>使用multi实现请求的事务</h3><p>前面介绍pipeline的时候强调了其仅仅只是将多个命令打包一起提交给了服务器，然后服务器依旧是等同于逐个提交上来的策略进行处理，无法保证原子性。对于一些需要保证多个操作命令原子性的场景下，可以使用<code>multi</code>来实现。</p><p>当客户端请求执行了multi命令之后，也即开启了事务，服务端会将这个客户端记录为一个特殊的状态，之后这个客户端发送到服务器上的命令，都会<em>被临时缓存</em>起来而不会执行。只有当收到此客户端发送<code>exec</code>命令的时候，redis才会将缓存的所有命令一起逐条的执行并且保证这一批命令被按照发送的顺序执行、执行期间不会被其他命令插入打断。</p><p><img src="https://pics.codingcoder.cn/pics/202211291711549.png"></p><p>代码示例如下：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">private void redisMulti() &#123;    stringRedisTemplate.multi();    stringRedisTemplate.opsForValue().set(&quot;key1&quot;, &quot;value1&quot;);    stringRedisTemplate.opsForValue().set(&quot;key2&quot;, &quot;value2&quot;);    stringRedisTemplate.exec();&#125;</code></pre><p>需要注意的一点是，redis的事务与关系型数据库中的事务是两个不同概念，Redis的事务<strong>不支持回滚</strong>，只能算是Redis中的一种特殊标记，可以将这个事务范围内的请求以指定的顺序执行，中间不会被插入其余的请求，可以保证多个命令执行的原子性。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h3 id="pipeline与multi区别"><a href="#pipeline与multi区别" class="headerlink" title="pipeline与multi区别"></a>pipeline与multi区别</h3><p>从上面分别对<code>pipeline</code>与<code>multi</code>的介绍，可以看出两者在定位与功能分工上的差异点：</p><ul><li><p><strong>pipeline是客户端行为</strong>，只是负责将客户端的多个请求一次性打包传递到服务器端，服务端依旧是按照和单条请求一样的处理，批量传递到服务端的请求之间可能会插入别的客户端的请求操作，所以它是无法保证原子性的，侧重点在于其可以提升客户端的效率（降低频繁的网络交互损耗）</p></li><li><p><strong>multi是服务端行为</strong>，通过开启事务缓存，保证客户端在事务期间提交的请求可以被一起集中执行。它的侧重点是保证多条请求的原子性，执行期间不会被插入其余客户端的请求，但是由于开启事务以及命令缓存等额外的操作，其对性能略微有一些影响。</p></li></ul><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h2 id="多级缓存机制"><a href="#多级缓存机制" class="headerlink" title="多级缓存机制"></a>多级缓存机制</h2><h3 id="本地-远端的二级缓存机制"><a href="#本地-远端的二级缓存机制" class="headerlink" title="本地+远端的二级缓存机制"></a>本地+远端的二级缓存机制</h3><p>在涉及与集中式缓存之间频繁交互的时候，通过前面介绍的pipeline方式可以适当的降低与服务端之间网络交互的频次，但是很多情况下，依旧会产生大量的网络交互，对于一些追求极致性能的系统而言，可能依旧无法满足诉求。</p><p>回想下此前文章中花费大量篇幅介绍的本地缓存，本地缓存在分布式场景下容易造成数据不一致的问题，但是其最大特点就是快，因为数据都存储在进程内。所以可以将本地缓存作为集中式缓存的一个补充策略，对于一些需要高频读取且不会经常变更的数据，缓存到本地进行使用。</p><p>常见的<code>本地+远端</code>二级缓存有两种存在形式。</p><ul><li><strong>独立划分，各司其职</strong></li></ul><p><img src="https://pics.codingcoder.cn/pics/202211282216146.png"></p><p>这种情况，将缓存数据分为了2种类型，一种是<em>不常变更的数据</em>，比如系统配置信息等，这种数据直接系统启动的时候从DB中加载并缓存到进程内存中，然后业务运行过程中需要使用时候直接从内存读取。而对于其他可能会<em>经常变更</em>的业务层面的数据，则缓存到Redis中。</p><ul><li><strong>混合存储，多级缓存</strong></li></ul><p><img src="https://pics.codingcoder.cn/pics/202211282230918.png"></p><p>这种情况可以搭配<code>Caffeine</code>或者<code>Ehcache</code>等本地缓存框架一起实现。首先去本地缓存中执行查询，如果查询到则返回，查询不到则去Redis中尝试获取。如果Redis中也获取不到，则可以考虑去DB中进行回源兜底操作，然后将回源的结果存储到Redis以及本地缓存中。这种情况下需要注意下如果数据发生变更的时候，需要删除本地缓存，以确保下一次请求的时候，可以再次去Redis拉取最新的数据。</p><p><img src="https://pics.codingcoder.cn/pics/202211282236062.png"></p><p><strong>本地+远端</strong>的二级缓存机制有着多方面的优点：</p><ul><li><p>主要操作都在本地进行，可以充分的<strong>享受到本地缓存的速度优势</strong>；</p></li><li><p>大部分操作都在本地进行，充分降低了客户端与远端集中式缓存服务器之间的IO交互，也<strong>降低了带宽占用</strong>；</p></li><li><p>通过本地缓存层，抵挡了大部分的业务请求，对集中式缓存服务器端进行减压，大大<strong>降低服务端的压力</strong>；</p></li><li><p><strong>提升了业务的可靠性</strong>，本地缓存实际上也是一种额外的副本备份，极端情况下，及时集中式缓存的服务端宕机，因为本地还有缓存数据，所以业务节点依旧可以对外提供正常服务。</p></li></ul><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h3 id="二级缓存的应用身影"><a href="#二级缓存的应用身影" class="headerlink" title="二级缓存的应用身影"></a>二级缓存的应用身影</h3><p>其实，在<code>C-S架构</code>的系统里面，多级缓存的概念使用的也非常的频繁。经常<em>Clinet端</em>会缓存运行时需要的业务数据，然后采用定期更新或者事件触发的方式从服务端更新本地的数据。而<em>Server端</em>负责存储所有的数据，并保证数据更新的时候可以提供给客户端进行更新获取。</p><p>一个典型的例子，就是分布式系统中的配置中心或者是服务注册管理中心。比如<code>SpringCloud</code>家族的<code>Eureka</code>，或者是<code>Alibaba</code>开源的<code>Nacos</code>。它们都有采用客户端本地缓存+服务端数据统一存储的方式，来保证整体的处理效率，降低客户端对于Server端的实时交互依赖。</p><p>看一下<code>Nacos</code>的交互示意：</p><p><img src="https://pics.codingcoder.cn/pics/202210012142276.png"></p><p>从图中可以表直观的看到，Client将业务数据缓存到各自本地，这样业务逻辑进行处理的时候就可以直接从本地缓存中查询到相关的业务节点映射信息，而Server端只需要负责在数据有变更的事后推送到Client端更新到本地缓存中即可，避免了Server端去承载业务请求的流量压力。整体的可靠性也得到了保证，避免了Server端异常对业务正常处理造成影响。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h2 id="小结回顾"><a href="#小结回顾" class="headerlink" title="小结回顾"></a>小结回顾</h2><p>好啦，到这里呢，《<a href="https://juejin.cn/column/7140852038258147358">深入理解缓存原理与实战设计</a>》系列专栏的内容就暂告一段落咯。本专栏围绕缓存这个宏大命题进行展开阐述，从缓存各种核心要素、到本地缓存的规范与标准介绍，从手写本地缓存框架、到各种优秀本地缓存框架的上手与剖析，从本地缓存到集中式缓存再到最后的多级缓存的构建，一步步全方位、系统性地做了介绍。希望通过本专栏的介绍，可以让大家对缓存有个更加深刻的理解，可以更好的在项目中去使用缓存，让缓存真正的成为我们项目中性能提升的<strong>神兵利器</strong>。</p><p>看到这里，不知道各位小伙伴们对缓存的理解与使用，是否有了新的认识了呢？你觉得缓存还有哪些好的使用场景呢？欢迎评论区一起交流下，期待和各位小伙伴们一起切磋、共同成长。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><p><strong>我是悟道，聊技术、又不仅仅聊技术~</strong></p><p>如果觉得有用，请<strong>点赞 + 关注</strong>让我感受到您的支持。也可以关注下我的公众号【架构悟道】，获取更及时的更新。</p><p>期待与你一起探讨，一起成长为更好的自己。</p><p><img src="https://pics.codingcoder.cn/pics/202207091312091.gif"></p><p><img src="https://pics.codingcoder.cn/pics/202207091317876.png"></p>]]></content>
      
      
      <categories>
          
          <category> 缓存原理与实战设计 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JAVA </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>面对集中式缓存实现上的挑战，Redis交出的是何种答卷？聊聊Redis的主从、哨兵与集群部署模式</title>
      <link href="//post/20230113071317.html"/>
      <url>//post/20230113071317.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>对于一个集中式缓存的分布式能力构建，必须要额外提供一些机制，来保障数据在各个节点上的安全与一致性。本文以Redis为代表，看下集Redis面对上述问题交出的是怎样一份答卷。</p></blockquote><p><img src="https://pics.codingcoder.cn/pics/202210050807355.png"></p><p>大家好，又见面了。</p><hr><blockquote><p>本文是笔者作为掘金技术社区签约作者的身份输出的缓存专栏系列内容，将会通过系列专题，讲清楚缓存的方方面面。如果感兴趣，欢迎关注以获取后续更新。</p></blockquote><hr><p>在本专栏前面的文章中，我们介绍了各种本地缓存框架，也知晓了本地缓存的常见特性与设计理念。在前两篇文章中，我们介绍了<strong>集中式缓存</strong> Redis的一些主流特性与典型使用场景。现在我们来对比一下，分布式缓存相比于本地缓存，在实现层面需要关注的点有哪些不同。梳理如下：</p><table><thead><tr><th>维度</th><th>本地缓存</th><th>集中式缓存</th></tr></thead><tbody><tr><td>缓存量</td><td>受限于单机内存大小，存储数据有限</td><td>需要提供给分布式系统里面所有节点共同使用，对于大型系统而言，对集中式缓存的容量诉求非常的大，远超单机内存的容量大小。</td></tr><tr><td>可靠性</td><td>影响有限，只有本进程使用，不会影响其他进程的可靠性。</td><td>作为整个系统扛压屏障，系统内所有节点共同依赖的通用服务，一旦集中式缓存出问题，会影响与其对接的所有业务节点，对系统的影响是<em>致命性</em>的。</td></tr><tr><td>承压性</td><td>承载单机节点的压力，请求量有限</td><td>承载整个分布式集群所有节点的流量，系统内业务分布式节点部署数量越多、业务体量越大，会导致集中缓存要承载的压力就越大，甚至是上不封顶的。</td></tr></tbody></table><p>从上述几个维度的对比可以发现，同样是缓存，但<strong>集中式缓存</strong>所承担的使命是完全不一样的，业务对集中式缓存的<code>存储容量</code>、<code>可靠性</code>、<code>承压性</code>等方面的诉求也是天壤之别，不可等同视之。以<strong>Redis</strong>为例：</p><ul><li>如何打破redis缓存容量受限于机器单机内存大小的问题？</li><li>如何使得redis能够扛住多方过来的请求压力？</li><li>如何保证redis不会成为单点故障源？</li></ul><p>其实答案很简单，加机器！通过多台机器的叠加使用，达到比单机更优的效果 —— 现在业务系统的集群化部署，也都是采用的这个思路。Redis的分布式之路亦是如此，但相比于常规的业务系统分布式集群化构建更加复杂：</p><ol><li>很多业务实现集群化部署会很简单，因为每个业务进程节点都是<em>无状态</em>的，只需要部署下然后通过负载均衡的方式对外提供请求应答即可。</li><li>Redis作为一个集中式缓存数据库，它是<em>有状态</em>的，不仅需要将进程分别部署在多个节点上，还需要将数据也分散存储在各个节点上，同时还得保证整个Redis集群对外是一个统一整体。</li></ol><p>所以对于一个集中式缓存的分布式能力构建，必须要额外提供一些机制，来保障数据在各个节点上的安全与<strong>一致性</strong>，还需要将分散在各个节点上的数据都组成一个逻辑上的整体。</p><p>下面，我们以Redis作为集中式缓存的代表，来看下集Redis面对上述各种难题，交出的是怎样的答卷。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h2 id="Reids部署方式的演进史"><a href="#Reids部署方式的演进史" class="headerlink" title="Reids部署方式的演进史"></a>Reids部署方式的演进史</h2><h3 id="单机部署-——-原始形态，最简单"><a href="#单机部署-——-原始形态，最简单" class="headerlink" title="单机部署 —— 原始形态，最简单"></a>单机部署 —— 原始形态，最简单</h3><p><strong>单机部署</strong>只能算是一个开发或测试场景去小范围使用的场景，它与普通本地缓存无二，在可靠性与承压性上无法得到保证。</p><p>虽说Redis的性能很高，但俗话也说双拳难敌四手，单机性能再高，也无法抗住大规模集群中所有节点过来的并发请求。此外，单机部署还有个致命点在于其不具备高可用性，系统容易出现<em>单点故障</em>。</p><p><img src="https://pics.codingcoder.cn/pics/202211252257064.png"></p><p>所以说，稍微正规点的项目，几乎不会有人天真到会用单机模式去部署线上使用。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h3 id="主从（master-replica）"><a href="#主从（master-replica）" class="headerlink" title="主从（master-replica）"></a>主从（master-replica）</h3><p>前面说过单机节点存在诸多问题，很少在生产环境上使用。在实际项目中，有些项目的存储容量要求其实并不是特别的高（比如常规的16G或者32G就已经足够使用），但是需要保证数据的可靠、并且支持大并发量请求，这种情况下，就可以选择<strong>主从部署</strong>的方式。</p><p>对于redis来说，<code>一主两从</code>是比较常见的搭配，如下所示：</p><p><img src="https://pics.codingcoder.cn/pics/202211260950451.png"></p><p>主从模式按照读写分离的策略来提升整体的请求处理能力：</p><ol><li><p>主节点(Master)同时对外提供<em>读和写</em>操作</p></li><li><p>从节点(Slave)通过<code>replicate</code>同步的方式，从主节点复制数据，保持自身数据与主节点一致</p></li><li><p>从节点只能对外提供<em>读操作</em></p></li></ol><p>当然，对于读多写少类的操作，为了提升整体读请求的处理能力，可以采用<code>一主多从</code>的方式：</p><p><img src="https://pics.codingcoder.cn/pics/202211260951823.png"></p><p>所有的从节点都从主节点进行数据同步，这样会导致主节点的同步处理压力过大而成为瓶颈。为了解决这个问题，redis还支持了从slave节点分发的能力：</p><p><img src="https://pics.codingcoder.cn/pics/202211260950417.png"></p><p>Redis的主从模式重点在于解决整体的承压能力，利用从节点分担读取操作的压力。但是其在<em>容错恢复</em>等可靠性层面欠缺明显，<strong>不具备</strong>自动的故障转移与恢复能力：</p><ul><li>如果slave从节点宕机，整个redis依旧可以正常提供服务，待slave节点重新启动后，可以恢复从master节点的数据同步、然后继续提供服务。</li><li>如果master主节点宕机，则redis功能受损，无法继续提供写服务，直到手动修复master节点方可恢复。</li></ul><p>当然，master节点故障后，也可以手动将其中一个从节点切换为新的master节点来恢复故障。而原先的master节点恢复后，需要手动将其降级为slave节点，对外提供只读服务。</p><p>实际使用的时候，手动故障恢复的时效无法得到保证，为了支持自动的故障转移与恢复能力，Redis在主从模式的基础上进行优化增强，提供了哨兵（Sentinel）架构模式。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h3 id="哨兵（sentinel）"><a href="#哨兵（sentinel）" class="headerlink" title="哨兵（sentinel）"></a>哨兵（sentinel）</h3><p><strong>哨兵模式</strong>是在现代自动化系统里面常见的一种模式。比如特斯拉汽车就配置了哨兵模式，当车辆停车锁定并启动哨兵模式时，会通过车辆四周的摄像头持续的监控车辆四周的环境，如果发现异常则启动报警系统。</p><p>同样地，在软件架构领域，也可以通过设定一些主进程之外的辅助进程，充当“哨兵”的角色时刻监控着主服务，一旦主服务出现异常则进行报警或者自动介入辅助故障转移，以最大限度的保证系统功能的持续性。</p><p>Redis的哨兵模式，就是在主从模式的基础上，额外部署若干独立的哨兵进程，通过哨兵进程去监视者Redis主从节点的状态，一旦发现主节点宕机，则哨兵可以重新从剩余slave节点中推选一个新的节点并将其升级为master节点，以此保证整个系统功能可以正常使用。</p><p>比较典型的一个<code>Redis sentinel</code>部署场景是“<em>一主二从三哨兵</em>”的组合，如下：</p><p><img src="https://pics.codingcoder.cn/pics/202211261040406.png"></p><p>哨兵可以准实时的监控着组网内所有的节点的状态信息，如果判定master节点宕机之后，所有的sentinel节点会一起推选出一个新的master节点。由于sentinel哨兵节点需要承担着master节点推选的责任，所以实施的时候要去sentinel节点个数必须为<em>基数</em>（比如3个、5个等），这是为了保证投票的时候不会出现平局的情况。</p><p>在哨兵模式下：</p><ol><li>如果Redis的master节点宕机之后，Sentinel监控到之后，需要先判定确认master节点已经宕机，然后会从剩余存活的slave节点中投票选出一个新的节点作为master节点。</li><li>Sentinel监控到此前宕机的master节点重新恢复之后，会将其作为slave节点，挂到现有的新的master节点下面。</li></ol><p>哨兵模式有效的解决了高可用的问题，保证了主节点的自动切换操作，进一步保障了Redis缓存节点的可靠性。但是，不管是哨兵模式还是主从模式，其增加的多台部署机器，都仅仅是扩展其承压能力与可靠性，并没有解决分布式场景下对于集中缓存容量的焦虑 —— 只能适用于数据量有限的场景。</p><p>成年人的世界总是贪婪的。如果我们既想要保证Redis的可靠性与承压性，还想要突破容量上的限制，就需要Redis的集群模式登场了。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h3 id="集群（cluster）"><a href="#集群（cluster）" class="headerlink" title="集群（cluster）"></a>集群（cluster）</h3><p>Redis提供了去中心化的<strong>集群部署</strong>模式，集群内所有Redis节点之间两两连接，而很多的客户端工具会根据key将请求分发到对应的分片下的某一个节点上进行处理。</p><p>一个典型的Redis集群部署场景如下图所示：</p><p><img src="https://pics.codingcoder.cn/pics/202211261555542.png"></p><p>在Redis集群里面，又会划分出<code>分区</code>的概念，一个集群中可有多个分区。分区有几个特点：</p><ol><li>同一个分区内的Redis节点之间的数据完全一样，多个节点保证了数据有多份副本冗余保存，且可以提供高可用保障。</li><li>不同分片之间的数据不相同。</li><li>通过水平增加多个分片的方式，可以实现整体集群的容量的扩展。</li></ol><p>按照Cluster模式进行部署的时候，要求最少需要部署<code>6个</code>Redis节点（3个分片，每个分片中1主1从），其中集群中每个分片的master节点负责对外提供读写操作，slave节点则作为故障转移使用（master出现故障的时候充当新的master）、对外提供只读请求处理。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h2 id="集群数据分布策略"><a href="#集群数据分布策略" class="headerlink" title="集群数据分布策略"></a>集群数据分布策略</h2><h3 id="Redis-Sharding（数据分片）"><a href="#Redis-Sharding（数据分片）" class="headerlink" title="Redis Sharding（数据分片）"></a>Redis Sharding（数据分片）</h3><p>在<code>Redis Cluster</code>前，为了解决数据分发到各个分区的问题，普遍采用的是<code>Redis Sharding</code>（数据分片）方案。所谓的Sharding，其实就是一种数据分发的策略。根据key的hash值进行取模，确定最终归属的节点。</p><p>使用Redis Sharding方式进行数据分片的时候，当集群内数据分区个数出现变化的时候，比如集群扩容的时候，会导致请求被分发到错误节点上，导致缓存<em>命中率降低</em>。</p><p><img src="https://pics.codingcoder.cn/pics/202211261611685.png"></p><p>如果需要解决这个问题，就需要对原先扩容前已经存储的数据重新进行一次hash计算和取模操作，将全部的数据重新分发到新的正确节点上进行存储。这个操作被称为<code>重新Sharding</code>，重新sharding期间服务不可用，可能会对业务造成影响。</p><h3 id="一致性Hash"><a href="#一致性Hash" class="headerlink" title="一致性Hash"></a>一致性Hash</h3><p>为了降低节点的增加或者移除对于整体已有缓存数据访问的影响，最大限度的保证缓存命中率，改良后的<code>一致性Hash</code>算法浮出水面。</p><p><img src="https://pics.codingcoder.cn/pics/202211261704124.png"></p><p>通过一致性Hash算法，将所有的存储节点排列在首尾相接的Hash环上，每个key在计算Hash后会顺时针找到最近的存储节点存放。而当有新的分区节点加入或退出时，仅影响该节点在Hash环上顺时针相邻的后续一个节点。</p><p>当然咯，如果Hash圆环上的分区节点数太少，可能会出现数据在各个分片中分布不均衡的情况，也即出现<strong>数据倾斜</strong>。</p><p><img src="https://pics.codingcoder.cn/pics/202211261659989.png"></p><p>为了解决这个问题，引入了<code>虚拟节点</code>的机制，通过增加虚拟节点，来实现数据尽可能的均匀分布在各个节点上。</p><p><img src="https://pics.codingcoder.cn/pics/202211261702759.png"></p><p>上图中，A1、A2实际上都对应真实的A分区节点，而B1、B2则对应真实的B分区节点。通过虚拟节点的方式，尽可能让节点在Hash环上保持均分，实现数据在分区内的均分。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h3 id="Hash槽"><a href="#Hash槽" class="headerlink" title="Hash槽"></a>Hash槽</h3><p>不管是原本的Hash取模，还是经过改良后的一致性Hash，在节点的新增或者删减的时候，始终都会出现部分缓存数据丢失的问题 —— 只是丢失的数据量的多少区别。如何才能实现扩展或者收缩节点的时候，保持已有数据不丢失呢？</p><p>既然动态变更调整的方式行不通，那就手动指定咯！Hash槽的实现策略因此产生。何为Hash槽？Hash槽的原理与HashMap有点相似，共有16384个槽位，每个槽位对应一个数据桶，然后每个Redis的分区都可以负责这些hash槽中的部分区间。存储数据的时候，数据key经过Hash计算后会匹配到一个对应的槽位，然后数据存储在该槽位对应的分片中。然后各个分区节点会与Hash槽之间有个映射绑定关系，由指定的Redis分区节点负责存储对应的Has槽对应的具体分片文件。</p><p><img src="https://pics.codingcoder.cn/pics/202211280952704.png"></p><p>数据查询的时候，先根据key的Hash值进行计算，确定应该落入哪个Hash槽，进而根据映射关系，确定负责此Hash槽数据存储的redis分区节点是哪个，然后就可以去做对应的查询操作。</p><p>执行数据节点增加的时候，需要手动执行下处理：</p><ul><li>为新的节点分配新其负责的Hash槽位区间段；</li><li>调整已有的节点的Hash槽位负责区间段；</li><li>将调整到新节点上的hash槽位区间段对应的数据分片文件拷贝到新的节点上。</li></ul><p>这样，就不会出现已有数据无法使用的情况了。鉴于Hash槽的自主可控性以及节点伸缩场景下的优势，其也成为了Redis Cluster中使用的方案。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h2 id="小结回顾"><a href="#小结回顾" class="headerlink" title="小结回顾"></a>小结回顾</h2><p>好啦，关于Redis部署模式的演进探讨，就聊到这里了。通过本篇文章，我们也可以感受出集中式缓存相对本地而言，在实现与设计机制上要更加的复杂，因为需要考虑与解决多方面的问题，比如可靠性、承压性、容量以及后期的水平扩容能力等等，而这些也都是一个合格的集中式缓存所必须要具备的基本品格。</p><p>那么，了解Redis对于集中式缓存在节点安全性与扩展性上的实现后，如果让你来设计一个集中缓存的话，你会采用何种方式来保证其可靠性与后续的扩展性呢？欢迎评论区一起交流下，期待和各位小伙伴们一起切磋、共同成长。</p><p>📣 <strong>补充说明</strong> ：</p><blockquote><p>本文属于《<a href="https://juejin.cn/column/7140852038258147358">深入理解缓存原理与实战设计</a>》系列专栏的内容之一。该专栏围绕缓存这个宏大命题进行展开阐述，全方位、系统性地深度剖析各种缓存实现策略与原理、以及缓存的各种用法、各种问题应对策略，并一起探讨下缓存设计的哲学。</p><p>如果有兴趣，也欢迎关注此专栏。</p></blockquote><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><p><strong>我是悟道，聊技术、又不仅仅聊技术~</strong></p><p>如果觉得有用，请<strong>点赞 + 关注</strong>让我感受到您的支持。也可以关注下我的公众号【架构悟道】，获取更及时的更新。</p><p>期待与你一起探讨，一起成长为更好的自己。</p><p><img src="https://pics.codingcoder.cn/pics/202207091312091.gif"></p><p><img src="https://pics.codingcoder.cn/pics/202207091317876.png"></p>]]></content>
      
      
      <categories>
          
          <category> 缓存原理与实战设计 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JAVA </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis缓存何以一枝独秀？(2) —— 聊聊Redis的数据过期、数据淘汰以及数据持久化的实现机制</title>
      <link href="//post/20230112090217.html"/>
      <url>//post/20230112090217.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>Redis作为一个非关系型数据库，由于其超高的并发处理性能，及其对缓存场景所提供的系列能力构建，使其成为了集中缓存的绝佳选择。本篇我们聊聊Redis数据管理的能力，如数据过期、数据淘汰、数据持久化等。</p></blockquote><hr><p><img src="https://pics.codingcoder.cn/pics/202210050807355.png"></p><p>大家好，又见面了。</p><hr><blockquote><p>本文是笔者作为掘金技术社区签约作者的身份输出的缓存专栏系列内容，将会通过系列专题，讲清楚缓存的方方面面。如果感兴趣，欢迎关注以获取后续更新。</p></blockquote><hr><p>上一篇文章中呢，我们简单的介绍了下<code>Redis</code>的整体情况。作为集中式缓存的优秀代表，Redis可以帮助我们在项目中完成很多特定的功能。Redis准确的说是一个<strong>非关系型数据库</strong>，但是由于其超高的并发处理性能，及其对于缓存场景所提供的一系列能力构建，使其成为了分布式系统中的集中缓存的绝佳选择。</p><p>Redis对于缓存能力场景的支持，除了基础的缓存<em>增删改查</em>，还支持对记录的<strong>过期</strong>时间设定，支持多种不同的数据<strong>淘汰策略</strong>等等。此外为了解决内存型组件数据可靠性问题，还提供了一系列的数据<strong>持久化</strong>方案。</p><p>本篇文章中，我们就一起聊一聊这方面内容。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h2 id="数据过期能力"><a href="#数据过期能力" class="headerlink" title="数据过期能力"></a>数据过期能力</h2><p>为了节约内存的使用量，保证有限的内存空间能够被更有价值的数据使用，所以很多内存缓存组件都会支持数据过期能力。之前我们提过的本地缓存组件Guava Cache、Caffeine等支持基于<strong>缓存容器对象级别</strong>设置统一的过期时间，而<code>Redis</code>则支持对<strong>每条记录</strong>设定单独的过期时间。</p><h3 id="创建时设定过期时间"><a href="#创建时设定过期时间" class="headerlink" title="创建时设定过期时间"></a>创建时设定过期时间</h3><p>可以在创建记录的时候指定过期时间，redis提供了<code>setex</code>命令可以实现插入的时候同步指定过期时间。比如：</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">setex key1 5 value1</code></pre><p>上述命令实现了往redis中写入一个key1记录，并同时设定了5s后过期。如果在JAVA SpringBoot项目中可以直接使用相关API接口来实现：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">stringRedisTemplate.opsForValue().set(&quot;key1&quot;, &quot;value1&quot;, 5, TimeUnit.SECONDS);</code></pre><p>这样缓存写入5s之后，缓存记录就会过期失效。描述到这里可以看出，这是一种基于<em>创建时间</em>来判定是否过期的机制，也即常规上说的<code>TTL策略</code>，当设定了过期时间之后不管有没有被使用都会到期被强制清理掉。但有很多场景下也会期望数据能够按照<em>TTI</em>（指定时间未使用再过期）的方式来过期清理，如用户鉴权场景：</p><blockquote><p>假设用户登录系统后生成token并存储到Redis中，指定token有效期30分钟，那么如果用户一直在使用系统的时候突然时间到了然后退出要求重新登录，这个体验感就会很差。正确的预期应该是用户连续操作的时候就不要退出登录，只有连续30分钟没有操作的时候才过期处理。</p></blockquote><p>略有遗憾的是，Redis并<strong>不支持</strong>按照<em>TTI</em>机制来做数据过期处理。但是作为补偿，Redis提供了一个重新设定某个key值过期时间的方法，可以通过<code>expire</code>方法来实现指定key的续期操作，以一种曲线救国的方式满足诉求。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h3 id="实现缓存的续期"><a href="#实现缓存的续期" class="headerlink" title="实现缓存的续期"></a>实现缓存的续期</h3><p>通过<code>expire</code>命令，可以对已有的记录重新设定过期时间，如果此前已经有设定了过期时间，则覆盖原先的过期时间。</p><pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">expire key1 30</code></pre><p>执行上述命令，可以将key1的过期时间给重新设定为30s,不管此前是否有过期时间。同样地，在代码中也可以方便的实现这一命令：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">stringRedisTemplate.expire(&quot;key1&quot;, 30, TimeUnit.SECONDS);</code></pre><p>对于上面说的用户token续期的诉求，可以这样来操作：</p><blockquote><p>用户首次登录成功后，会生成一个token令牌，然后将令牌与用户信息存储到redis中，设定30分钟有效期。<br>每次请求接口中携带token来鉴权，每次get请求的时候，就重新通过expire操作将token的过期时间重新设定为30分钟。<br>持续30分钟无请求后，此条token缓存信息过期失效。</p></blockquote><p>同样实现了<code>TTI</code>的效果。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h3 id="实现指定时刻过期"><a href="#实现指定时刻过期" class="headerlink" title="实现指定时刻过期"></a>实现指定时刻过期</h3><p>Redis的过期时间设定，是基于当前命令执行时刻开始的<strong>相对过期时间</strong>，只能设定距离当前多久后失效，如果想要实现在<em>固定时刻</em>失效，还需要调用端执行一点小小的换算处理来实现。</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public void test() &#123;    LocalDateTime dateTime &#x3D; LocalDateTime.parse(&quot;2022-11-23 22:00:00&quot;, DateTimeFormatter.ofPattern(&quot;yyyy-MM-dd &quot; +            &quot;HH:mm:ss&quot;));    Date date &#x3D; Date.from(dateTime.atZone(ZoneId.systemDefault()).toInstant());    long expireTimeLong &#x3D; date.getTime() - System.currentTimeMillis();    stringRedisTemplate.expire(&quot;key1&quot;, expireTimeLong, TimeUnit.MILLISECONDS);&#125;</code></pre><p>通过计算出目标时刻与当前时刻的时间差值，作为过期时间设定到记录上，即可。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h2 id="数据淘汰策略"><a href="#数据淘汰策略" class="headerlink" title="数据淘汰策略"></a>数据淘汰策略</h2><p>前面强调过，Redis是一个基于<strong>内存</strong>的缓存数据库，而内存的容量通常是有限的。虽然Reids有提供数据过期处理逻辑，但是当数据量特别多的时候就需要<code>数据淘汰机制</code>来兜底了。</p><p>这里<code>数据淘汰</code>策略与<code>数据过期</code>两个概念的差异要先弄清楚：</p><ul><li><p><strong>数据过期</strong>，是符合业务预期的一种数据删除机制，为记录设定过期时间，过期后从缓存中移除。</p></li><li><p><strong>数据淘汰</strong>，是一种“<em>有损自保</em>”的<code>降级策略</code>，是业务预期之外的一种数据删除手段。指的是所存储的数据没达到过期时间，但缓存空间满了，对于新的数据想要加入内存时，为了避免OOM而需要执行的一种应对策略。</p></li></ul><p>试想下，把Redis当做一个容器，容器已满的情况下继续往里面放东西，应对之法其实就两种：</p><ol><li><p>直接拒绝放入。</p></li><li><p>扔掉容器中部分已有内容，腾出空间接纳新内容放入。</p></li></ol><p><img src="https://pics.codingcoder.cn/pics/202210051001463.png"></p><p>遵循上述认知，Redis提供了6种不同的数据淘汰机制，供使用方按需选择，将有限的空间仅用来存储热点数据，实现缓存的价值最大化。如下：</p><p><img src="https://pics.codingcoder.cn/pics/202210031841474.png"></p><p>对几种策略具体含义梳理归纳如下表所示：</p><table><thead><tr><th>数据淘汰策略</th><th>具体含义说明</th></tr></thead><tbody><tr><td>noeviction</td><td>淘汰新进入的数据，即<strong>拒绝新内容写入</strong>缓存，直到缓存有新的空间。</td></tr><tr><td>allkeys-lru</td><td>将内存中已有的key内容按照<code>LRU策略</code>将最久没有使用的记录淘汰掉，然后腾出空间用来存放新的记录。</td></tr><tr><td>volatile-lru</td><td>从设置了过期时间的key里面按照LRU策略，淘汰掉最久没有使用的记录。与allkeys-lru相比，这种方式仅会在设定了过期时间的key里面进行淘汰。</td></tr><tr><td>allkeys-random</td><td>从已有的所有key里面<strong>随机</strong>剔除部分，腾出空间容纳新数据。</td></tr><tr><td>volatile-random</td><td>从已有的设定了过期时间的key里面随机剔除部分，腾出空间容纳新的数据</td></tr><tr><td>volatile-ttl</td><td>从已有的设定了过期时间的key里面，将最近将要过期的数据提前剔除掉，与volatile-lru的区别在于排序逻辑不一样，一个基于<em>ttl</em>规则排序，一个基于<em>lru</em>策略排序。</td></tr></tbody></table><p>从上述策略里面可以看出，根据<code>LRU</code>和<code>Random</code>两种操作的范围不同，各自又细分了两种不同的执行策略。</p><ul><li><strong>从设定过期时间的key里进行淘汰</strong></li></ul><p>相对来说，设定了过期时间的数据，说明业务层面已经默许了其可以被删除，所以即使被提前淘汰了，对业务层面的影响也是比较小的。</p><blockquote><p>系统中缓存最近30分钟的用户浏览历史记录，即使这些数据被删除淘汰，对系统主体功能而言，不会受损。</p></blockquote><ul><li><strong>从全量key里面执行淘汰</strong></li></ul><p>从全量数据里面执行淘汰，就有可能淘汰掉没有设置过期时间的key记录。未设置过期时间的数据如果数据被淘汰掉，很有可能会影响业务的运行逻辑逻辑正确性。</p><blockquote><p>缓存中存储了系统内的黑名单用户列表，用户鉴权的时候，会判断用户是否在黑名单中，如果在黑名单中则禁止登录。这个黑名单是永久的，不会自己解封。如果由于被动淘汰策略触发删除部分黑名单，那原先的黑名单用户就会不受限制而进入到系统中，导致预期之外的情况发生。</p></blockquote><p>不得不说，Redis的这一细分处理原则，还是很贴心的。具体实践中，可以根据自身系统内存储的数据体量以及存储的数据内容性质，选择合适的数据淘汰策略。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h2 id="数据持久化方案"><a href="#数据持久化方案" class="headerlink" title="数据持久化方案"></a>数据持久化方案</h2><p>除了容量有限之外，存储在内存中的数据最大的风险点是什么？数据丢失！</p><p>因为内存中的数据是非持久化存储的，一旦断电或者出现系统异常等情况，很容易导致内存数据丢失。所以大部分的系统里面都只是将内存型缓存用作数据库的辅助扛压，最终的数据存储在DB等可以持久化存储容器中，同步一份数据到缓存中用于并发场景下的业务使用。</p><p><img src="https://pics.codingcoder.cn/pics/202211232247563.png"></p><p>这种组网场景下，Redis的数据其实是没有持久化的诉求的，因为Redis中数据仅仅是一份副本，最终数据在DB中都有。即使系统异常或者掉电重启，也可以基于数据库的数据进行缓存重建 —— 最多就是数据量特别巨大的时候，重建缓存的耗时会比较长。</p><p>另外一种场景，业务里面会有有些写操作会比较频繁、强依赖Redis特性来实现的功能，这部分数据不能丢、但又没有重要到必须每次更新都需要存入DB的地步。比如博客系统中的文章阅读量数据，文章每次被读取都需要更新阅读数，写操作非常频繁，如果阅读量存储到DB中，会导致DB压力较大，这种情况就希望可以将数据存储在内存中，然后内存数据可以持久化保存。</p><p><img src="https://pics.codingcoder.cn/pics/202211232251229.png"></p><p>Redis提供了多种<strong>持久化</strong>方案，可以实现将内存数据定期存储到磁盘上，重启时候可以从磁盘加载到内存中，以此来避免数据的丢失。</p><p>下面一起看下。</p><h3 id="RDB全量持久化模式"><a href="#RDB全量持久化模式" class="headerlink" title="RDB全量持久化模式"></a>RDB全量持久化模式</h3><p>全量模式很好理解，就是定时将当前内存里面所有的key-value键值对内容，全部导出一份快照数据存储到磁盘上。这样下次如果需要使用的时候，就可以从磁盘上加载快照文件，实现内存数据的恢复。</p><p><strong>RDB全量模式</strong>持久化将数据写入磁盘的动作可以分为<code>SAVE</code>与<code>BGSAVE</code>两种。所谓BGSAVE就是background-save，也就是后台异步save，区别点在于SAVE是由Redis的<strong>命令执行线程</strong>按照普通命令的方式去执行操作，而BGSAVE是通过fork出一个新的进程，在新的<strong>独立进程</strong>里面去执行save操作。</p><p><img src="https://pics.codingcoder.cn/pics/202211232302953.png"></p><p>还记得前面文章中说的么？Redis的请求命令执行是通过单线程的方式执行的，所以要尽量避免耗时操作，而save动作需要将内存全部数据写入到磁盘上，对于redis而言，这一操作是<em>非常耗时</em>的，会阻塞住全部正常业务请求，所以save操作的触发只有两个场景：</p><ol><li>客户端手动发送save命令执行</li><li>Redis在shutdown的时候自动执行</li></ol><p>从数据保存完备性方面看，这两种方式都起不到自动持久化备份的能力，如果出现一些机器掉电等情况，是不会触发redis shutdown操作的，将面临数据丢失的风险。</p><p>相比而言，<code>bgsave</code>的杀伤力要小一些、适用度也更好一些，它可以保证在持久化期间Redis主进程可以继续处理业务请求。bgsave增加了过程中自动持久化操作的机制，触发条件更加的“智能”：</p><ol><li>客户端手动命令触发bgsave操作</li><li>Redis配置<em>定时</em>任务触发（支持间隔时间+变更数据量双重维度综合判断，达到任一条件则触发）</li></ol><p>此外，在master-slave主从部署的场景中还支持仅由slave节点触发bgsave操作，来降低对master节点的影响。值得注意的是，在fork子进程的时候需要将redis主进程中内存所有数据都复制一份到子进程中，所以<code>bgsave</code>操作实际上是将子进程内存中的数据快照导出到磁盘上，在执行期间对机器的剩余内存有较高要求，如果机器剩余内存不足，则可能导致fork的时候两份内存数据量超过机器物理内存大小，导致系统启用虚拟内存，拷贝速度大打折扣（虚拟内存本质上就是把磁盘当内存用，操作速度相比物理内存大大降低），会阻塞住Redis主进程的命令执行。</p><p><img src="https://pics.codingcoder.cn/pics/202211240717798.png"></p><p>如果开启了RDB的bgsave定时触发执行机制，在出现异常掉电等情况，可能会丢失最后一部分尚未来及持久化的内容。在恢复的时候，Redis启动之后会先去读取RDB文件然后将其写入内存中恢复此前的缓存数据，数据恢复期间不受理外部业务请求。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h3 id="AOF增量同步方式"><a href="#AOF增量同步方式" class="headerlink" title="AOF增量同步方式"></a>AOF增量同步方式</h3><p>RDB全量模式简单粗暴，直接将内存全量数据存储为快照序列化到本地。<code>AOF</code>（Append Only File）与RDB的思路不同，AOF更像是记录住Redis的每一次<em>写请求</em>执行命令，将每次执行的写操作命令记录存储到磁盘上，然后通过一种类似<strong>命令重放</strong>执行的方式，来实现数据的恢复。</p><p><img src="https://pics.codingcoder.cn/pics/202211232326039.png"></p><p>AOF具体实现的时候，包含几种不同的策略：</p><ul><li><strong>always</strong></li></ul><p>可以简单的理解为每一条redis写请求执行的时候会触发一次磁盘写入操作，且只有在磁盘写入完成之后，请求的响应才会返回。这种方式可以保证AOF记录的准确性，但是会严重影响Redis的并发吞吐量。</p><ul><li><strong>every sec</strong></li></ul><p>异步执行，任务执行线程执行命令后将命令写入任务放入队列中，由子线程异步方式每秒一次将执行命令分批写入文件中，相比always方式在异常情况下可能会丢失最后1s的执行记录，但可以大大降低对redis命令执行效率的影响。</p><ul><li><strong>no</strong></li></ul><p>redis不控制落盘时间，由操作系统去决定什么时候该往磁盘flush，这种情况一般不推荐使用，无法准确掌控是否落盘，可靠性不够。</p><p>AOF的方式落盘持久化的时候，每次仅写入增量的部分，所以对系统整体运行期的影响较小，但随着系统在线运行时长的累加，AOF中存储的命令也越来越多，这样问题也随着出现：</p><ol><li>AOF写入的方式类似与日志打印，将请求追加写入到磁盘文件中，文本文件未经过压缩，时间久了之后会占据大量<strong>磁盘空间</strong>，易造成磁盘满的问题。</li><li>在需要从AOF文件回放重新构建缓存内容时，可能会<strong>耗时较久</strong>（相当于要将长期累积下来的写操作命令逐个重新执行一下）。</li></ol><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h3 id="RDB与AOF混合使用"><a href="#RDB与AOF混合使用" class="headerlink" title="RDB与AOF混合使用"></a>RDB与AOF混合使用</h3><p>从前面的介绍中可以看出：</p><ul><li><p>RDB在过程中每次写磁盘的时候对Redis业务处理的性能影响较大，但是从磁盘加载到内存重建缓存的时候效率很高。</p></li><li><p>AOF通过增量的方式降低了运行过程中对Redis业务处理的影响，但是命令回放重建缓存的时候效率较差。</p></li></ul><p>如果将两者结合起来使用，是否可以取长补短呢？事实似乎的确如此。从<em>4.0</em>版本开始，Redis支持了<code>RDB + AOF</code>的混合持久化方式，通过<code>rewrite</code>机制来实现。需要在redis的配置文件中开启对应开关：</p><pre class="line-numbers language-properties" data-language="properties"><code class="language-properties">aof-use-rdb-preamble yes</code></pre><p>开启之后，redis在每次执行aof操作的时候会判断下是否达到了触发rewrite的条件，如果达到，则fork出一个新的子进程进行RDB操作将当前时刻全量内存数据生成RDB数据然后写入到AOF文件中，而后续的写操作命令则继续append方式追加记录到AOF文件中。这样一来AOF文件实际上由两部分内容组成。如下图所示：</p><p><img src="https://pics.codingcoder.cn/pics/202211240832168.png"></p><p>通过RDB + AOF混合的策略，很好的实现了两者的优势互补：</p><ol><li>先通过AOF的方式记录命令，达到门槛的时候才执行rewrite操作生成RDB，最大限度降低了RDB执行频率，降低了对redis业务命令处理过程的影响。</li><li>通过RDB的方式替代了前期大量的AOF命令存储，有效的降低了磁盘占用。</li><li>通过RDB + AOF的方式，系统重建缓存的时候，先加载RDB文件完成主体数据的重建，然后在此基础上重放AOF增量命令，大大降低了启动时AOF重放的耗时。</li></ol><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h2 id="小结回顾"><a href="#小结回顾" class="headerlink" title="小结回顾"></a>小结回顾</h2><p>好啦，关于Redis的<code>数据过期</code>设定、数据<code>淘汰机制</code>以及数据<code>持久化策略</code>等方面的问题，就讨论到这里了。那么你对Redis是否有了新的了解呢？你觉得Redis的哪个方面特性最打动了你呢？欢迎评论区一起交流下，期待和各位小伙伴们一起切磋、共同成长。</p><p>📣 <strong>补充说明</strong> ：</p><blockquote><p>本文属于《<a href="https://juejin.cn/column/7140852038258147358">深入理解缓存原理与实战设计</a>》系列专栏的内容之一。该专栏围绕缓存这个宏大命题进行展开阐述，全方位、系统性地深度剖析各种缓存实现策略与原理、以及缓存的各种用法、各种问题应对策略，并一起探讨下缓存设计的哲学。</p><p>如果有兴趣，也欢迎关注此专栏。</p></blockquote><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><p><strong>我是悟道，聊技术、又不仅仅聊技术~</strong></p><p>如果觉得有用，请<strong>点赞 + 关注</strong>让我感受到您的支持。也可以关注下我的公众号【架构悟道】，获取更及时的更新。</p><p>期待与你一起探讨，一起成长为更好的自己。</p><p><img src="https://pics.codingcoder.cn/pics/202207091312091.gif"></p><p><img src="https://pics.codingcoder.cn/pics/202207091317876.png"></p>]]></content>
      
      
      <categories>
          
          <category> 缓存原理与实战设计 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JAVA </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis缓存何以一枝独秀？——从百变应用场景与热门面试题中感受下Redis的核心特性与使用注意点</title>
      <link href="//post/20230110072917.html"/>
      <url>//post/20230110072917.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>在分布式盛行的今天，本地缓存明显无法满足分布式场景的缓存诉求。作为应对之法，集中式缓存被广泛的使用在各中分布式系统中，而使用最广泛的莫过于大家耳熟能详的Redis了，本篇开始聊一聊Redis相关的内容。</p></blockquote><hr><p><img src="https://pics.codingcoder.cn/pics/202210050807355.png"></p><p>大家好，又见面了。</p><hr><blockquote><p>本文是笔者作为掘金技术社区签约作者的身份输出的缓存专栏系列内容，将会通过系列专题，讲清楚缓存的方方面面。如果感兴趣，欢迎关注以获取后续更新。</p></blockquote><hr><p>作为《<a href="https://juejin.cn/column/7140852038258147358">深入理解缓存原理与实战设计</a>》系列专栏，在前面的文章中，我们一起领略了Guava Cache、Caffeine、Ehcache等优秀的本地JVM级别本地缓存框架的特性、原理与具体的使用方法。除却本地缓存之外，在当前分布式、微服务等架构盛行的时代，<strong>本地缓存</strong>明显<em>无法满足</em>大型系统中的各种缓存诉求，比如前面文章中反复提及的<strong>缓存漂移</strong>问题、以及单机缓存无法逾越的<strong>内存容量</strong>瓶颈。作为应对之法，<strong>集中式缓存</strong>被广泛的使用在各中分布式系统中，而使用最广泛的莫过于大家耳熟能详的<code>Redis</code>了。</p><p><img src="https://pics.codingcoder.cn/pics/202211222143844.png"></p><p>提到Redis，大家应该都不会陌生，至少应该是有听过这个名字。在中大型分布式系统中，Redis似乎成了一种标配，而说到集中缓存，很多人脑海中第一闪过的也是Redis。<code>Redis</code>是一个基于内存的非关系型数据库（<em>NoSQL</em>），主要是存储key-value类型的键值对数据，而value则支持多种不同的类型。由于其强悍的性能表现以及完善的可靠性与集群扩展机制，使其俘获了众多开发人员的青睐，成为了高并发系统的制胜法宝。接下来的几篇文章中呢，我们就一起聊一聊与Redis有关的内容，探讨下Redis在集中式缓存领域一枝独秀的秘诀。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h2 id="Redis的各种数据类型"><a href="#Redis的各种数据类型" class="headerlink" title="Redis的各种数据类型"></a>Redis的各种数据类型</h2><p>作为缓存组件，Redis的数据结构整体而言就是<code>key-value</code>类型的键值对，但是Redis对于value类型的支持还是比较丰富的，提供了<strong>5种</strong>不同的数据结构，可以满足大部分场景的使用诉求。</p><p><img src="https://pics.codingcoder.cn/pics/202211222151588.png"></p><p>对几种类型的结构特点与使用注意点梳理汇总如下：</p><table><thead><tr><th>类型</th><th>说明</th><th>支持功能</th></tr></thead><tbody><tr><td>string</td><td>普通字符串</td><td>字符串的基础增删改查能力，如果是整数或者浮点数，还支持<em>自增自减</em>能力。</td></tr><tr><td>list</td><td>链表内容，每个元素都是一个独立的字符串，内容可以相同</td><td>基础增删改查能力，从链表两端插入或者弹出元素，按照下标获取指定元素列表等等</td></tr><tr><td>set</td><td>无序集合，每个元素都是一个独立字符串，元素之间不允许重复</td><td>基础增删改查能力，判断元素是否存在，随机获取元素等等</td></tr><tr><td>hash</td><td>无序的key-value键值对集合</td><td>基础增删改查能力，获取所有的键值对</td></tr><tr><td>zset</td><td>可以理解为一种比较特殊的hash结构，含有member和score两个概念，对应到hash类型上分别是key与value的关系，其区别点在在于score是固定的double类型的value</td><td>基础增删改查能力，支持根据score排序并获取指定的排序个数的元素列表</td></tr></tbody></table><p>实际的使用中，也会根据各自类型不同的特点，用来实现不同的业务诉求。</p><p>举个例子：</p><blockquote><p>一个系统内的通知公告查看功能，可以将公告ID作为key，然后这边通知公告的阅读量作为score，在redis中存储为zset类型，然后每次读取详情操作的都累加更新下对应的score值，这样的话，就可以根据score进行降序排列，拉取到热门新闻公告的排行榜。</p></blockquote><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h2 id="Redis的百变应用场景"><a href="#Redis的百变应用场景" class="headerlink" title="Redis的百变应用场景"></a>Redis的百变应用场景</h2><p>基于Redis提供的基础能力，在项目中不同场景都有被广泛的使用，下面列举几个常见的使用场景。</p><ul><li><strong>分布式锁</strong></li></ul><p>在分布式系统里面经常会需要用到分布式锁，实现分布式锁的方式有很多种，其中使用的比较广泛的一种策略，就是基于Redis来实现的。之所以采用Redis来作为分布式锁，可以有几方面理由：</p><ol><li>redis足够的快</li><li>redis提供了<code>setnx + expire</code>的机制，完全契合分布式锁的实现要点</li><li><code>Redisson</code>客户端的流行，使得基于redis的分布式锁更加简单</li></ol><ul><li><strong>数据库扛压层</strong></li></ul><p>借助redis超高的处理性能，经常会被放置在数据库的前面，用于数据扛压场景使用。比如各种<strong>秒杀</strong>场景，可以将数据库中的库存信息缓存到redis中，然后利用redis来抗住秒杀期间洪水般的大并发量请求。</p><ul><li><strong>登录验证码存储</strong></li></ul><p>这个场景也很常见，比如用户发送的短信验证码，一般都会要求5分钟内有效。这种情况下，可以将验证码信息存储在redis中并设定5分钟后自动过期。这样的话就可以实现超时失效的功能，而无需业务层面去维护过期信息。</p><ul><li><strong>全局ID生成&amp;全局限流</strong></li></ul><p>在分布式系统中，Redis作为一个可以被所有节点访问的集中节点，加上其具备的<code>incrby</code>原子命令，使得在多个场景下发挥价值：</p><ol><li><p>将其用作<strong>全局唯一ID</strong>的生成，以保证各个节点之间生成的唯一ID不会冲突。</p></li><li><p>incrby可以实现全局请求量的统计计数，结合expire一起可以实现定时重置计数器，进而实现<strong>限流能力</strong>。</p></li></ol><ul><li><strong>bitmap方式存储每日签到数据</strong></li></ul><p>其实，Redis还支持位图（<code>Bitmap</code>）格式进行数据存储。前面我们说Redis支持五种数据结构里面并没有看到Bitmap类型的身影，其实Redis的bitmap数据最终存储的是string类型，但是Redis为Bitmap操作提供了配套的操作接口，比如<code>setbit</code>命令。</p><p>位图的存在就是为了服务于<strong>海量数据</strong>的存储场景的，比如系统里面有10亿用户，现在需要记录每个人每天的签到情况，每天10亿数据量，如果用普通String类型存储，每天10亿条数据量，时间一久任何的Redis也扛不住。而基于bitmap的方式存储，则可以极大的降低整体数据量。关于redis的bitmap操作与使用，后面文章会展开阐述。</p><ul><li><strong>热门榜单生成</strong></li></ul><p>基于Redis的<code>zset</code>数据结构，可以将热门值作为score进行存储，这样可以根据需要，按照score进行排序并拉取榜单数据。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h2 id="后端面试中的常客"><a href="#后端面试中的常客" class="headerlink" title="后端面试中的常客"></a>后端面试中的常客</h2><p>这篇文章中，我们改变下以往的文章行文叙事风格。我们先不直接切入到Redis的具体特性或功能点的实现原理与使用层面，而是先从面试场景作为切入口，通过几个面试问题，来感受下Redis整体的“魅力”、引出Redis所具备的核心特性与常见使用注意事项。</p><p>因为Redis在项目中的广泛使用，也让其成为了后端面试中的热门嘉宾。很多小伙伴应该在面试中都被问过与Redis有关的问题吧？当然有很多的八股文背诵一下就可以应付很多简单的面试场景，但笔者作为面试官一般不太会直接去问八股文问题，经常会将问题稍作包装之后再去问。</p><p>下面举几个例子。</p><p><strong>Q1. 很多人都说Redis处理快是因为它是单线程的，Redis进程中真的只有一个线程吗？为什么常规项目中为了提升并发量都会采用线程池等方式来多线程处理，而Redis却反其道而行之呢？</strong></p><p>很多的面试八股文中都会提到说Redis是单线程的，这个说法其实<strong>不够严谨</strong>，因为Redis中并非是只有一个线程，整个进程中还有一些额外的线程负责做一些辅助的其他事务，比如管理与客户端的连接，比如队列中消息的维护等等。</p><p>Redis整体基于一种多路复用的机制来实现请求的接收与分配处理。整体简化后的处理逻辑如下图所示。</p><p><img src="https://pics.codingcoder.cn/pics/202211222220863.png"></p><p>所以说，其实Redis仅仅是采用单线程来负责执行命令请求处理，而非整个Redis就是一个单线程的。回到最初的问题，为什么Redis选择采用单线程的方式来执行命令。在多线程编程的时候面临问题主要有：</p><ul><li><strong>并发线程安全问题</strong>， 需要保证操作的先后顺序，需要保证同一时刻只能有1个线程对某个对象进行写操作 —— 需要构建完备的同步保护机制，会对整体性能造成影响。</li><li><strong>多线程维护的系统额外开销</strong> —— CPU需要不停的在多个线程之间进行切换，由此会带来一系列的额外开销。</li></ul><p>而由于Redis是一种key-value模型的数据结构模式，比如很多查询操作都是<code>O(1)</code>的时间复杂度，其操作执行速度非常快，所以这种情况下，结合<code>I/O多路复用</code>模型一起，使用单线程的方式执行命令，反而可以达到比多线程更加优异的表现。</p><p>问题可以进一步引申，可以继续聊一些其他问题。比如：</p><ul><li><p>既然Redis是单线程的，那使用的时候有什么需要注意的事项吗？<br>不能执行耗时操作，会阻塞其余请求命令的执行。</p></li><li><p><em>I&#x2F;O多路复用</em>是个什么概念？它和<em>BIO</em>、<em>NIO</em>之间有什么异同？<br>诸如此类的问题，都可以进一步的去展开考察。</p></li><li><p>当前计算机一般都是多核CPU，用单线程去执行的话，相当于其它几个核就浪费了，那有什么方式可以将其余的几个核也利用起来么？<br>答案其实也不难，在一台机器上同时去部署多个Redis进程，组成个集群，就可以啦。</p></li></ul><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><p><strong>Q2. 如果我想要查询一下生产环境的Redis中有多少以“User_”开头的记录数量，可以怎么做？</strong></p><p>这个问题其实是有一点小陷阱的。查找以指定前缀开头的记录，首先很多同学想到的就是<code>keys</code>命令，但问题中有个约束是在生产环境中执行。所以这个问题看似简单，其实需要结合如下几点来综合考虑：</p><ol><li>通常情况下，生产环境中的数据量是非常大的、且请求并发量会比较高；</li><li>Redis的<code>keys</code>命令是一个耗时操作，复杂度<code>O(n)</code>，数据量越大执行速度越慢；</li><li>Redis的命令执行是单线程执行的。</li></ol><p>基于上述几点因素，如果在数据量较大的生产环境去执行<code>keys</code>命令将会导致执行耗时特别长，而由于Redis是单线程执行命令，就会导致其余请求命令被阻塞无法执行，这样在一个高并发集群内，很容易造成集群内请求的大面积阻塞，影响系统的整体稳定性。</p><p>那么keys命令不可以用，有什么替代方案呢？可以使用<code>scan</code>命令。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><p><strong>Q3. 假如有一批机器，内存都比较小（单机内存小于整体待缓存数据量），用来搭建个Redis做热点数据缓存扛压以降低数据库的请求压力。如果你来做的话，会有哪些应对思路呢？</strong></p><p>这个问题就比较开放，而且答案也不唯一，考核的点也比较综合。</p><p>首先来分析下题目，从题干描述中可以捕捉到几个信息，以及对应的关联知识点：</p><ol><li>单机内存小于整体数据量，所以想要将所有数据全量加载到单机内存里面是不可行的；</li><li>使用Redis的用途是扛压来降低数据库访问压力的，也就是允许部分请求穿透Redis打到数据库上的，所以可以考虑将有限内存用来存放<code>热点数据</code>，扛住大部分的流量；</li><li>题目说有一批机器，就是说机器的数量不止一台，所以可以考虑构建<code>集群</code>的方式，扩展Redis集群总内存大小，这样以集群的力量来缓存全部的数据量。</li></ol><p>所以说这个题目里面其实涉及到了两个考点：</p><ol><li><strong>热点数据</strong>的概念、也即Redis的数据淘汰策略。</li><li>Redis<strong>集群扩展</strong>的相关概念。</li></ol><p>更进一步，又可以引申出很多其它细节问题，比如：</p><ul><li><p><em>Redis中的数据淘汰策略有哪些？</em><br>no-enviction、volatile-lru、volatile-ttl、volatile-random、allkeys-lru、allkeys-random</p></li><li><p><em>Redis的数据淘汰策略与数据过期有啥区别？</em><br>数据过期是达到了设定的过期时间之后使数据不可用，而数据淘汰策略主要是在容量满之后采取的被动应对策略。</p></li><li><p><em>Redis集群中是如何决定一个记录应该保存在哪个节点上的？</em><br>关于<strong>一致性Hash</strong>相关的内容，以及如何解决数据<code>倾斜问题</code>、节点扩容对缓存命中情况的影响等等。</p></li></ul><p>回头看下，是不是其中蕴含的内容还是蛮多的？</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><p>这里我们以面试场景中会被问及的几个问题作为切入点，大概聊了下与Redis有关的一系列内容。当然这里介绍的都比较浅显，甚至只是列了下相关的知识点，主要是先让大家先感受下Redis所包含与涉及的相关知识点。在后续的文章中，我们将逐步逐个地去剖析与介绍。</p><h2 id="小结回顾"><a href="#小结回顾" class="headerlink" title="小结回顾"></a>小结回顾</h2><p>好啦，作为redis部分的第一篇内容，我们只是简单的聊了下<code>Redis</code>的基础概念以及主要的特性介绍，同时通过几个实际的面试题演示了下Redis整体内容的“<em>博大精深</em>”。而关于Redis的更多细化方向的展开阐述，我们将会在后续文章中逐步介绍。那么你对Redis如何看呢？欢迎评论区一起交流下，期待和各位小伙伴们一起切磋、共同成长。</p><p>📣 <strong>补充说明1</strong> ：</p><blockquote><p>本文属于《<a href="https://juejin.cn/column/7140852038258147358">深入理解缓存原理与实战设计</a>》系列专栏的内容之一。该专栏围绕缓存这个宏大命题进行展开阐述，全方位、系统性地深度剖析各种缓存实现策略与原理、以及缓存的各种用法、各种问题应对策略，并一起探讨下缓存设计的哲学。</p><p>如果有兴趣，也欢迎关注此专栏。</p></blockquote><p>📣 <strong>补充说明2</strong> ：</p><ul><li>关于本文中涉及的<strong>演示代码</strong>的完整示例，我已经整理并提交到github中，如果您有需要，可以自取：<a href="https://github.com/veezean/JavaBasicSkills">https://github.com/veezean/JavaBasicSkills</a></li></ul><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><p><strong>我是悟道，聊技术、又不仅仅聊技术~</strong></p><p>如果觉得有用，请<strong>点赞 + 关注</strong>让我感受到您的支持。也可以关注下我的公众号【架构悟道】，获取更及时的更新。</p><p>期待与你一起探讨，一起成长为更好的自己。</p><p><img src="https://pics.codingcoder.cn/pics/202207091312091.gif"></p><p><img src="https://pics.codingcoder.cn/pics/202207091317876.png"></p>]]></content>
      
      
      <categories>
          
          <category> 缓存原理与实战设计 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JAVA </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JAVA中使用最广泛的本地缓存？Ehcache的自信从何而来3 —— 本地缓存变身分布式集群缓存，打破本地缓存天花板</title>
      <link href="//post/20230107070417.html"/>
      <url>//post/20230107070417.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>作为JAVA本地缓存综合实力天花板的Ehcache，还提供了对于集群能力的支持，这也使其不仅仅是个单机缓存，更是一个分布式缓存。本篇一起探讨Ehcache的各种集群方案。</p></blockquote><hr><p><img src="https://pics.codingcoder.cn/pics/202210050807355.png"></p><p>大家好，又见面了。</p><hr><blockquote><p>本文是笔者作为掘金技术社区签约作者的身份输出的缓存专栏系列内容，将会通过系列专题，讲清楚缓存的方方面面。如果感兴趣，欢迎关注以获取后续更新。</p></blockquote><hr><p>上一篇文章中，我们知晓了如何在项目中通过不同的方式来<strong>集成Ehcache</strong>并在业务逻辑中进行使用。作为JAVA本地缓存框架综合实力天花板级别的Ehcache，除了在本地缓存方面具有强悍的实力外，还具有一个其它对手所不具备的特色功能，即Ehcache提供了对于<strong>集群能力</strong>的支持，这也使得Ehcache不仅仅是个本地单机缓存，更是一个分布式缓存。</p><p>分布式缓存的意义是什么？集群方案又可以解决哪些问题？它与单机缓存有啥区别？与Redis等集中式缓存有啥不同？如何去选择、又该如何使用？带着这一连串的疑问，让我们一起探讨下Ehcache的各种不同集群方案，找出上述问题的答案。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h2 id="本地缓存或者集中缓存的问题"><a href="#本地缓存或者集中缓存的问题" class="headerlink" title="本地缓存或者集中缓存的问题"></a>本地缓存或者集中缓存的问题</h2><p>在正式开始阐述Ehcache的集群解决方案前，先来做个铺垫，了解下单机缓存与集中式缓存各自存在的问题。</p><h3 id="单机缓存不可言说的痛"><a href="#单机缓存不可言说的痛" class="headerlink" title="单机缓存不可言说的痛"></a>单机缓存不可言说的痛</h3><p>对于<strong>单机缓存</strong>而言，缓存数据维护在进程中，应用系统部署完成之后，各个节点进程就会自己维护自己内存中的数据。在集群化部署的业务场景中，各个进程独自维护自己内存中的数据，而经由负载均衡器分发到各个节点进行处理的请求各不相同，这就导致了进程内缓存数据不一致，进而出现各种问题 —— 比较典型的就是<em>缓存漂移</em>问题。</p><p>缓存漂移，是单机缓存在分布式系统下无法忽视的一个问题。在这种情况下，大部分的项目使用中会选择避其锋芒、或者自行实现同步策略进行应对。常见的策略有：</p><ul><li><p>本地缓存中仅存储一些固定不变、或者不常变化的数据。</p></li><li><p>通过过期重新加载、定时refresh等策略定时更新本地的缓存，忍受数据有一定时间内的<em>不一致</em>。</p></li><li><p>对于少量更新的场景，借助MQ构建<em>更新机制</em>，有变更就发到MQ中然后所有节点消费变更事件然后更新自身数据。</p></li></ul><p><img src="https://pics.codingcoder.cn/pics/202211201115080.png"></p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h3 id="集中式缓存也并非万能银弹"><a href="#集中式缓存也并非万能银弹" class="headerlink" title="集中式缓存也并非万能银弹"></a>集中式缓存也并非万能银弹</h3><p>在集群部署的场景下，为了简化缓存数据一致性方面的处理逻辑，大部分的场景会直接选择使用Redis等<strong>集中式缓存</strong>。集中式缓存的确是为分布式集群场景而生的，通过将缓存数据集中存放，使得每个业务节点读取与操作的都是同一份缓存记录。这样只需要由缓存服务保证并发原子性即可。</p><p><img src="https://pics.codingcoder.cn/pics/202211201114951.png"></p><p>但集中式缓存也并非是分布式场景下缓存方案的万能银弹。</p><p>项目中使用缓存的目的，主要是为了提升整体的运算处理效率，降低对外的IO请求等等。而集中式缓存是独立于进程之外部署的远端服务，需要基于<em>网络IO交互</em>的方式来获取，如果一个业务逻辑中涉及到非常频繁的缓存操作，势必会导致引入大量的网络IO交互，进而导致非常严重的<strong>性能损耗</strong>。</p><p>为了解决这个问题，很多时候还是需要本地缓存结合集中式缓存的方式，构建<code>多级缓存</code>的方式来解决。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h2 id="Ehcache分布式集群方案"><a href="#Ehcache分布式集群方案" class="headerlink" title="Ehcache分布式集群方案"></a>Ehcache分布式集群方案</h2><p>相比纯粹的本地缓存，<strong>Ehcache自带集群解决方案</strong>，通过相应的配置可以让本地缓存变身集群版本，以此来应付分布式场景下各个节点缓存数据不一致的问题，并且由于数据都缓存在进程内部，所以也可以避免集中是缓存频繁在业务流程中频繁网络交互的弊端。</p><p>Ehcache官方提供了多种集群方案供选择，下面一起看下。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h3 id="RMI组播"><a href="#RMI组播" class="headerlink" title="RMI组播"></a>RMI组播</h3><p><code>RMI</code>是一种点对点（P2P）的通信交互机制，Ehcache利用RMI来实现多个节点之间数据的互通有无，相互知会彼此更新数据。对于集群场景下，这就要求集群内所有节点之间要两两互通，组成一张网状结构。</p><p><img src="https://pics.codingcoder.cn/pics/202211201155815.png"></p><p>在集群方式下进行数据通信交互，要求被传输的数据一定是要<em>可序列化与反序列化</em>的，对于JAVA而言，直白的说，就是对象一定是要实现了<code>Serializable</code>接口。</p><p>基于RMI组播的方式，Ehcache会向对应地址发送<code>RMI UDP</code>组播包，由于Ehcache对于组播的实现较为简单，所以在一些网络情况较为复杂的场景的支持度不是很完善，方案选择的时候需注意。此外，由于是即时消息模式，如果中途某个进程由于某些原因不可达，也可能会导致同步消息的丢失。所以对于可靠性以及数据一致性要求较高的场景需要<strong>慎选</strong>。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h3 id="JMS消息"><a href="#JMS消息" class="headerlink" title="JMS消息"></a>JMS消息</h3><p><code>JMS</code>消息方案是一种很常用的Ehcache集群方案。JMS是一套JAVA中两个进程之间的<em>异步通信API</em>，定义了消息通讯所必须的一组通用能力接口，比如消息的创建、发送、接收读取等。</p><p>JMS也支持构建基于事件触发模型的消息交互机制，也即生产者消费者模式（又称<em>发布订阅模式</em>），其核心就是一个消息队列，集群内各个业务节点都订阅对应的消息队列topic主题，如果有数据变更事件，也发送到消息队列的对应的topic主题下供其它节点消费。</p><p><img src="https://pics.codingcoder.cn/pics/202211201143419.png"></p><p>相比于RMI组播方式，JMS消息方式有个很大的优势在于不需要保证所有节点都全部同时在线，因为是基于发布订阅模式，所以即使有节点中途某些原因宕机又重启了，重启之后仍然可以接收其他节点已发布的变更，然后保证自己的缓存数据与其它节点一致。</p><p>Ehcache支持对接多种不同的MQ来实现基于JMS消息的集群组网方案，默认使用<code>ActiveMQ</code>，也可以切换为<code>Kafka</code>或者<code>RabbitMQ</code>等消息队列组件。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h3 id="Cache-Server模式"><a href="#Cache-Server模式" class="headerlink" title="Cache Server模式"></a>Cache Server模式</h3><p>Ehcache的<code>Cache Server</code>是一种比较特殊的存在形式，它通常是一个独立的进程进行部署，然后多个独立的进程之间组成一个分布式集群。Cache Server是一个纯粹的缓存集群，对外提供<em>restful</em>接口或者<em>soap</em>接口，各个业务可以通过接口来获取缓存 —— 这个其实已经不是本地进程内缓存的概念了，其实就是一个独立的集中式缓存，类似Redis般的感觉。</p><p>看一下一个典型的高可用水平扩容模式的Cache Server组网与业务调用的场景示意图：</p><p><img src="https://pics.codingcoder.cn/pics/202211212206985.png"></p><p>可以看到不管业务模块是用的什么编码语言，或者是什么形态的，都可以通过http接口去访问缓存数据，而Cache Server就是一个集中式缓存。在Cache Server中，集群内部可以有一个或者多个节点，这些节点具有完全相同的数据内容，做到了数据的冗余备份，而集群之间数据可以不同，实现了数据容量的水平扩展。</p><p>值得注意的一点是，如果你访问Ehcache的官网，会发现其官方提供的<code>3.x版本</code>的说明文档中<strong>不再有Cache Server的身影</strong>，而在2.x版本中都会作为一个单独的章节进行介绍。为什么在3.x版本中不再提供Cache Server模式呢？我在官方文档中没找到相关的说明，个人猜测主要有下面几个原因：</p><ul><li><p><em>定位过于尴尬</em>，如果说要作为集中式缓存来使用，完全可以直接使用redis，没有必要费事劳神的去搭建Cache Server</p></li><li><p><code>Terracotta</code>方式相比而言功能上更加的完备，兼具水平扩展与本地缓存的双重优势，<em>完全可以取代Cache Server</em></p></li></ul><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h3 id="JGroups方式"><a href="#JGroups方式" class="headerlink" title="JGroups方式"></a>JGroups方式</h3><p><code>JGroups</code>的方式其实和RMI有点类似。JGroups是一个开源的群组通讯工具，可以用来创建一个组，这个组中的成员可以给其他成员发送消息。其工作模式基于IP组播（IP multicast），但可以在可靠性和群组成员管理上进行扩展，而且JGroups的架构上设计非常灵活，提供可以兼容多种协议的协议栈。</p><p>JGroups的<strong>可靠性</strong>体现在下面几个方面：</p><ol><li>对所有接收者的消息的无丢失传输（通过丢失消息的重发）</li><li>大消息的分割传输和重组</li><li>消息的顺序发送和接收</li><li>保证原子性，消息要么被所有接收者接收，要么所有接收者都收不到</li></ol><p>也正是由于JGroups具备的上述诸多优秀特性，它常常被选择作为集群内各个节点之间数据同步的解决方案。而Ehcache也一样，支持基于JGroups实现的集群方案，通过IP组播消息，保证集群内各个节点之间数据的同步。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h3 id="Terracotta方式"><a href="#Terracotta方式" class="headerlink" title="Terracotta方式"></a>Terracotta方式</h3><p><code>Terracotta</code>是什么？看下来自百度百科的介绍：</p><blockquote><p>Terracotta是一款由美国Terracotta公司开发的著名开源Java集群平台。它在JVM与Java应用之间实现了一个专门处理集群功能的抽象层，以其特有的增量检测、智能定向传送、分布式协作、服务器镜像、分片等技术，允许用户在不改变现有系统代码的情况下实现单机Java应用向集群化应用的无缝迁移。使得用户可以专注于商业逻辑的开发，由Terracotta负责实现高性能、高可用性、高稳定性的企业级Java集群。</p></blockquote><p>所以说，Terracotta是一个JVM层专门负责做分布式节点间协同处理的平台框架。那么当优秀的JVM级缓存框架Ehcache与同样优秀的JVM间多节点协同框架Terracotta组合到一起，势必会有不俗的表现。</p><p>看下来自Ehcache官网的对于其Terracotta集群模式的图片说明：</p><p><img src="https://pics.codingcoder.cn/pics/202211201248174.png"></p><p>基于Terracotta方式，Ehcache可以支持：</p><ul><li><p>热点数据存储在进程本地，然后根据热度进行优化存储，热度高的会优先存储在更快的位置（比如heap中）。</p></li><li><p>存储在其中一台应用节点上的缓存数据，可以被集群中其它节点访问到。</p></li><li><p>缓存数据在集群层面是完整的，也支持按照HA模式设定高可用备份。</p></li></ul><p>可以说这种模式下，<em>既保留了Ehcache本地缓存的超高处理性能，又享受到了分布式缓存带来的集群优势</em>，不失为一种比较亮眼的组合。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h2 id="引申思考-——-本地缓存的设计边界与定位"><a href="#引申思考-——-本地缓存的设计边界与定位" class="headerlink" title="引申思考 —— 本地缓存的设计边界与定位"></a>引申思考 —— 本地缓存的设计边界与定位</h2><p>如上所言，纵使Ehcache提供了多种集群化策略，但略显尴尬的是实际中各个公司项目并没有大面积的使用。其实分析下来也很好理解：</p><blockquote><p>如果真的需要很明确的诉求去解决分布式场景下的缓存一致性问题，直接选择redis、memcache等主流的集中式缓存组件即可</p></blockquote><p>所以Ehcache的整体综合功能虽然是最强大的，整体定位偏向于大而全，但也导致在各个细分场景下表现不够极致：</p><ul><li><p>相比<code>Caffeine</code>：略显臃肿， 因为提供了很多额外的功能，比如使用磁盘缓存、比如支持多节点间集群组网等；</p></li><li><p>相比<code>Redis</code>： 先天不足，毕竟是个本地缓存，纵使支持了多种组网模式，依旧无法媲美集中式缓存在分布式场景下的体验。</p></li></ul><p>但在一些相对简单的集群数据同步场景下，或者对可靠性要求不高的集群缓存数据同步场景下，Ehcache还是很有优势的、尤其是<code>Terracotta集群</code>模式，也不啻为一个很好的选择。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h2 id="小结回顾"><a href="#小结回顾" class="headerlink" title="小结回顾"></a>小结回顾</h2><p>好啦，关于<code>Ehcache</code>的集群相关能力，就介绍到这里咯，而关于文章开头的几个问题，我们也在文章内容中做了解答与探讨。至此呢，我们关于Ehcache的相关介绍就全部结束了。那么你对Ehcache是否还有什么自己的观点呢？欢迎评论区一起交流下，期待和各位小伙伴们一起切磋、共同成长。</p><blockquote><p>随着本篇Ehcache介绍文章的结束，我们缓存专栏关于主流本地缓存框架的介绍就告一段落了。下一篇文章开始，我们将开始将目光聚焦到集中式缓存的身上，比如大家耳熟能详的Redis，以及经常在面试中会拿来与Redis做比较的Memcache等等。如有兴趣，欢迎关注。</p></blockquote><p>📣 <strong>补充说明1</strong> ：</p><blockquote><p>本文属于《<a href="https://juejin.cn/column/7140852038258147358">深入理解缓存原理与实战设计</a>》系列专栏的内容之一。该专栏围绕缓存这个宏大命题进行展开阐述，全方位、系统性地深度剖析各种缓存实现策略与原理、以及缓存的各种用法、各种问题应对策略，并一起探讨下缓存设计的哲学。</p><p>如果有兴趣，也欢迎关注此专栏。</p></blockquote><p>📣 <strong>补充说明2</strong> ：</p><ul><li>关于本文中涉及的<strong>演示代码</strong>的完整示例，我已经整理并提交到github中，如果您有需要，可以自取：<a href="https://github.com/veezean/JavaBasicSkills">https://github.com/veezean/JavaBasicSkills</a></li></ul><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><p><strong>我是悟道，聊技术、又不仅仅聊技术~</strong></p><p>如果觉得有用，请<strong>点赞 + 关注</strong>让我感受到您的支持。也可以关注下我的公众号【架构悟道】，获取更及时的更新。</p><p>期待与你一起探讨，一起成长为更好的自己。</p><p><img src="https://pics.codingcoder.cn/pics/202207091312091.gif"></p><p><img src="https://pics.codingcoder.cn/pics/202207091317876.png"></p>]]></content>
      
      
      <categories>
          
          <category> 缓存原理与实战设计 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JAVA </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JAVA中使用最广泛的本地缓存？Ehcache的自信从何而来2 —— Ehcache的各种项目集成与使用初体验</title>
      <link href="//post/20230106071817.html"/>
      <url>//post/20230106071817.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>本篇一起实践下Ehcache的各种不同使用方式，来感受下Ehcache的强大与便利。比如独立集成使用，基于JCache方式使用，以及通过Springboot+JCache+Ehcache方式集成使用等。</p></blockquote><hr><p><img src="https://pics.codingcoder.cn/pics/202210050807355.png"></p><p>大家好，又见面了。</p><hr><blockquote><p>本文是笔者作为掘金技术社区签约作者的身份输出的缓存专栏系列内容，将会通过系列专题，讲清楚缓存的方方面面。如果感兴趣，欢迎关注以获取后续更新。</p></blockquote><hr><p>在上一篇文章《<a href="https://juejin.cn/post/7167259989826863112">JAVA中使用最广泛的本地缓存？Ehcache的自信从何而来 —— 感受来自Ehcache的强大实力</a>》中，介绍了Ehcache所具有的核心优秀特性，如数据持久化、多级缓存、集群能力等等。所谓<em>纸上得来终觉浅、绝知此事要躬行</em>，接下来我们就一起动手实践下，在项目中集成Ehcache并体验Ehcache的各种常见用法。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h2 id="Ehcache的依赖集成与配置"><a href="#Ehcache的依赖集成与配置" class="headerlink" title="Ehcache的依赖集成与配置"></a>Ehcache的依赖集成与配置</h2><h3 id="依赖引入"><a href="#依赖引入" class="headerlink" title="依赖引入"></a>依赖引入</h3><p>集成使用Ehcache的第一步，就是要引入对应的依赖包。对于Maven项目而言，可以在pom.xml中添加对应依赖：</p><pre class="line-numbers language-markup" data-language="markup"><code class="language-markup">&lt;dependency&gt;  &lt;groupId&gt;org.ehcache&lt;&#x2F;groupId&gt;  &lt;artifactId&gt;ehcache&lt;&#x2F;artifactId&gt;  &lt;version&gt;3.10.0&lt;&#x2F;version&gt;&lt;&#x2F;dependency&gt;      </code></pre><p>依赖添加完成后，还需要对缓存进行配置后方可使用。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h3 id="缓存的配置与创建"><a href="#缓存的配置与创建" class="headerlink" title="缓存的配置与创建"></a>缓存的配置与创建</h3><h4 id="使用代码配置与创建Ehcache"><a href="#使用代码配置与创建Ehcache" class="headerlink" title="使用代码配置与创建Ehcache"></a>使用代码配置与创建Ehcache</h4><p>Ehcache支持在代码中手动创建缓存对象，并指定对应缓存参数信息。在使用之前，需要先了解几个关键代码类：</p><table><thead><tr><th>类名</th><th>具体说明</th></tr></thead><tbody><tr><td>CacheManagerBuilder</td><td>CacheManager对象的构造器对象，可以方便的指定相关参数然后创建出符合条件的CacheManager对象。</td></tr><tr><td>ResourcePoolsBuilder</td><td>用于指定缓存的存储形式（ResourcePools）的配置构造器对象，可以指定缓存是<code>堆内</code>缓存、<code>堆外</code>缓存、<code>磁盘</code>缓存或者多者的组合，以及各个类型缓存的容量信息、是否持久化等信息。</td></tr><tr><td>CacheConfiguration</td><td>用于承载所有指定的关于缓存的配置属性值。</td></tr><tr><td>CacheConfigurationBuilder</td><td>用于生成最终缓存总体配置信息的构造器，可以指定缓存<code>存储形式</code>（ResourcePools）、<code>过期策略</code>（ExpiryPolicy）、<code>键值类型</code>等等各种属性值。</td></tr></tbody></table><p>通过组合使用上述Builder构造器，我们便可以在代码中完成对缓存Cache属性的设置。比如下面这样：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public static void main(String[] args) &#123;    CacheManager cacheManager &#x3D; CacheManagerBuilder.newCacheManagerBuilder()            .with(CacheManagerBuilder.persistence(&quot;d:\\myCache\\&quot;))            .build(true);    &#x2F;&#x2F; 指定缓存的存储形式，采用多级缓存，并开启缓存持久化操作    ResourcePools resourcePools &#x3D; ResourcePoolsBuilder.newResourcePoolsBuilder()            .heap(1, MemoryUnit.MB)            .disk(10, MemoryUnit.GB, true)            .build();    &#x2F;&#x2F; 封装缓存配置对象，指定了键值类型、指定了使用TTL与TTI联合的过期淘汰策略    CacheConfiguration&lt;Integer, String&gt; cacheConfiguration &#x3D;            CacheConfigurationBuilder.newCacheConfigurationBuilder(Integer.class, String.class, resourcePools)                    .withExpiry(ExpiryPolicyBuilder.timeToIdleExpiration(Duration.ofSeconds(10)))                    .withExpiry(ExpiryPolicyBuilder.timeToLiveExpiration(Duration.ofSeconds(5)))                    .build();    &#x2F;&#x2F; 使用给定的配置参数，创建指定名称的缓存对象    Cache&lt;Integer, String&gt; myCache &#x3D; cacheManager.createCache(&quot;myCache&quot;, cacheConfiguration);&#125;</code></pre><p>上面的示例中，我们创建了一个基于<code>heap + disk</code>的<strong>二级缓存</strong>对象，并开启了缓存的持久化，以及指定了持久化结果文件的存储路径。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h4 id="基于XML配置Ehcache"><a href="#基于XML配置Ehcache" class="headerlink" title="基于XML配置Ehcache"></a>基于XML配置Ehcache</h4><p>因为Ehcache在创建缓存的时候可以指定的参数较多，如果通过上面的代码方式指定配置，略显繁琐且不够清晰直观，并且当需要创建多个不同的缓存对象的时候比较麻烦。好在Ehcache还提供了一种通过<code>XML</code>来进行参数配置的途径，并且支持在一个xml中配置多个不同的缓存对象信息。</p><p>在项目的resource目录下添加个Ehcache的配置文件，比如取名<code>ehcache.xml</code>，项目层级结构示意如下：</p><p><img src="https://pics.codingcoder.cn/pics/202211192004320.png"></p><p>然后我们在ehcache.xml中添加配置内容。内容示例如下：</p><pre class="line-numbers language-markup" data-language="markup"><code class="language-markup">&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot;?&gt;&lt;config xmlns:xsi&#x3D;&#39;http:&#x2F;&#x2F;www.w3.org&#x2F;2001&#x2F;XMLSchema-instance&#39; xmlns:jsr107&#x3D;&#39;http:&#x2F;&#x2F;www.ehcache.org&#x2F;v3&#x2F;jsr107&#39;        xmlns&#x3D;&#39;http:&#x2F;&#x2F;www.ehcache.org&#x2F;v3&#39;        xsi:schemaLocation&#x3D;&quot;http:&#x2F;&#x2F;www.ehcache.org&#x2F;v3 http:&#x2F;&#x2F;www.ehcache.org&#x2F;schema&#x2F;ehcache-core-3.1.xsd        http:&#x2F;&#x2F;www.ehcache.org&#x2F;v3&#x2F;jsr107 http:&#x2F;&#x2F;www.ehcache.org&#x2F;schema&#x2F;ehcache-107-ext-3.1.xsd&quot;&gt;    &lt;persistence directory&#x3D;&quot;D:\myCache&quot;&#x2F;&gt;    &lt;cache alias&#x3D;&quot;myCache&quot;&gt;        &lt;key-type&gt;java.lang.Integer&lt;&#x2F;key-type&gt;        &lt;value-type&gt;java.lang.String&lt;&#x2F;value-type&gt;        &lt;expiry&gt;            &lt;tti unit&#x3D;&quot;minutes&quot;&gt;5&lt;&#x2F;tti&gt;        &lt;&#x2F;expiry&gt;        &lt;resources&gt;            &lt;heap unit&#x3D;&quot;MB&quot;&gt;10&lt;&#x2F;heap&gt;            &lt;offheap unit&#x3D;&quot;MB&quot;&gt;50&lt;&#x2F;offheap&gt;            &lt;disk persistent&#x3D;&quot;true&quot; unit&#x3D;&quot;MB&quot;&gt;500&lt;&#x2F;disk&gt;        &lt;&#x2F;resources&gt;    &lt;&#x2F;cache&gt;&lt;&#x2F;config&gt;</code></pre><p>上面演示的<code>Ehcache3.x</code>版本中的配置实现方式（配置文件与<em>Ehcache2.x</em>存在<strong>较大差异</strong>，不要混用，运行会报错），在xml中指定了<code>myCache</code>的key与value对应的类型，指定了基于TTI的5分钟过期淘汰策略，并规定了采用<code>heap + offheap + disk</code>的三级缓存机制，此外还开启了缓存持久化能力，并指定了持久化文件的存储路径。</p><p>通过xml配置的方式，可以很直观的看出这个缓存对象的所有关键属性约束，也是相比于代码中直接配置的方式更有优势的一个地方。在xml配置文件中，也可以同时配置多个缓存对象信息。此外，为了简化配置，Ehcache还支持通过<code>&lt;cache-template&gt;</code>来将一些公用的配置信息抽取出来成为模板，然后各个Cache独立配置的时候只需要增量配置各自差异化的部分即可，当然也可以基于给定的模板进行个性化的修改覆写配置。</p><p>比如下面这个配置文件，配置了两个Cache对象信息，复用了同一个配置模板，然后各自针对模板中不符合自己的配置进行了重新改写。</p><pre class="line-numbers language-markup" data-language="markup"><code class="language-markup">&lt;?xml version&#x3D;&quot;1.0&quot; encoding&#x3D;&quot;UTF-8&quot;?&gt;&lt;config xmlns:xsi&#x3D;&#39;http:&#x2F;&#x2F;www.w3.org&#x2F;2001&#x2F;XMLSchema-instance&#39; xmlns:jsr107&#x3D;&#39;http:&#x2F;&#x2F;www.ehcache.org&#x2F;v3&#x2F;jsr107&#39;        xmlns&#x3D;&#39;http:&#x2F;&#x2F;www.ehcache.org&#x2F;v3&#39;        xsi:schemaLocation&#x3D;&quot;        http:&#x2F;&#x2F;www.ehcache.org&#x2F;v3 http:&#x2F;&#x2F;www.ehcache.org&#x2F;schema&#x2F;ehcache-core-3.1.xsd        http:&#x2F;&#x2F;www.ehcache.org&#x2F;v3&#x2F;jsr107 http:&#x2F;&#x2F;www.ehcache.org&#x2F;schema&#x2F;ehcache-107-ext-3.1.xsd&quot;&gt;    &lt;persistence directory&#x3D;&quot;D:\myCache&quot;&#x2F;&gt;    &lt;cache-template name&#x3D;&quot;myTemplate&quot;&gt;        &lt;key-type&gt;java.lang.String&lt;&#x2F;key-type&gt;        &lt;value-type&gt;java.lang.String&lt;&#x2F;value-type&gt;        &lt;expiry&gt;            &lt;ttl unit&#x3D;&quot;minutes&quot;&gt;30&lt;&#x2F;ttl&gt;        &lt;&#x2F;expiry&gt;        &lt;resources&gt;            &lt;heap unit&#x3D;&quot;MB&quot;&gt;10&lt;&#x2F;heap&gt;            &lt;disk unit&#x3D;&quot;GB&quot; persistent&#x3D;&quot;true&quot;&gt;2&lt;&#x2F;disk&gt;        &lt;&#x2F;resources&gt;    &lt;&#x2F;cache-template&gt;    &lt;cache alias&#x3D;&quot;myCache&quot; uses-template&#x3D;&quot;myTemplate&quot;&gt;        &lt;key-type&gt;java.lang.Integer&lt;&#x2F;key-type&gt;    &lt;&#x2F;cache&gt;    &lt;cache alias&#x3D;&quot;myCache2&quot; uses-template&#x3D;&quot;myTemplate&quot;&gt;        &lt;expiry&gt;            &lt;ttl unit&#x3D;&quot;minutes&quot;&gt;60&lt;&#x2F;ttl&gt;        &lt;&#x2F;expiry&gt;    &lt;&#x2F;cache&gt;&lt;&#x2F;config&gt;</code></pre><p>配置完成之后，我们还需要在代码中指定使用此配置文件进行CacheManager创建与配置，并且完成CacheManager的<em>init初始化</em>操作。</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public Cache&lt;Integer, String&gt; createCacheWithXml() &#123;    &#x2F;&#x2F; 获取配置文件    URL xmlConfigUrl &#x3D; this.getClass().getClassLoader().getResource(&quot;.&#x2F;ehcache.xml&quot;);    &#x2F;&#x2F; 解析对应的配置文件并创建CacheManager对象    XmlConfiguration xmlConfiguration &#x3D; new XmlConfiguration(xmlConfigUrl);    CacheManager cacheManager &#x3D; CacheManagerBuilder.newCacheManager(xmlConfiguration);    &#x2F;&#x2F; 执行初始化操作    cacheManager.init();    &#x2F;&#x2F; 直接从CacheManager中根据名称获取对应的缓存对象    return cacheManager.getCache(&quot;myCache&quot;, Integer.class, String.class);&#125;</code></pre><p>这样，Ehcache的集成与配置就算完成了，接下来直接获取Cache对象并对其进行操作即可。</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public static void main(String[] args) &#123;    EhcacheService ehcacheService &#x3D; new EhcacheService();    Cache&lt;Integer, String&gt; cache &#x3D; ehcacheService.createCacheWithXml();    cache.put(1, &quot;value1&quot;);    System.out.println(cache.get(1));&#125;</code></pre><p>当然，Ehcache3.x版本中使用xml方式配置的时候，有<strong>几个坑</strong>需要提防，避免踩坑。</p><ol><li>对于过期时间的设定<em>只允许选择ttl或者tti中的一者</em>，不允许两者同时存在——而通过代码配置的时候则没有这个问题。如果在xml中同时指定ttl与tti则运行的时候会抛异常。</li></ol><p><img src="https://pics.codingcoder.cn/pics/202211192034355.png"></p><ol start="2"><li><code>&lt;cache&gt;</code>节点下面配置的时候，<code>&lt;expire&gt;</code>节点需要放在<code>&lt;configuration&gt;</code>节点的前面，否则会报错<em>Schema校验失败</em>。</li></ol><p><img src="https://pics.codingcoder.cn/pics/202211192037491.png"></p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h3 id="业务中使用"><a href="#业务中使用" class="headerlink" title="业务中使用"></a>业务中使用</h3><p>缓存设置并创建完成后，业务代码中便可以通过Ehcache提供的接口，进行缓存数据的相关操作。业务使用是通过对Cache对象的操作来进行的，Cache提供的API接口与JDK中的Map接口极其相似，所以在使用上毫无门槛，可以直接上手。</p><p><img src="https://pics.codingcoder.cn/pics/202211182304748.png"></p><p>实际编码中，根据业务的实际诉求，通过Cache提供的API接口来完成缓存数据的增删改查操作。</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public static void main(String[] args) &#123;    EhcacheService ehcacheService &#x3D; new EhcacheService();    Cache&lt;Integer, String&gt; cache &#x3D; ehcacheService.getCache();    &#x2F;&#x2F; 存入单条记录到缓存中    cache.put(1, &quot;value1&quot;);    Map&lt;Integer, String&gt; values &#x3D; new HashMap&lt;&gt;();    values.put(2, &quot;value2&quot;);    values.put(3, &quot;value3&quot;);    &#x2F;&#x2F; 批量向缓存中写入数据    cache.putAll(values);    &#x2F;&#x2F; 当缓存不存在的时候才写入缓存    cache.putIfAbsent(2, &quot;value2&quot;);    &#x2F;&#x2F; 查询单条记录    System.out.println(cache.get(2));    &#x2F;&#x2F; 批量查询操作    System.out.println(cache.getAll(Stream.of(1,2,3).collect(Collectors.toSet())));    &#x2F;&#x2F; 移除单条记录    cache.remove(1);    System.out.println(cache.get(1));    &#x2F;&#x2F; 清空缓存记录    cache.clear();    System.out.println(cache.get(1));&#125;</code></pre><p>从上述代码可以看出，EhCache具体使用起来与普通Map操作无异。虽然使用简单，但是这样也存在个问题就是业务代码所有使用缓存的地方，都需要强依赖Ehcache的具体接口，导致业务代码与Ehcache的依赖耦合度太高，后续如果想要更换缓存组件时，难度会非常大。</p><p>在前面的文章《<a href="https://juejin.cn/post/7159328581611421726">聊一聊JAVA中的缓存规范 —— 虽迟但到的JCache API与天生不俗的Spring Cache</a>》中有介绍过JAVA业界的缓存标准规范，主要有<code>JSR107</code>标准与<code>Spring Cache</code>标准，如果可以通过标准的接口方式进行访问，这样就可以解决与EhCache深度耦合的问题了。令人欣慰的是，<em>Ehcache同时提供了对JSR107与Spring Cache规范的支持</em>！</p><p>下面一起看下如何通过JSR107规范接口以及Spring Cache的标准来使用Ehcache。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h2 id="通过JCache-API来使用Ehcache"><a href="#通过JCache-API来使用Ehcache" class="headerlink" title="通过JCache API来使用Ehcache"></a>通过JCache API来使用Ehcache</h2><h3 id="依赖集成与配置"><a href="#依赖集成与配置" class="headerlink" title="依赖集成与配置"></a>依赖集成与配置</h3><p>如果要使用JCache标准方式来使用，需要额外引入JCache对应依赖包：</p><pre class="line-numbers language-markup" data-language="markup"><code class="language-markup">&lt;dependency&gt;    &lt;groupId&gt;javax.cache&lt;&#x2F;groupId&gt;    &lt;artifactId&gt;cache-api&lt;&#x2F;artifactId&gt;    &lt;version&gt;1.1.1&lt;&#x2F;version&gt;&lt;&#x2F;dependency&gt;</code></pre><p>按照JCache的规范，必须通过CacheManager才能获取到Cache对象（这一点与Ehcache相同），而CacheManager则又需要通过<code>CacheProvider</code>来获取。</p><p><img src="https://pics.codingcoder.cn/pics/202210141512700.png"></p><p>遵循这一原则，我们可以按照JCache的方式来得到Cache对象：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">import javax.cache.Cache;import javax.cache.CacheManager;import javax.cache.Caching;import javax.cache.configuration.MutableConfiguration;import javax.cache.expiry.CreatedExpiryPolicy;import javax.cache.expiry.Duration;import javax.cache.spi.CachingProvider;public class JsrCacheService &#123;    public Cache&lt;Integer, String&gt; getCache() &#123;        CachingProvider cachingProvider &#x3D; Caching.getCachingProvide();        CacheManager cacheManager &#x3D; cachingProvider.getCacheManager();        MutableConfiguration&lt;Integer, String&gt; configuration &#x3D;                new MutableConfiguration&lt;Integer, String&gt;()                        .setTypes(Integer.class, String.class)                        .setStoreByValue(false)                        .setExpiryPolicyFactory(CreatedExpiryPolicy.factoryOf(Duration.ONE_MINUTE));        Cache&lt;Integer, String&gt; myCache &#x3D; cacheManager.createCach    (&quot;myCache&quot;, configuration);        System.out.println(myCache.getClass().getCanonicalName());        return myCache;    &#125;&#125;</code></pre><p>从<code>import</code>的内容可以看出上述代码没有调用到任何Ehcache的类，调用上述代码执行并打印出构建出来的Cache对象具体类型如下，可以看出的的确确创建出来的是Ehcache提供的<code>Eh107Cache</code>类：</p><pre class="line-numbers language-none"><code class="language-none">org.ehcache.jsr107.Eh107Cache</code></pre><p>这是为什么呢？其实原理很简单，之前介绍JCache API的文章中也有解释过。JCache中的CacheProvider其实是一个<strong>SPI接口</strong>，Ehcache实现并向JVM中注册了这一接口，所以JVM可以直接加载使用了Ehcache提供的实际能力。翻看下Ehcache的源码，我们也可以找到其SPI注册对应的配置信息：</p><p><img src="https://pics.codingcoder.cn/pics/202211192211897.png"></p><p>这里还有一个需要注意的点，因为SPI接口有可能被多个组件实现，而且可能会有多个组件同时往JVM中注册了<em>javax.cache.spi.CachingProvider</em>这一SPI接口的实现类，这种情况下，上述代码执行的时候会报错，因为没有指定具体使用哪一个SPI，所以JVM出现了选择困难症，只能抛异常了：</p><p><img src="https://pics.codingcoder.cn/pics/202211192229086.png"></p><p>所以为了避免这种情况的发生，我们可以在获取CacheProvider的时候，指定加载使用Ehcache提供的具体实现类<code>org.ehcache.jsr107.EhcacheCachingProvider</code>即可。</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">CachingProvider cachingProvider &#x3D; Caching.getCachingProvider(&quot;org.ehcache.jsr107.EhcacheCachingProvider&quot;);</code></pre><p>上面代码中，使用了JCache的<code>MutableConfiguration</code>类来实现缓存配置的设定。作为通用规范，JCache仅定义了所有缓存实现者需要实现的功能的最小集，而Ehcache除了JCache提供的最低限度缓存功能外，还有很多其余缓存不具备的增强特性。如果需要使用这些特性，则需要使用Ehcache自己的缓存配置类来实现。</p><p>举个例子，MutableConfiguration只能设定基于内存缓存的一些行为参数，而如果需要配置Ehcache提供的<code>heap+offheap+disk</code>三级缓存能力，或者是要开启Ehcache的持久化能力，则MutableConfiguration就有点爱莫能助，只能Ehcache亲自出马了。</p><p>比如下面这样：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public Cache&lt;Integer, String&gt; getCache() &#123;    CacheConfiguration&lt;Integer, String&gt; cacheConfiguration &#x3D;            CacheConfigurationBuilder.newCacheConfigurationBuilder(Integer.class, String.class,                    ResourcePoolsBuilder.heap(10).offheap(20, MemoryUnit.MB)).build();    EhcacheCachingProvider cachingProvider &#x3D; (EhcacheCachingProvider) Caching.getCachingProvider();    CacheManager cacheManager &#x3D; cachingProvider.getCacheManager();    return cacheManager.createCache(&quot;myCache&quot;,            Eh107Configuration.fromEhcacheCacheConfiguration(cacheConfiguration));&#125;</code></pre><p>当然，也可以在JCache中继续使用Ehcache的xml配置方式。如下示意：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public Cache&lt;Integer, String&gt; getCache3() throwsURISyntaxException &#123;    CachingProvider cachingProvider &#x3D; Caching.getCachingProvider();    CacheManager manager &#x3D; cachingProvider.getCacheManager(            getClass().getClassLoader().getResource(&quot;.&#x2F;ehcache.xml&quot;).toURI(),            getClass().getClassLoader());    return manager.getCache(&quot;myCache&quot;, Integer.class, String.class);&#125;</code></pre><p>相比于使用纯粹的<code>JCache API</code>方式，上述两种使用Ehcache自己配置的方式可以享受到Ehcache提供的一些高级特性。但<strong>代价</strong>就是业务代码与Ehcache的解耦不是那么彻底，好在这些依赖仅在创建缓存的地方，对整体代码的耦合度影响不是很高，属于可接受的范围。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h3 id="业务中使用-1"><a href="#业务中使用-1" class="headerlink" title="业务中使用"></a>业务中使用</h3><p>完成了通过JCache API获取Cache对象，然后业务层代码中，便可以基于Cache对象提供的一系列方法，对缓存的具体内容进行操作了。</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public static void main(String[] args) throws Exception &#123;    JsrCacheService service &#x3D; new JsrCacheService();    Cache&lt;Integer, String&gt; cache &#x3D; service.getCache();    cache.put(1,&quot;value1&quot;);    cache.put(2,&quot;value2&quot;);    System.out.println(cache.get(1));    cache.remove(1);    System.out.println(cache.containsKey(1));&#125;</code></pre><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h2 id="在Spring中集成Ehcache"><a href="#在Spring中集成Ehcache" class="headerlink" title="在Spring中集成Ehcache"></a>在Spring中集成Ehcache</h2><p>作为JAVA领域霸主级别的存在，Spring凭借其优良的设计与出色的表现俘获了大批开发人员青睐，大部分项目都使用Spring作为基础框架来简化编码逻辑。Ehcache可以整合到Spring中，并搭配<code>Spring Cache</code>的标准化注解，让代码可以以一种更加优雅的方式来实现缓存的操作。</p><h3 id="依赖集成与配置-1"><a href="#依赖集成与配置-1" class="headerlink" title="依赖集成与配置"></a>依赖集成与配置</h3><p>以SpringBoot项目为例进行说明，首先需要引入对应的依赖包。对于maven项目，在pom.xml中添加如下配置：</p><pre class="line-numbers language-markup" data-language="markup"><code class="language-markup">&lt;dependency&gt;    &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt;    &lt;artifactId&gt;spring-boot-starter-cache&lt;&#x2F;artifactId&gt;&lt;&#x2F;dependency&gt;&lt;dependency&gt;    &lt;groupId&gt;org.ehcache&lt;&#x2F;groupId&gt;    &lt;artifactId&gt;ehcache&lt;&#x2F;artifactId&gt;&lt;&#x2F;dependency&gt;</code></pre><p>依赖引入之后，我们需要在配置文件中指定使用Ehcache作为集成的缓存能力提供者，并且可以指定<code>ehcache.xml</code>独立的配置文件（ehcache.xml配置文件需要放置在resource目录下）：</p><pre class="line-numbers language-properties" data-language="properties"><code class="language-properties">spring.cache.type&#x3D;ehcachespring.cache.ehcache.config&#x3D;.&#x2F;ehcache.xml</code></pre><p>然后我们需要在项目启动类上添加上<code>@EnableCaching</code>来声明<strong>开启缓存</strong>能力：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">@SpringBootApplication@EnableCachingpublic class CrawlerApplication &#123;    &#x2F;&#x2F; ...&#125;</code></pre><p>到这里，对于<code>Ehcache2.x</code>版本而言，就已经完成集成预配置操作，可以直接在代码中进行操作与使用了。但是对于<code>Ehcache3.x</code>版本而言，由于<strong>Spring并未提供对应的CacheManager对其进行支持</strong>，如果这个时候我们直接启动程序，会在启动的时候就被无情的泼上一盆冷水：</p><p><img src="https://pics.codingcoder.cn/pics/202211200835466.png"></p><p>为了实现<em>Ehcache3.x</em>与<em>Spring</em>的集成，解决上述的问题，需要做一些额外的适配逻辑。根据报错信息，首先可以想到的就是手动实现cacheManager的创建与初始化。而由于Spring Cache提供了对JSR107规范的支持，且Ehcache3.x也全面符合JSR107规范，所以我们可以将三者结合起来，<strong>以JSR107规范作为桥梁</strong>，实现SpringBoot与Ehcache3.x的集成。</p><p>这个方案也即目前比较常用的”<code>SpringBoot + JCache + Ehcache</code>“组合模式。首先需要在前面已有实现的基础上，额外增加对JCache的依赖：</p><pre class="line-numbers language-markup" data-language="markup"><code class="language-markup">&lt;dependency&gt;    &lt;groupId&gt;javax.cache&lt;&#x2F;groupId&gt;    &lt;artifactId&gt;cache-api&lt;&#x2F;artifactId&gt;    &lt;version&gt;1.1.1&lt;&#x2F;version&gt;&lt;&#x2F;dependency&gt;</code></pre><p>其次，需要修改下<code>application.properties</code>配置文件，将Spring Cache声明使用的缓存类型改为<strong>JCache</strong>。</p><pre class="line-numbers language-properties" data-language="properties"><code class="language-properties">spring.cache.type&#x3D;jcachespring.cache.jcache.config&#x3D;.&#x2F;ehcache.xml</code></pre><p>上面的配置看着<strong>略显魔幻</strong>，也是很多不清楚原有的小伙伴们会比较疑惑的地方（我曾经刚在项目中看到这种写法的时候，就一度怀疑是别人代码配置写错了）。但是经过上述的原因阐述，应该就明白其中的寓意了。</p><p>接下来，需要在项目中手动指定使用ehcache.xml配置文件来构建cacheManager对象。</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">@Configurationpublic class EhcacheConfig &#123;    @Bean    public JCacheManagerFactoryBean cacheManagerFactoryBean() throws Exception &#123;        JCacheManagerFactoryBean factoryBean &#x3D; new JCacheManagerFactoryBean();        factoryBean.setCacheManagerUri(getClass().getClassLoader().getResource(&quot;ehcache.xml&quot;).toURI());        return factoryBean;    &#125;    @Bean    public CacheManager cacheManager(javax.cache.CacheManager cacheManager) &#123;        JCacheCacheManager cacheCacheManager &#x3D; new JCacheCacheManager();        cacheCacheManager.setCacheManager(cacheManager);        return cacheCacheManager;    &#125;&#125;</code></pre><p>这样，就完成了通过JCache桥接来实现Spring中使用Ehcache3.x版本的目的了。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h3 id="支持Spring-Cache注解操作"><a href="#支持Spring-Cache注解操作" class="headerlink" title="支持Spring Cache注解操作"></a>支持Spring Cache注解操作</h3><p>完成了Spring与Ehcache的整合之后，便可以使用Spring Cache提供的标准注解来实现对Ehcache缓存的操作。</p><p>首先需了解Spring Cache几个常用的注解及其含义：</p><table><thead><tr><th>注解</th><th>含义说明</th></tr></thead><tbody><tr><td>@EnableCaching</td><td>开启使用缓存能力</td></tr><tr><td>@Cacheable</td><td>添加相关内容到缓存中</td></tr><tr><td>@CachePut</td><td>更新相关缓存记录</td></tr><tr><td>@CacheEvict</td><td>删除指定的缓存记录，如果需要清空指定容器的全部缓存记录，可以指定<code>allEntities=true</code>来实现</td></tr></tbody></table><p>通过注解的方式，可以轻松的实现将某个方法调用的入参与响应映射自动缓存起来，基于AOP机制，实现了对业务逻辑无侵入式的静默缓存处理。</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">@Service@Slf4jpublic class TestService &#123;    @Cacheable(cacheNames &#x3D; &quot;myCache&quot;, key &#x3D; &quot;#id&quot;)    public String queryById(int id) &#123;        log.info(&quot;queryById方法被执行&quot;);        return &quot;value&quot; + id;    &#125;    @CachePut(cacheNames &#x3D; &quot;myCache&quot;, key &#x3D; &quot;#id&quot;)    public String updateIdValue(int id, String newValue) &#123;        log.info(&quot;updateIdValue方法被执行&quot;);        return newValue;    &#125;    @CacheEvict(cacheNames &#x3D; &quot;myCache&quot;, key &#x3D; &quot;#id&quot;)    public void deleteById(int id) &#123;        log.info(&quot;deleteById方法被执行&quot;);    &#125;&#125;</code></pre><p>通过注解的方式指定了各个方法需要配套执行的缓存操作，具体业务代码里面则聚焦于自身逻辑，无需操心缓存的具体实现。可以通过下面的代码测试下集成后的效果：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">@GetMapping(&quot;&#x2F;test&quot;)public String test() &#123;    String value &#x3D; testService.queryById(123);    System.out.println(&quot;第一次查询，结果：&quot; + value);    value &#x3D; testService.queryById(123);    System.out.println(&quot;第二次查询，结果：&quot; +value);    testService.updateIdValue(123, &quot;newValue123&quot;);    value &#x3D; testService.queryById(123);    System.out.println(&quot;更新后重新查询，结果：&quot; + value);    testService.deleteById(123);    value &#x3D; testService.queryById(123);    System.out.println(&quot;删除后重新查询，结果：&quot; + value);    return &quot;OK&quot;;&#125;</code></pre><p>执行结果如下：</p><pre class="line-numbers language-none"><code class="language-none">queryById方法被执行第一次查询，结果：value123第二次查询，结果：value123updateIdValue方法被执行更新后重新查询，结果：newValue123deleteById方法被执行queryById方法被执行删除后重新查询，结果：newValue123</code></pre><p>从测试结果可以看出，查询之后方法的入参与返回值被做了缓存，再次去查询的时候并没有真正的执行具体的查询操作方法，而调用删除方法之后再次查询，又会触发了真正的查询方法的执行。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h2 id="小结回顾"><a href="#小结回顾" class="headerlink" title="小结回顾"></a>小结回顾</h2><p>好啦，关于<code>Ehcache</code>的各种配置、以及通过JSR107或者Spring Cache规范集成到项目中使用的相关内容，就介绍到这里了。不知道小伙伴们是否对Ehcache的使用有了进一步的了解呢？而关于Ehcache，你是否有自己的一些想法与见解呢？欢迎评论区一起交流下，期待和各位小伙伴们一起切磋、共同成长。</p><p>📣 <strong>补充说明1</strong> ：</p><blockquote><p>本文属于《<a href="https://juejin.cn/column/7140852038258147358">深入理解缓存原理与实战设计</a>》系列专栏的内容之一。该专栏围绕缓存这个宏大命题进行展开阐述，全方位、系统性地深度剖析各种缓存实现策略与原理、以及缓存的各种用法、各种问题应对策略，并一起探讨下缓存设计的哲学。</p><p>如果有兴趣，也欢迎关注此专栏。</p></blockquote><p>📣 <strong>补充说明2</strong> ：</p><ul><li>关于本文中涉及的<strong>演示代码</strong>的完整示例，我已经整理并提交到github中，如果您有需要，可以自取：<a href="https://github.com/veezean/JavaBasicSkills">https://github.com/veezean/JavaBasicSkills</a></li></ul><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><p><strong>我是悟道，聊技术、又不仅仅聊技术~</strong></p><p>如果觉得有用，请<strong>点赞 + 关注</strong>让我感受到您的支持。也可以关注下我的公众号【架构悟道】，获取更及时的更新。</p><p>期待与你一起探讨，一起成长为更好的自己。</p><p><img src="https://pics.codingcoder.cn/pics/202207091312091.gif"></p><p><img src="https://pics.codingcoder.cn/pics/202207091317876.png"></p>]]></content>
      
      
      <categories>
          
          <category> 缓存原理与实战设计 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JAVA </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JAVA中使用最广泛的本地缓存？Ehcache的自信从何而来 —— 感受来自Ehcache的强大实力</title>
      <link href="//post/20230105155417.html"/>
      <url>//post/20230105155417.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>提到JAVA本地缓存框架，还有一个同样无法被忽视的强大存在 —— Ehcache!其官网直言不讳的将自己称为“JAVA中使用最广泛的缓存”，那么这份自信与实力从何而来？让我们一起解读下。</p></blockquote><hr><p><img src="https://pics.codingcoder.cn/pics/202210050807355.png"></p><p>大家好，又见面了。</p><hr><blockquote><p>本文是笔者作为掘金技术社区签约作者的身份输出的缓存专栏系列内容，将会通过系列专题，讲清楚缓存的方方面面。如果感兴趣，欢迎关注以获取后续更新。</p></blockquote><hr><p>作为《<a href="https://juejin.cn/column/7140852038258147358">深入理解缓存原理与实战设计</a>》系列专栏，前面几篇文章中我们详细的介绍与探讨了<code>Guava Cache</code>与<code>Caffeine</code>的实现、特性与使用方式。提到JAVA本地缓存框架，还有一个同样无法被忽视的强大存在 —— <strong>Ehcache</strong>！它最初是由Greg Luck于2003年开始开发，截止目前，Ehcache已经演进到了<code>3.10.0</code>版本，各方面的能力已经构建的非常完善。<a href="https://www.ehcache.org/">Ehcache官网</a>上也毫不谦虚的描述自己是“<em>Java’s most widely-used cache</em>”，即JAVA中使用最广泛的缓存，足见<code>Ehcache</code>的强大与自信。</p><p><img src="https://pics.codingcoder.cn/pics/202211170715109.png"></p><p>此外，Ehcache还是被<code>Hibernate</code>选中并默认集成的缓存框架，它究竟有什么魅力可以让著名的Hibernate对其青眼有加？它与Caffeine又有啥区别呢？我们实际的业务项目里又该<em>如何取舍</em>呢？带着这些疑问，接下来就来认识下Ehcache，一睹Ehcache那些闪闪发光的优秀特性吧！</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h2 id="Ehcache的闪光特性"><a href="#Ehcache的闪光特性" class="headerlink" title="Ehcache的闪光特性"></a>Ehcache的闪光特性</h2><h3 id="支持多级缓存"><a href="#支持多级缓存" class="headerlink" title="支持多级缓存"></a>支持多级缓存</h3><p>之前文章中我们介绍过的Guava Cache或者是Caffeine，都是纯<strong>内存缓存</strong>，使用上会受到内存大小的制约，而Ehcache则打破了这一约束。<strong>Ehcache2.x</strong>时代就已经支持了基于<code>内存</code>和<code>磁盘</code>的二级缓存能力，而演进到<strong>Ehcache3.x</strong>版本时进一步扩展了此部分能力，增加了对于<code>堆外缓存</code>的支持。此外，结合Ehcache原生支持的<code>集群</code>能力，又可以打破单机的限制，完全解决容量这一制约因素。</p><p>综合而言，Ehcache支持的缓存形式就有了如下四种：</p><ul><li><strong>堆内缓存（heap）</strong></li></ul><p>所谓的<code>堆内</code>（heap）缓存，就是我们常规意义上说的<em>内存缓存</em>，严格意义上来说，是指<strong>被JVM托管</strong>占用的部分内存。内存缓存最大的优势就是具有超快的读写速度，但是不足点就在于<code>容量有限</code>、且<code>无法持久化</code>。</p><p>在创建缓存的时候可以指定使用堆内缓存，也可以一并指定堆内缓存允许的<code>最大字节数</code>。</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">&#x2F;&#x2F; 指定使用堆内缓存，并限制最大容量为100MResourcePoolsBuilder.newResourcePoolsBuilder().heap(100, MemoryUnit.MB);</code></pre><p>除了按照总字节大小限制，还可以按照<code>记录数</code>进行约束：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">&#x2F;&#x2F; 指定使用堆内缓存，并限制最大容量为100个Entity记录ResourcePoolsBuilder.newResourcePoolsBuilder().heap(100, EntryUnit.ENTRIES);</code></pre><ul><li><strong>堆外缓存（off-heap）</strong></li></ul><p><code>堆外</code>（off-heap）缓存，同样是存储在<strong>内存</strong>中。其实就是在内存中开辟一块区域，将其当做磁盘进行使用。由于内存的读写速度特别快，所以将数据存储在这个区域，读写上可以获得比本地磁盘读取更优的表现。这里的“堆外”，主要是相对与JVM的堆内存而言的，因为这个区域<strong>不在JVM的堆内存</strong>中，所以叫堆外缓存。这块的关系如下图示意：</p><p><img src="https://pics.codingcoder.cn/pics/202211172259773.png"></p><p>看到这里，不知道大家是否有这么个疑问：既然都是内存中存储，那为何多此一举非要将其划分为堆外缓存呢？直接将这部分的空间类驾到堆内缓存上，不是一样的效果吗？</p><p>我们知道<strong>JVM</strong>会基于<code>GC机制</code>自动的对内存中不再使用的对象进行<em>垃圾回收</em>，而<code>GC</code>的时候对系统性能的影响是非常大的。堆内缓存的数据越多，GC的压力就会越大，对系统性能的影响也会越明显。所以为了降低大量缓存对象的GC回收动作的影响，便出现了<code>off-heap</code>处理方式。在JVM堆外的内存中开辟一块空间，可以像使用本地磁盘一样去使用这块内存区域，这样就既享受了内存的高速读写能力，又<strong>避免频繁GC</strong>带来的烦恼。</p><p>可以在创建缓存的时候，通过<code>offheap</code>方法来指定使用堆外缓存并设定堆外缓存的容量大小，这样当heap缓存容量满之后，其余的数据便会存储到堆外缓存中。</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">ResourcePoolsBuilder.newResourcePoolsBuilder()        .heap(100, MemoryUnit.KB) &#x2F;&#x2F; 堆内缓存100K        .offheap(10, MemoryUnit.MB); &#x2F;&#x2F; 堆外缓存10M</code></pre><p>堆外缓存的时候，<strong>offheap</strong>的大小设定需要注意两个原则：</p><ol><li>offheap需要<strong>大于heap</strong>的容量大小（前提是heap大小设定的是<em>字节数</em>而非Entity数）</li><li>offheap大小<strong>必须1M以上</strong>。</li></ol><p>如果设定的时候不满足上述条件，会报错：</p><pre class="line-numbers language-none"><code class="language-none">Caused by: java.lang.IllegalArgumentException: The value of maxBytesLocalOffHeap is less than the minimum allowed value of 1M. Reconfigure maxBytesLocalOffHeap in ehcache.xml or programmatically.at org.ehcache.impl.internal.store.offheap.HeuristicConfiguration.&lt;init&gt;(HeuristicConfiguration.java:55)at org.ehcache.impl.internal.store.offheap.OffHeapStore.createBackingMap(OffHeapStore.java:102)at org.ehcache.impl.internal.store.offheap.OffHeapStore.access$500(OffHeapStore.java:69)</code></pre><p>总结下堆内缓存与堆外缓存的区别与各自<strong>优缺点</strong>：</p><ol><li><code>堆内缓存</code>是由<strong>JVM管理</strong>的，在JVM中可以直接去以<strong>引用</strong>的形式去读取，所以读写的<em>速度会特别高</em>。而且JVM会负责其内容的回收与清理，使用起来比较“省心”。</li><li><code>堆外缓存</code>是在内存中划定了一块独立的存储区域，然后可以将这部分内存当做“磁盘”进行使用。需要使用方自行维护数据的清理，读写前需要<strong>序列化</strong>与<strong>反序列化</strong>操作，但可以省去GC的影响。</li></ol><ul><li><strong>磁盘缓存（disk）</strong></li></ul><p>当我们需要缓存的数据量特别大、内存容量无法满足需求的时候，可以使用<code>disk</code>磁盘存储来作为补充。相比于内存，磁盘的读写速度显然要慢一些、但是胜在其价格便宜，<em>容量</em>可以足够大。</p><p>我们可以在缓存创建的时候，指定使用磁盘缓存，作为堆内缓存或者堆外缓存的补充。</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">ResourcePoolsBuilder.newResourcePoolsBuilder()        .heap(10, MemoryUnit.MB)         .offheap(1, MemoryUnit.MB)        .disk(10, MemoryUnit.GB); &#x2F;&#x2F; 指定使用10G磁盘缓存空间</code></pre><p>需要注意这里磁盘的容量设定一定要<strong>大于</strong>前面的<code>heap</code>以及<code>offHeap</code>的大小，否则会报错：</p><pre class="line-numbers language-none"><code class="language-none">Exception in thread &quot;main&quot; java.lang.IllegalArgumentException: Tiering Inversion: &#39;Pool &#123;100 MB offheap&#125;&#39; is not smaller than &#39;Pool &#123;20 MB disk&#125;&#39;at org.ehcache.impl.config.ResourcePoolsImpl.validateResourcePools(ResourcePoolsImpl.java:137)at org.ehcache.config.builders.ResourcePoolsBuilder.&lt;init&gt;(ResourcePoolsBuilder.java:53)</code></pre><ul><li><strong>集群缓存（Cluster）</strong></li></ul><p>作为单机缓存，数据都是存在各个进程内的，在分布式组网系统中，如果缓存数据发生变更，就会出现各个进程节点中缓存<strong>数据不一致</strong>的问题。为了解决这一问题，Ehcache支持通过<strong>集群</strong>的方式，将多个分布式节点组网成一个整体，保证相互节点之间的数据同步。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><p>需要注意的是，除了堆内缓存属于JVM堆内部，可以直接通过引用的方式进行访问，其余几种类型都属于JVM外部的数据交互，所以对这部分数据的读写时，需要先进行<code>序列化</code>与<code>反序列化</code>，因此要求缓存的数据对象一定要支持序列化与反序列化。</p><p>不同的缓存类型具有不同的运算处理速度，<strong>堆内缓存的速度最快</strong>，堆外缓存次之，集群缓存的速度最慢。为了兼具处理性能与缓存容量，可以采用多种缓存形式组合使用的方式，构建<code>多级缓存</code>来实现。组合上述几种不同缓存类型然后构建多级缓存的时候，也需要遵循几个约束：</p><ol><li>多级缓存中必须有<strong>堆内缓存</strong>，必须按照<code>堆内缓存 &lt; 堆外缓存 &lt; 磁盘缓存 &lt; 集群缓存</code>的顺序进行组合；</li><li>多级缓存中的容量设定必须遵循<code>堆内缓存 &lt; 堆外缓存 &lt; 磁盘缓存 &lt; 集群缓存</code>的原则；</li><li>多级缓存中<strong>不允许</strong><em>磁盘缓存</em>与<strong>集群缓存</strong>同时出现；</li></ol><p><img src="https://pics.codingcoder.cn/pics/202211181442326.png"></p><p>按照上述原则，可以组合出所有合法的多级缓存类型：</p><blockquote><p>堆内缓存 + 堆外缓存<br>堆内缓存 + 堆外缓存 + 磁盘缓存<br>堆内缓存 + 堆外缓存 + 集群缓存<br>堆内缓存 + 磁盘缓存<br>堆内缓存 + 集群缓存</p></blockquote><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h3 id="支持缓存持久化"><a href="#支持缓存持久化" class="headerlink" title="支持缓存持久化"></a>支持缓存持久化</h3><p>常规的基于内存的缓存都有一个通病就是无法持久化，每次重新启动的时候，缓存数据都会丢失，需要重新去构建。而Ehcache则支持使用磁盘来对缓存内容进行<strong>持久化</strong>保存。</p><p>如果需要开启持久化保存能力，我们首先需要在创建缓存的时候先指定下持久化结果存储的磁盘根目录，然后需要指定组合使用磁盘存储的容量，并选择开启持久化数据的能力。</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public static void main(String[] args) &#123;    CacheManager cacheManager &#x3D; CacheManagerBuilder.newCacheManagerBuilder()            .withCache(&quot;myCache&quot;, CacheConfigurationBuilder.newCacheConfigurationBuilder(Integer.class,                    String.class,                    ResourcePoolsBuilder.newResourcePoolsBuilder()                            .heap(1, MemoryUnit.MB)                            .disk(10, MemoryUnit.GB, true)) &#x2F;&#x2F; 指定需要持久化到磁盘                    .build())            .with(CacheManagerBuilder.persistence(&quot;d:\\myCache\\&quot;)) &#x2F;&#x2F; 指定持久化磁盘路径            .build(true);    Cache&lt;Integer, String&gt; myCache &#x3D; cacheManager.getCache(&quot;myCache&quot;, Integer.class, String.class);    myCache.put(1, &quot;value1&quot;);    myCache.put(2, &quot;value2&quot;);    System.out.println(myCache.get(2));    cacheManager.close();&#125;</code></pre><p>执行之后，指定的目录里面会留有对应的持久化文件记录：</p><p><img src="https://pics.codingcoder.cn/pics/202211180713297.png"></p><p>这样在进程重新启动的时候，会自动从持久化文件中读取内容并加载到缓存中，可以直接使用。比如我们将代码修改下，缓存创建完成后不执行<code>put</code>操作，而是直接去读取数据。比如还是上面的这段代码，将<code>put</code>操作注释掉，重新启动执行，依旧可以获取到缓存值。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h3 id="支持变身分布式缓存"><a href="#支持变身分布式缓存" class="headerlink" title="支持变身分布式缓存"></a>支持变身分布式缓存</h3><p>在本专栏开立后的第一篇文章《<a href="https://juejin.cn/post/7151937376578142216#heading-1">聊一聊作为高并发系统基石之一的缓存，会用很简单，用好才是技术活</a>》中，我们介绍了下在集群多节点场景下本地缓存经常会出现的一个<strong>缓存漂移</strong>问题。比如一个互动论坛系统里面，其中一个节点处理了修改请求并同步更新了自己的本地缓存，但是其余节点没有感知到这个变更操作，导致相互之间内存数据不一致，这个时候查询请求就会出现一会正常一会异常的情况。</p><p><img src="https://pics.codingcoder.cn/pics/202210010815833.png"></p><p>对于分布式系统，或者是集群场景下，并非是本地缓存的主战场。为了保证集群内数据的一致性，很多场景往往就直接选择<code>Redis</code>等<strong>集中式缓存</strong>。但是集中式缓存也弊端，比如有些数据并不怎么更新、但是每个节点对其依赖度却非常高，如果频繁地去Redis请求交互，又会导致大量的性能损耗在<strong>网络IO</strong>交互处理上。</p><p>针对这种情况，Ehcache给出了一个相对完美的答案：<code>本地 + 集群化</code>策略。即在本地缓存的基础上，将集群内各本地节点组成一个相互连接的网，然后基于某种机制，将一个节点上发生的变更同步给其余节点进行同步更新自身缓存数据，这样就可以实现各个节点的缓存数据一致。</p><p>Ehcache提供了多种不同的解决方案，可以将其由本地缓存变身为“分布式缓存”：</p><ul><li><p><code>RMI</code>组播方式</p></li><li><p><code>JMS</code>消息方式</p></li><li><p><code>Cache Server</code>模式</p></li><li><p><code>JGroup</code>方式</p></li><li><p><code>Terracotta</code>方式</p></li></ul><p>在下一篇文章中，将专门针对上面的几种方式进行展开介绍。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h3 id="更灵活和细粒度的过期时间设定"><a href="#更灵活和细粒度的过期时间设定" class="headerlink" title="更灵活和细粒度的过期时间设定"></a>更灵活和细粒度的过期时间设定</h3><p>前面我们介绍过的本地缓存框架Caffeine与Guava Cache，它们支持设定过期时间，但是仅允许为设定缓存<strong>容器级别统一</strong>的过期时间，容器内的所有元素都遵循同一个过期时间。</p><p>Ehcache不仅支持缓存容器对象级别统一的过期时间设定，还会支持为容器中每一条缓存记录设定<strong>独立过期时间</strong>，允许不同记录有不同的过期时间。这在某些场景下还是非常友好的，可以指定部分热点数据一个相对较长的过期时间，避免热点数据因为过期导致的<em>缓存击穿</em>。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h3 id="同时支持JCache与SpringCache规范"><a href="#同时支持JCache与SpringCache规范" class="headerlink" title="同时支持JCache与SpringCache规范"></a>同时支持JCache与SpringCache规范</h3><p>Ehcache作为一个标准化构建的通用缓存框架，同时支持了JAVA目前业界最为主流的两大缓存标准，即官方的JSR107标准以及使用非常广泛的Spring Cache标准，这样使得业务中可以基于标准化的缓存接口去调用，避免了Ehcache深度耦合到业务逻辑中去。</p><p>作为当前绝对主流的Spring框架，Ehcache可以做到无缝集成，便于项目中使用。在下面的章节中会专门介绍如何与Spring进行集成，此处先不赘述。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h2 id="Hibernate的默认缓存策略"><a href="#Hibernate的默认缓存策略" class="headerlink" title="Hibernate的默认缓存策略"></a>Hibernate的默认缓存策略</h2><p><code>Hibernate</code>是一个著名的开源<strong>ORM框架</strong>实现，提供了对<code>JDBC</code>的轻量级封装实现，可以在代码中以面向对象的方式去操作数据库数据，此前著名的<code>SSH</code>框架中的<code>H</code>，指的便是Hibernate框架。Hibernate支持一二级缓存，其中一级缓存是<em>session级别</em>的缓存，默认开启。而Hibernate的二级缓存，默认使用的便是Ehcache来实现的。能够被大名鼎鼎的Hibernate选中作为默认的缓存实现，也可以证明Ehcache不俗的实力。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h2 id="Ehcache、Caffeine、Redis如何选择"><a href="#Ehcache、Caffeine、Redis如何选择" class="headerlink" title="Ehcache、Caffeine、Redis如何选择"></a>Ehcache、Caffeine、Redis如何选择</h2><p>之前的文章中介绍过Caffeine的相关特性与用法，两者虽然同属JVM级别的本地缓存框架，但是两者在目标细分领域，还是各有侧重的。而作为具备分布式能力的本地缓存，Ehcache与天生的分布式集中式缓存之间似乎也存在一些功能上的重合度，那么<code>Ehcache</code>、<code>Caffeine</code>、<code>Redis</code>三者之间应该<strong>如何选择</strong>呢？先看下三者的定位：</p><ul><li><strong>Caffeine</strong></li></ul><ol><li>更加<strong>轻量级</strong>，使用更加简单，可以理解为一个<em>增强版的HashMap</em>；</li><li>足够<strong>纯粹</strong>，适用于仅需要本地缓存数据的常规场景，可以获取到绝佳的命中率与并发访问性能。</li></ol><ul><li><strong>Redis</strong></li></ul><ol><li>纯粹的<strong>集中</strong>缓存，为集群化、分布式多节点场景而生，可以保证缓存的一致性；</li><li>业务需要通过网络进行交互，相比与本地缓存而言<em>性能上会有损耗</em>。</li></ol><ul><li><strong>Ehcache</strong></li></ul><ol><li>支持多级缓存扩展能力。通过<code>内存+磁盘</code>等多种存储机制，解决缓存容量问题，适合本地缓存中对容量有特别要求的场景；</li><li>支持缓存数据<code>持久化</code>操作。允许将内存中的缓存数据持久化到磁盘上，进程启动的时候从磁盘加载到内存中；</li><li>支持多节点<code>集群化</code>组网。可以将分布式场景下的各个节点组成集群，实现缓存数据一致，解决缓存漂移问题。</li></ol><p>相比而言，Caffeine专注于提供纯粹且简单的本地基础缓存能力、Redis则聚焦统一缓存的数据一致性方面，而Ehcache的功能则是更为的<strong>中庸</strong>，介于两者之间，既具有本地缓存无可比拟的性能优势，又兼具分布式缓存的多节点数据一致性与容量扩展能力。项目里面进行选型的时候，可以结合上面的差异点，评估下自己的实际诉求，决定如何选择。</p><p>简单来说，把握如下原则即可：</p><ul><li><p>如果只是本地简单、少量缓存数据使用的，选择<code>Caffeine</code>；</p></li><li><p>如果本地缓存数据量较大、内存不足需要使用磁盘缓存的，选择<code>EhCache</code>；</p></li><li><p>如果是大型分布式多节点系统，业务对缓存使用较为重度，且各个节点需要依赖并频繁操作同一个缓存，选择<code>Redis</code>。</p></li></ul><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h2 id="小结回顾"><a href="#小结回顾" class="headerlink" title="小结回顾"></a>小结回顾</h2><p>好啦，关于<code>Ehcache</code>的一些问题关键特性，就介绍到这里了。不知道小伙伴们是否开始对Ehcache更加的感兴趣了呢？后面我们将一起来具体看下如何在项目中进行集成与使用Ehcache，充分去发掘与体验其强大之处。而关于Ehcache你是否有自己的一些想法与见解呢？欢迎评论区一起交流下，期待和各位小伙伴们一起切磋、共同成长。</p><p>📣 <strong>补充说明1</strong> ：</p><blockquote><p>本文属于《<a href="https://juejin.cn/column/7140852038258147358">深入理解缓存原理与实战设计</a>》系列专栏的内容之一。该专栏围绕缓存这个宏大命题进行展开阐述，全方位、系统性地深度剖析各种缓存实现策略与原理、以及缓存的各种用法、各种问题应对策略，并一起探讨下缓存设计的哲学。</p><p>如果有兴趣，也欢迎关注此专栏。</p></blockquote><p>📣 <strong>补充说明2</strong> ：</p><ul><li>关于本文中涉及的<strong>演示代码</strong>的完整示例，我已经整理并提交到github中，如果您有需要，可以自取：<a href="https://github.com/veezean/JavaBasicSkills">https://github.com/veezean/JavaBasicSkills</a></li></ul><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><p><strong>我是悟道，聊技术、又不仅仅聊技术~</strong></p><p>如果觉得有用，请<strong>点赞 + 关注</strong>让我感受到您的支持。也可以关注下我的公众号【架构悟道】，获取更及时的更新。</p><p>期待与你一起探讨，一起成长为更好的自己。</p><p><img src="https://pics.codingcoder.cn/pics/202207091312091.gif"></p><p><img src="https://pics.codingcoder.cn/pics/202207091317876.png"></p>]]></content>
      
      
      <categories>
          
          <category> 缓存原理与实战设计 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JAVA </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>解读JVM级别本地缓存Caffeine青出于蓝的要诀3 —— 讲透Caffeine的数据驱逐淘汰机制与用法</title>
      <link href="//post/20221224065417.html"/>
      <url>//post/20221224065417.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>上一篇文章中我们聊了Caffeine的同步、异步的数据回源方式。本篇文章我们再一起研讨下经Caffeine改良过的异步数据驱逐处理实现，以及Caffeine支持的多种不同的数据淘汰驱逐机制和对应的实际使用。</p></blockquote><hr><p><img src="https://pics.codingcoder.cn/pics/202210050807355.png"></p><p>大家好，又见面了。</p><hr><blockquote><p>本文是笔者作为掘金技术社区签约作者的身份输出的缓存专栏系列内容，将会通过系列专题，讲清楚缓存的方方面面。如果感兴趣，欢迎关注以获取后续更新。</p></blockquote><hr><p>上一篇文章中，我们聊了下<strong>Caffeine</strong>的同步、异步的数据回源方式。本篇文章我们再一起研讨下Caffeine的多种不同的数据<strong>淘汰驱逐机制</strong>，以及对应的实际使用。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h2 id="Caffeine的异步淘汰清理机制"><a href="#Caffeine的异步淘汰清理机制" class="headerlink" title="Caffeine的异步淘汰清理机制"></a>Caffeine的异步淘汰清理机制</h2><p>在惰性删除实现机制这边，Caffeine做了一些改进优化以提升在并发场景下的性能表现。我们可以和Guava Cache的基于容量大小的淘汰处理做个对比。</p><p>当限制了<code>Guava Cache</code>最大容量之后，有新的记录写入超过了总大小，会理解触发数据淘汰策略，然后腾出空间给新的记录写入。比如下面这段逻辑：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public static void main(String[] args) &#123;    Cache&lt;String, String&gt; cache &#x3D; CacheBuilder.newBuilder()            .maximumSize(1)            .removalListener(notification -&gt; System.out.println(notification.getKey() + &quot;被移除，原因：&quot; + notification.getCause()))            .build();    cache.put(&quot;key1&quot;, &quot;value1&quot;);    System.out.println(&quot;key1写入后，当前缓存内的keys：&quot; + cache.asMap().keySet());    cache.put(&quot;key2&quot;, &quot;value1&quot;);    System.out.println(&quot;key2写入后，当前缓存内的keys：&quot; + cache.asMap().keySet());&#125;</code></pre><p>其运行后的结果显示如下，可以很明显的看出，超出容量之后继续写入，会在<strong>写入前先执行缓存移除</strong>操作。</p><pre class="line-numbers language-none"><code class="language-none">key1写入后，当前缓存内的keys：[key1]key1被移除，原因：SIZEkey2写入后，当前缓存内的keys：[key2]</code></pre><p>同样地，我们看下使用<code>Caffeine</code>实现一个限制容量大小的缓存对象的处理表现，代码如下：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public static void main(String[] args) &#123;    Cache&lt;String, String&gt; cache &#x3D; Caffeine.newBuilder()            .maximumSize(1)            .removalListener((key, value, cause) -&gt; System.out.println(key + &quot;被移除，原因：&quot; + cause))            .build();    cache.put(&quot;key1&quot;, &quot;value1&quot;);    System.out.println(&quot;key1写入后，当前缓存内的keys：&quot; + cache.asMap().keySet());    cache.put(&quot;key2&quot;, &quot;value1&quot;);    System.out.println(&quot;key2写入后，当前缓存内的keys：&quot; + cache.asMap().keySet());&#125;</code></pre><p>运行这段代码，会发现Caffeine的容量限制功能似乎“<strong>失灵</strong>”了！从输出结果看<strong>并没有限制住</strong>：</p><pre class="line-numbers language-none"><code class="language-none">key1写入后，当前缓存内的keys：[key1]key2写入后，当前缓存内的keys：[key1, key2]</code></pre><p>什么原因呢？</p><p><code>Caffeine</code>为了提升读写操作的并发效率而将数据淘汰清理操作改为了<strong>异步处理</strong>，而异步处理时会有微小的延时，由此导致了上述看到的容量控制“失灵”现象。为了证实这一点，我们对上述的测试代码稍作修改，打印下调用线程与数据淘汰清理线程的线程ID，并且最后添加一个sleep等待操作：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public static void main(String[] args) throws Exception &#123;    System.out.println(&quot;当前主线程：&quot; + Thread.currentThread().getId());    Cache&lt;String, String&gt; cache &#x3D; Caffeine.newBuilder()            .maximumSize(1)            .removalListener((key, value, cause) -&gt;                    System.out.println(&quot;数据淘汰执行线程：&quot; + Thread.currentThread().getId()                            + &quot;，&quot; + key + &quot;被移除，原因：&quot; + cause))            .build();    cache.put(&quot;key1&quot;, &quot;value1&quot;);    System.out.println(&quot;key1写入后，当前缓存内的keys：&quot; + cache.asMap().keySe());    cache.put(&quot;key2&quot;, &quot;value1&quot;);    Thread.sleep(1000L); &#x2F;&#x2F; 等待一段时间时间，等待异步清理操作完成    System.out.println(&quot;key2写入后，当前缓存内的keys：&quot; + cache.asMap().keySet());&#125;</code></pre><p>再次执行上述测试代码，发现结果变的符合预期了，也可以看出Caffeine的确是另起了<strong>独立线程</strong>去执行<em>数据淘汰</em>操作的。</p><pre class="line-numbers language-none"><code class="language-none">当前主线程：1key1写入后，当前缓存内的keys：[key1]数据淘汰执行线程：13，key1被移除，原因：SIZEkey2写入后，当前缓存内的keys：[key2]</code></pre><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><p>深扒一下源码的实现，可以发现<code>Caffeine</code>在读写操作时会使用<strong>独立线程</strong>池执行对应的清理任务，如下图中的调用链执行链路 —— 这也证实了上面我们的分析。</p><p><img src="https://pics.codingcoder.cn/pics/202211131502827.png"></p><p>所以，严格意义来说，Caffeine的大小容量限制并不能够保证完全精准的小于设定的值，会存在<strong>短暂的误差</strong>，但是作为一个以<em>高并发吞吐量</em>为优先考量点的组件而言，这一点点的误差也是可以接受的。关于这一点，如果阅读源码仔细点的小伙伴其实也可以发现在很多场景的注释中，Caffeine也都会有明确的说明。比如看下面这段从源码中摘抄的描述，就清晰的写着“<strong>如果有同步执行的插入或者移除操作，实际的元素数量可能会出现差异</strong>”。</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public interface Cache&lt;K, V&gt; &#123;    &#x2F;**     * Returns the approximate number of entries in this cache. The value returned is an estimate; the     * actual count may differ if there are concurrent insertions or removals, or if some entries are     * pending removal due to expiration or weak&#x2F;soft reference collection. In the case of stale     * entries this inaccuracy can be mitigated by performing a &#123;@link #cleanUp()&#125; first.     *     * @return the estimated number of mappings     *&#x2F;    @NonNegative    long estimatedSize();  &#x2F;&#x2F; 省略其余内容...&#125;</code></pre><p>同样道理，不管是基于大小、还是基于过期时间或基于引用的数据淘汰策略，由于数据淘汰处理是异步进行的，都会存在<strong>短暂</strong>的<strong>不够精确</strong>的情况。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h2 id="多种淘汰机制"><a href="#多种淘汰机制" class="headerlink" title="多种淘汰机制"></a>多种淘汰机制</h2><p>上面提到并演示了Caffeine基于整体容量进行的数据驱逐策略。除了基于容量大小之外，Caffeine还支持基于时间与基于引用等方式来进行数据驱逐处理。</p><h3 id="基于时间"><a href="#基于时间" class="headerlink" title="基于时间"></a>基于时间</h3><p>Caffine支持<strong>基于时间</strong>进行数据的淘汰驱逐处理。这部分的能力与Guava Cache相同，支持根据记录<strong>创建时间</strong>以及<strong>访问时间</strong>两个维度进行处理。</p><p>数据的过期时间在创建缓存对象的时候进行指定，Caffeine在创建缓存对象的时候提供了<code>3种</code>设定过期策略的方法。</p><table><thead><tr><th>方式</th><th>具体说明</th></tr></thead><tbody><tr><td>expireAfterWrite</td><td>基于创建时间进行过期处理</td></tr><tr><td>expireAfterAccess</td><td>基于最后访问时间进行过期处理</td></tr><tr><td>expireAfter</td><td>基于<strong>个性化定制</strong>的逻辑来实现过期处理（可以定制基于<code>新增</code>、<code>读取</code>、<code>更新</code>等场景的过期策略，甚至支持为<em>不同记录指定不同过期时间</em>）</td></tr></tbody></table><p>下面逐个看下。</p><h4 id="expireAfterWrite"><a href="#expireAfterWrite" class="headerlink" title="expireAfterWrite"></a>expireAfterWrite</h4><p><code>expireAfterWrite</code>用于指定数据创建之后多久会过期，使用方式举例如下：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">Cache&lt;String, User&gt; userCache &#x3D;     Caffeine.newBuilder()        .expireAfterWrite(1, TimeUnit.SECONDS)        .build();userCache.put(&quot;123&quot;, new User(&quot;123&quot;, &quot;张三&quot;))；</code></pre><p>当记录被写入缓存之后达到指定的时间之后，就会被过期淘汰（<strong>惰性删除</strong>，并不会立即从内存中移除，而是在下一次操作的时候触发清理操作）。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h4 id="expireAfterAccess"><a href="#expireAfterAccess" class="headerlink" title="expireAfterAccess"></a>expireAfterAccess</h4><p><code>expireAfterAccess</code>用于指定缓存记录多久没有被访问之后就会过期。使用方式与expireAfterWrite类似：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">Cache&lt;String, User&gt; userCache &#x3D;     Caffeine.newBuilder()        .expireAfterAccess(1, TimeUnit.SECONDS)        .build();    userCache.get(&quot;123&quot;, s -&gt; userDao.getUser(s));</code></pre><p>这种是基于最后一次访问时间来计算数据是否过期，如果一个数据一直被访问，则其就不会过期。比较适用于<strong>热点数据</strong>的存储场景，可以保证较高的缓存命中率。同样地，数据过期时也不会被立即从内存中移除，而是基于<strong>惰性删除</strong>机制进行处理。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h4 id="expireAfter"><a href="#expireAfter" class="headerlink" title="expireAfter"></a>expireAfter</h4><p>上面两种设定过期时间的策略与Guava Cache是相似的。为了提供更为灵活的过期时间设定能力，Caffeine提供了一种全新的的过期时间设定方式，也即这里要介绍的<code>expireAfter</code>方法。其支持传入一个自定义的<code>Expiry</code>对象，自行实现数据的过期策略，甚至是针对不同的记录来定制不同的过期时间。</p><p>先看下Expiry接口中需要实现的三个方法：</p><table><thead><tr><th>方法名称</th><th>含义说明</th></tr></thead><tbody><tr><td>expireAfterCreate</td><td>指定一个过期时间，从记录创建的时候开始计时，超过指定的时间之后就过期淘汰，效果类似<code>expireAfterWrite</code>，但是支持<strong>更灵活</strong>的定制逻辑。</td></tr><tr><td>expireAfterUpdate</td><td>指定一个过期时间，从记录最后一次被更新的时候开始计时，超过指定的时间之后就过期。每次执行<strong>更新操作</strong>之后，都会重新计算过期时间。</td></tr><tr><td>expireAfterRead</td><td>指定一个过期时间，从记录最后一次被访问的时候开始计时，超过指定时间之后就过期。效果类似<code>expireAfterAccess</code>，但是支持<strong>更高级</strong>的定制逻辑。</td></tr></tbody></table><p>比如下面的代码中，定制了<code>expireAfterCreate</code>方法的逻辑，根据缓存key来决定过期时间，如果key以字母A开头则设定1s过期，否则设定2s过期：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public static void main(String[] args) &#123;    try &#123;        LoadingCache&lt;String, User&gt; userCache &#x3D; Caffeine.newBuilder()                .removalListener((key, value, cause) -&gt; &#123;                    System.out.println(key + &quot;移除，原因：&quot; + cause);                &#125;)                .expireAfter(new Expiry&lt;String, User&gt;() &#123;                    @Override                    public long expireAfterCreate(@NonNull String key, @NonNullUser value, long currentTime) &#123;                        if (key.startsWith(&quot;A&quot;)) &#123;                            return TimeUnit.SECONDS.toNanos(1);                        &#125; else &#123;                            return TimeUnit.SECONDS.toNanos(2);                        &#125;                    &#125;                    @Override                    public long expireAfterUpdate(@NonNull String key, @NonNullUser value, long currentTime,                                                  @NonNegative longcurrentDuration) &#123;                        return Long.MAX_VALUE;                    &#125;                    @Override                    public long expireAfterRead(@NonNull String key, @NonNull Uservalue, long currentTime,                                                @NonNegative long currentDuration)&#123;                        return Long.MAX_VALUE;                    &#125;                &#125;)                .build(key -&gt; userDao.getUser(key));        userCache.put(&quot;123&quot;, new User(&quot;123&quot;, &quot;123&quot;));        userCache.put(&quot;A123&quot;, new User(&quot;A123&quot;, &quot;A123&quot;));        Thread.sleep(1100L);        System.out.println(userCache.get(&quot;123&quot;));        System.out.println(userCache.get(&quot;A123&quot;));    &#125; catch (Exception e) &#123;        e.printStackTrace();    &#125;&#125;</code></pre><p>执行代码进行测试，可以发现，<strong>不同的key拥有了不同的过期时间</strong>：</p><pre class="line-numbers language-none"><code class="language-none">User(userName&#x3D;123, userId&#x3D;123, departmentId&#x3D;null)A123移除，原因：EXPIREDUser(userName&#x3D;A123, userId&#x3D;A123, departmentId&#x3D;null)</code></pre><p>除了根据<code>key</code>来定制不同的过期时间，也可以根据<code>value</code>的内容来指定不同的过期时间策略。也可以同时定制上述三个方法，搭配来实现更复杂的过期策略。</p><p>按照这种方式来定时过期时间的时候需要注意一点，如果不需要设定某一维度的过期策略的时候，需要将对应实现方法的返回值设置为一个非常大的数值，比如可以像上述示例代码中一样，指定为<code>Long.MAX_VALUE</code>值。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h3 id="基于大小"><a href="#基于大小" class="headerlink" title="基于大小"></a>基于大小</h3><p>除了前面提到的基于访问时间或者创建时间来执行数据过期淘汰的方式之外，Caffeine还支持针对缓存<strong>总体容量</strong>大小进行限制，如果容量满的时候，基于<code>W-TinyLFU</code>算法，淘汰最不常被使用的数据，腾出空间给新的记录写入。</p><p>Caffeine支持按照<code>Size</code>（记录条数）或者按照W<code>eighter</code>（记录权重）值进行总体容量的限制。关于Size和Weighter的区别，之前的文章中有介绍过，如果不清楚的小伙伴们可以查看下《<a href="https://juejin.cn/post/7161187654057328647#heading-1">重新认识下JVM级别的本地缓存框架Guava Cache(2)——深入解读其容量限制与数据淘汰策略</a>》。</p><h4 id="maximumSize"><a href="#maximumSize" class="headerlink" title="maximumSize"></a>maximumSize</h4><p>在创建Caffeine缓存对象的时候，可以通过<code>maximumSize</code>来指定允许缓存的最大条数。</p><p>比如下面这段代码：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">Cache&lt;Integer, String&gt; cache &#x3D; Caffeine.newBuilder()        .maximumSize(1000L) &#x2F;&#x2F; 限制最大缓存条数        .build();</code></pre><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h4 id="maximumWeight"><a href="#maximumWeight" class="headerlink" title="maximumWeight"></a>maximumWeight</h4><p>在创建Caffeine缓存对象的时候，可以通过<code>maximumWeight</code>与<code>weighter</code>组合的方式，指定按照权重进行限制缓存总容量。比如一个字符串value值的缓存场景下，我们可以根据字符串的长度来计算权重值，最后根据总权重大小来限制容量。</p><p>代码示意如下：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">Cache&lt;Integer, String&gt; cache &#x3D; Caffeine.newBuilder()        .maximumWeight(1000L) &#x2F;&#x2F; 限制最大权重值        .weigher((key, value) -&gt; (String.valueOf(value).length() &#x2F; 1000) + 1)        .build();</code></pre><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h4 id="使用注意点"><a href="#使用注意点" class="headerlink" title="使用注意点"></a>使用注意点</h4><p>需要注意一点：如果创建的时候指定了<code>weighter</code>，则必须同时指定<code>maximumWeight</code>值，如果不指定、或者指定了maximumSize，会<strong>报错</strong>（这一点与Guava Cache一致）：</p><pre class="line-numbers language-none"><code class="language-none">java.lang.IllegalStateException: weigher requires maximumWeightat com.github.benmanes.caffeine.cache.Caffeine.requireState(Caffeine.java:201)at com.github.benmanes.caffeine.cache.Caffeine.requireWeightWithWeigher(Caffeine.java:1215)at com.github.benmanes.caffeine.cache.Caffeine.build(Caffeine.java:1099)at com.veezean.skills.cache.caffeine.CaffeineCacheService.main(CaffeineCacheService.java:254)</code></pre><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h3 id="基于引用"><a href="#基于引用" class="headerlink" title="基于引用"></a>基于引用</h3><p>基于引用回收的策略，核心是利用<code>JVM</code>虚拟机的<strong>GC机制</strong>来达到数据清理的目的。当一个对象不再被引用的时候，JVM会选择在适当的时候将其回收。Caffeine支持<code>三种</code>不同的基于引用的回收方法：</p><table><thead><tr><th>方法</th><th>具体说明</th></tr></thead><tbody><tr><td>weakKeys</td><td>采用<code>弱引用</code>方式存储key值内容，当key对象不再被引用的时候，由<strong>GC</strong>进行回收</td></tr><tr><td>weakValues</td><td>采用<code>弱引用</code>方式存储value值内容，当value对象不再被引用的时候，由<strong>GC</strong>进行回收</td></tr><tr><td>softValues</td><td>采用<code>软引用</code>方式存储value值内容，当内存容量满时基于<strong>LRU</strong>策略进行回收</td></tr></tbody></table><p>下面逐个介绍下。</p><h4 id="weakKeys"><a href="#weakKeys" class="headerlink" title="weakKeys"></a>weakKeys</h4><p>默认情况下，我们创建出一个Caffeine缓存对象并写入<code>key-value</code>映射数据时，key和value都是以<strong>强引用</strong>的方式存储的。而使用<code>weakKeys</code>可以指定将缓存中的key值以<strong>弱引用</strong>（WeakReference）的方式进行存储，这样一来，如果程序运行时没有其它地方使用或者依赖此缓存值的时候，该条记录就可能会被<code>GC回收</code>掉。</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">LoadingCache&lt;String,  User&gt; loadingCache &#x3D; Caffeine.newBuilder()               .weakKeys()               .build(key -&gt; userDao.getUser(key));</code></pre><p>小伙伴们应该都有个基本的认知，就是两个对象进行比较是否相等的时候，要使用<code>equals</code>方法而非<code>==</code>。而且很多时候我们会主动去覆写<code>hashCode</code>方法与<code>equals</code>方法来指定两个对象的相等判断逻辑。但是基于引用的数据淘汰策略，关注的是引用地址值而非实际内容值，也即一旦使用<strong>weakKeys</strong>指定了基于引用方式回收，那么查询的时候将只能是使用同一个key对象（内存地址相同）才能够查询到数据，因为这种情况下查询的时候，使用的是<code>==</code>判断是否为同一个key。</p><p>看下面的例子：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public static void main(String[] args) &#123;    Cache&lt;String, String&gt; cache &#x3D; Caffeine.newBuilder()            .weakKeys()            .build();    String key1 &#x3D; &quot;123&quot;;    cache.put(key1, &quot;value1&quot;);    System.out.println(cache.getIfPresent(key1));    String key2 &#x3D; new String(&quot;123&quot;);    System.out.println(&quot;key1.equals(key2) ： &quot; + key1.equals(key2));    System.out.println(&quot;key1&#x3D;&#x3D;key2 ： &quot; + (key1&#x3D;&#x3D;key2));    System.out.println(cache.getIfPresent(key2));&#125;</code></pre><p>执行之后，会发现使用存入时的key1进行查询的时候是可以查询到数据的，而使用key2去查询的时候并没有查询到记录，虽然key1与key2的值都是字符串123！</p><pre class="line-numbers language-none"><code class="language-none">value1key1.equals(key2) ： truekey1&#x3D;&#x3D;key2 ： falsenull</code></pre><p>在实际使用的时候，这一点务必需要注意，对于新手而言，<strong>很容易踩进坑里</strong>。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h4 id="weakValues"><a href="#weakValues" class="headerlink" title="weakValues"></a>weakValues</h4><p>与weakKeys类似，我们可以在创建缓存对象的时候使用<code>weakValues</code>指定将value值以<strong>弱引用</strong>的方式存储到缓存中。这样当这条缓存记录的对象不再被引用依赖的时候，就会被JVM在适当的时候回收释放掉。</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">LoadingCache&lt;String,  User&gt; loadingCache &#x3D; Caffeine.newBuilder()               .weakValues()               .build(key -&gt; userDao.getUser(key));</code></pre><p>实际使用的时候需要注意<code>weakValues</code><strong>不支持</strong>在<code>AsyncLoadingCache</code>中使用。比如下面的代码：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public static void main(String[] args) &#123;    AsyncLoadingCache&lt;String, User&gt; cache &#x3D; Caffeine.newBuilder()            .weakValues()            .buildAsync(key -&gt; userDao.getUser(key));&#125;</code></pre><p>启动运行的时候，就会报错：</p><pre class="line-numbers language-none"><code class="language-none">Exception in thread &quot;main&quot; java.lang.IllegalStateException: Weak or soft values cannot be combined with AsyncLoadingCacheat com.github.benmanes.caffeine.cache.Caffeine.requireState(Caffeine.java:201)at com.github.benmanes.caffeine.cache.Caffeine.buildAsync(Caffeine.java:1192)at com.github.benmanes.caffeine.cache.Caffeine.buildAsync(Caffeine.java:1167)at com.veezean.skills.cache.caffeine.CaffeineCacheService.main(CaffeineCacheService.java:297)</code></pre><p>当然咯，很多时候也可以将<code>weakKeys</code>与<code>weakValues</code>组合起来使用，这样可以获得到两种能力的综合加成。</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">LoadingCache&lt;String,  User&gt; loadingCache &#x3D; Caffeine.newBuilder()               .weakKeys()               .weakValues()               .build(key -&gt; userDao.getUser(key));</code></pre><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h4 id="softValues"><a href="#softValues" class="headerlink" title="softValues"></a>softValues</h4><p><code>softValues</code>是指将缓存内容值以<strong>软引用</strong>的方式存储在缓存容器中，当<strong>内存容量满</strong>的时候Caffeine会以<code>LRU</code>（least-recently-used，最近最少使用）顺序进行数据淘汰回收。对比下其与weakValues的差异：</p><table><thead><tr><th>方式</th><th>具体描述</th></tr></thead><tbody><tr><td>weakValues</td><td><strong>弱引用</strong>方式存储，一旦不再被引用，则会被GC回收</td></tr><tr><td>softValues</td><td><strong>软引用</strong>方式存储，不会被GC回收，但是在内存容量满的时候，会基于<strong>LRU策略</strong>数据回收</td></tr></tbody></table><p>具体使用的时候，可以在创建缓存对象的时候进行指定基于软引用方式数据淘汰：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">LoadingCache&lt;String,  User&gt; loadingCache &#x3D; Caffeine.newBuilder()               .softValues()               .build(key -&gt; userDao.getUser(key));</code></pre><p>与weakValues一样，需要注意<code>softValues</code>也<strong>不支持</strong>在<code>AsyncLoadingCache</code>中使用。此外，还需要注意<code>softValues</code>与<code>weakValues</code>两者也<strong>不可以</strong>一起使用。</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public static void main(String[] args) &#123;    LoadingCache&lt;String, User&gt; cache &#x3D; Caffeine.newBuilder()            .weakKeys()            .weakValues()            .softValues()            .build(key -&gt; userDao.getUser(key));&#125;</code></pre><p>启动运行的时候，也会报错：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">Exception in thread &quot;main&quot; java.lang.IllegalStateException: Value strength was already set to WEAKat com.github.benmanes.caffeine.cache.Caffeine.requireState(Caffeine.java:201)at com.github.benmanes.caffeine.cache.Caffeine.softValues(Caffeine.java:572)at com.veezean.skills.cache.caffeine.CaffeineCacheService.main(CaffeineCacheService.java:297)</code></pre><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h2 id="小结回顾"><a href="#小结回顾" class="headerlink" title="小结回顾"></a>小结回顾</h2><p>好啦，关于<code>Caffeine Cache</code>的<strong>数据淘汰驱逐策略</strong>的实现原理与使用方式的阐述，就介绍到这里了。至此呢，关于Caffeine相关的内容就全部结束了，通过与Caffeine相关的这三篇文章，我们介绍完了Caffeine的整体情况、与Guava Cache相比的改进点、Caffeine的项目中使用，以及Caffeine在数据回源、数据驱逐等方面的展开探讨。关于<code>Caffeine Cache</code>，你是否有自己的一些想法与见解呢？欢迎评论区一起交流下，期待和各位小伙伴们一起切磋、共同成长。</p><blockquote><p>说起JAVA的本地缓存，除了此前提及的Guava Cache和这里介绍的Caffeine，还有一个同样无法被忽视的存在 —— Ehcache！作为被Hibernate选中的默认缓存实现框架，它究竟有什么魅力？它与Caffeine又有啥区别呢？接下来的文章中，我们就一起来认识下Ehcache，尝试找寻出答案。</p></blockquote><p>📣 <strong>补充说明1</strong> ：</p><blockquote><p>本文属于《<a href="https://juejin.cn/column/7140852038258147358">深入理解缓存原理与实战设计</a>》系列专栏的内容之一。该专栏围绕缓存这个宏大命题进行展开阐述，全方位、系统性地深度剖析各种缓存实现策略与原理、以及缓存的各种用法、各种问题应对策略，并一起探讨下缓存设计的哲学。</p><p>如果有兴趣，也欢迎关注此专栏。</p></blockquote><p>📣 <strong>补充说明2</strong> ：</p><ul><li>关于本文中涉及的<strong>演示代码</strong>的完整示例，我已经整理并提交到github中，如果您有需要，可以自取：<a href="https://github.com/veezean/JavaBasicSkills">https://github.com/veezean/JavaBasicSkills</a></li></ul><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><p><strong>我是悟道，聊技术、又不仅仅聊技术~</strong></p><p>如果觉得有用，请<strong>点赞 + 关注</strong>让我感受到您的支持。也可以关注下我的公众号【架构悟道】，获取更及时的更新。</p><p>期待与你一起探讨，一起成长为更好的自己。</p><p><img src="https://pics.codingcoder.cn/pics/202207091312091.gif"></p><p><img src="https://pics.codingcoder.cn/pics/202207091317876.png"></p>]]></content>
      
      
      <categories>
          
          <category> 缓存原理与实战设计 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JAVA </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>解读JVM级别本地缓存Caffeine青出于蓝的要诀2 —— 弄清楚Caffeine的同步、异步回源方式</title>
      <link href="//post/20221214070417.html"/>
      <url>//post/20221214070417.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>作为一种对外提供黑盒缓存能力的专门组件，Caffeine基于穿透型缓存模式进行构建。本文就深度全面聊一聊关于Caffeine的多种不同的数据回源方式、以及在同步异步场景下的实现与使用。</p></blockquote><hr><p><img src="https://pics.codingcoder.cn/pics/202210050807355.png"></p><p>大家好，又见面了。</p><hr><blockquote><p>本文是笔者作为掘金技术社区签约作者的身份输出的缓存专栏系列内容，将会通过系列专题，讲清楚缓存的方方面面。如果感兴趣，欢迎关注以获取后续更新。</p></blockquote><hr><p>上一篇文章中，我们继<em>Guava Cache</em>之后，又认识了青出于蓝的<strong>Caffeine</strong>。作为一种对外提供黑盒缓存能力的专门组件，<code>Caffeine</code>基于<strong>穿透型缓存</strong>模式进行构建。也即对外提供数据查询接口，会优先在缓存中进行查询，若命中缓存则返回结果，未命中则尝试去真正的源端（如：数据库）去获取数据并回填到缓存中，返回给调用方。</p><p><img src="https://pics.codingcoder.cn/pics/202210032116685.png"></p><p>与Guava Cache相似，<em>Caffeine</em>的<strong>回源</strong>填充主要有两种手段：</p><ul><li><p><code>Callable</code>方式</p></li><li><p><code>CacheLoader</code>方式</p></li></ul><p>根据执行调用方式不同，又可以细分为<strong>同步阻塞</strong>方式与<strong>异步非阻塞</strong>方式。</p><p>本文我们就一起探寻下Caffeine的多种不同的数据回源方式，以及对应的实际使用。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h2 id="同步方式"><a href="#同步方式" class="headerlink" title="同步方式"></a>同步方式</h2><p><strong>同步</strong>方式是最常被使用的一种形式。查询缓存、数据回源、数据回填缓存、返回执行结果等一系列操作都是在一个调用线程中<strong>同步阻塞</strong>完成的。</p><p><img src="https://pics.codingcoder.cn/pics/202211121655645.png"></p><h3 id="Callable"><a href="#Callable" class="headerlink" title="Callable"></a>Callable</h3><p>在每次<code>get</code>请求的时候，传入一个Callable函数式接口具体实现，当没有命中缓存的时候，Caffeine框架会执行给定的Callable实现逻辑，去获取真实的数据并且回填到缓存中，然后返回给调用方。</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public static void main(String[] args) &#123;    Cache&lt;String, User&gt; cache &#x3D; Caffeine.newBuilder().build();    User user &#x3D; cache.get(&quot;123&quot;, s -&gt; userDao.getUser(s));    System.out.println(user);&#125;</code></pre><p><code>Callable</code>方式的回源填充，有个明显的<strong>优势</strong>就是调用方可以根据自己的场景，<em>灵活</em>的给定不同的回源执行逻辑。但是这样也会带来一个<strong>问题</strong>，就是如果需要获取缓存的地方太多，会导致每个调用的地方都得指定下对应Callable回源方法，调用起来比较<strong>麻烦</strong>，且对于需要保证回源逻辑统一的场景<em>管控能力不够强势</em>，无法约束所有的调用方使用相同的回源逻辑。</p><p>这种时候，便需要<code>CacheLoader</code>登场了。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h3 id="CacheLoader"><a href="#CacheLoader" class="headerlink" title="CacheLoader"></a>CacheLoader</h3><p>在创建缓存对象的时候，可以通在<code>build()</code>方法中传入指定的<strong>CacheLoader</strong>对象的方式来指定回源时默认使用的回源数据加载器，这样当使用方调用<code>get</code>方法获取不到数据的时候，框架就会自动使用给定的<strong>CacheLoader</strong>对象执行对应的数据加载逻辑。</p><p>比如下面的代码中，便在创建缓存对象时指定了当缓存未命中时通过<code>userDao.getUser()</code>方法去<em>DB</em>中执行数据查询操作：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public LoadingCache&lt;String, User&gt; createUserCache() &#123;    return Caffeine.newBuilder()            .maximumSize(10000L)            .build(key -&gt; userDao.getUser(key));&#125;</code></pre><p>相比于Callable方式，CacheLoader更<strong>适用</strong>于<em>所有回源场景使用的回源策略都固定且统一</em>的情况。对具体业务使用的时候更加的友好，调用<code>get</code>方法也更加简单，只需要传入带查询的<code>key</code>值即可。</p><p>上面的示例代码中还有个需要关注的点，即创建缓存对象的时候指定了CacheLoader，最终创建出来的缓存对象是<strong>LoadingCache</strong>类型，这个类型是Cache的一个子类，扩展提供了<em>无需传入Callable参数的get方法</em>。进一步地，我们打印出对应的详细类名，会发现得到的缓存对象具体类型为：</p><pre class="line-numbers language-none"><code class="language-none">com.github.benmanes.caffeine.cache.BoundedLocalCache.BoundedLocalLoadingCache</code></pre><p>当然，如果创建缓存对象的时候没有指定最大容量限制，则创建出来的缓存对象还可能会是下面这个：</p><pre class="line-numbers language-none"><code class="language-none">com.github.benmanes.caffeine.cache.UnboundedLocalCache.UnboundedLocalManualCache</code></pre><p>通过<code>UML图</code>，可以清晰的看出其与Cache之间的继承与实现链路情况：</p><p><img src="https://pics.codingcoder.cn/pics/202211122120138.png"></p><p>因为LoadingCache是Cache对象的子类，根据JAVA中类继承的特性，<code>LoadingCache</code>也完全具备Cache所有的接口能力。所以，对于大部分场景都需要固定且统一的回源方式，但是某些特殊场景需要自定义回源逻辑的情况，也可以通过<strong>组合使用</strong>Callable的方式来实现。</p><p>比如下面这段代码：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public static void main(String[] args) &#123;    LoadingCache&lt;String, User&gt; cache &#x3D; Caffeine.newBuilder().build(userId -&gt; userDao.getUser(userId));    &#x2F;&#x2F; 使用CacheLoader回源    User user &#x3D; cache.get(&quot;123&quot;);    System.out.println(user);    &#x2F;&#x2F; 使用自定义Callable回源    User techUser &#x3D; cache.get(&quot;J234&quot;, userId -&gt; &#123;        &#x2F;&#x2F; 仅J开头的用户ID才会去回源        if (!StringUtils.isEmpty(userId) &amp;&amp; userId.startsWith(&quot;J&quot;)) &#123;            return userDao.getUser(userId);        &#125; else &#123;            return null;        &#125;    &#125;);    System.out.println(techUser);&#125;</code></pre><p>上述代码中，构造的是一个指定了CacheLoader的LoadingCache缓存类型，这样对于大众场景可以直接使用<code>get</code>方法由CacheLoader提供<strong>统一</strong>的回源能力，而特殊场景中也可以在<code>get</code>方法中传入需要的<strong>定制化回源</strong>Callable逻辑。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h3 id="不回源"><a href="#不回源" class="headerlink" title="不回源"></a>不回源</h3><p>在实际的缓存应用场景中，并非是所有的场景都要求缓存没有命中的时候要去执行回源查询。对于一些业务规划上无需执行回源操作的请求，也可以要求Caffeine不要执行回源操作（比如黑名单列表，只要用户在黑名单就禁止操作，不在黑名单则允许继续往后操作，因为大部分请求都不会命中到黑名单中，所以不需要执行回源操作）。为了实现这一点，在查询操作的时候，可以使用Caffeine提供的<strong>免回源查询</strong>方法来实现。</p><p>具体梳理如下：</p><table><thead><tr><th>接口</th><th>功能说明</th></tr></thead><tbody><tr><td>getIfPresent</td><td>从内存中查询，如果存在则返回对应值，不存在则返回null</td></tr><tr><td>getAllPresent</td><td>批量从内存中查询，如果存在则返回存在的键值对，不存在的key则不出现在结果集里</td></tr></tbody></table><p>代码使用演示如下：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public static void main(String[] args) &#123;    LoadingCache&lt;String, User&gt; cache &#x3D; Caffeine.newBuilder().build(userId -&gt; userDao.getUser(userId));    cache.put(&quot;124&quot;, new User(&quot;124&quot;, &quot;张三&quot;));    User userInfo &#x3D; cache.getIfPresent(&quot;123&quot;);    System.out.println(userInfo);    Map&lt;String, User&gt; presentUsers &#x3D;            cache.getAllPresent(Stream.of(&quot;123&quot;, &quot;124&quot;, &quot;125&quot;).collect(Collectors.toList()));    System.out.println(presentUsers);&#125;</code></pre><p>执行结果如下，可以发现执行的过程中并<strong>没有触发</strong>自动回源与回填操作：</p><pre class="line-numbers language-none"><code class="language-none">null&#123;124&#x3D;User(userName&#x3D;张三, userId&#x3D;124)&#125;</code></pre><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h2 id="异步方式"><a href="#异步方式" class="headerlink" title="异步方式"></a>异步方式</h2><p><code>CompletableFuture</code>并行流水线能力，是<code>JAVA8</code>在<strong>异步编程</strong>领域的一个重大改进。可以将一系列耗时且无依赖的操作改为并行同步处理，并等待各自处理结果完成后继续进行后续环节的处理，由此来降低阻塞等待时间，进而达到降低请求链路时长的效果。</p><p>很多小伙伴对JAVA8之后的<code>CompletableFuture</code>并行处理能力接触的不是很多，有兴趣的可以移步看下我之前专门介绍JAVA8流水线并行处理能力的介绍《<a href="https://juejin.cn/post/7124124854747398175">JAVA基于CompletableFuture的流水线并行处理深度实践，满满干货</a>》，相信可以让你对ComparableFututre并行编程有全面的认识与理解。</p><p>Caffeine完美的支持了在异步场景下的<strong>流水线</strong>处理使用场景，回源操作也支持<strong>异步</strong>的方式来完成。</p><h3 id="异步Callable"><a href="#异步Callable" class="headerlink" title="异步Callable"></a>异步Callable</h3><p>要想支持异步场景下使用缓存，则创建的时候必须要创建一个异步缓存类型，可以通过<code>buildAsync()</code>方法来构建一个<strong>AsyncCache</strong>类型缓存对象，进而可以在异步场景下进行使用。</p><p>看下面这段代码：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public static void main(String[] args) &#123;    AsyncCache&lt;String, User&gt; asyncCache &#x3D; Caffeine.newBuilder().buildAsyn();    CompletableFuture&lt;User&gt; userCompletableFuture &#x3D; asyncCache.get(&quot;123&quot;, s -&gt; userDao.getUser(s));    System.out.println(userCompletableFuture.join());&#125;</code></pre><p>上述代码中，get方法传入了Callable回源逻辑，然后会开始<strong>异步</strong>的加载处理操作，并返回了个CompletableFuture类型结果，最后如果需要获取其实际结果的时候，需要等待其异步执行完成然后获取到最终结果（通过上述代码中的<code>join()</code>方法等待并获取结果）。</p><p>我们可以比对下<em>同步</em>和<em>异步</em>两种方式下<code>Callable</code>逻辑执行线程情况。看下面的代码：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public static void main(String[] args) &#123;    System.out.println(&quot;main thread:&quot; + Thread.currentThread().getId());    &#x2F;&#x2F; 同步方式    Cache&lt;String, User&gt; cache &#x3D; Caffeine.newBuilder().build();    cache.get(&quot;123&quot;, s -&gt; &#123;        System.out.println(&quot;同步callable thread:&quot; + Thread.currentThread().getId());        return userDao.getUser(s);    &#125;);    &#x2F;&#x2F; 异步方式    AsyncCache&lt;String, User&gt; asyncCache &#x3D; Caffeine.newBuilder().buildAsync();    asyncCache.get(&quot;123&quot;, s -&gt; &#123;        System.out.println(&quot;异步callable thread:&quot; + Thread.currentThread().getId());        return userDao.getUser(s);    &#125;);&#125;</code></pre><p>执行结果如下：</p><pre class="line-numbers language-none"><code class="language-none">main thread:1同步callable thread:1异步callable thread:15</code></pre><p>结果很明显的可以看出，<strong>同步</strong>处理逻辑中，回源操作直接占用的<em>调用线程</em>进行操作，而<strong>异步</strong>处理时则是<em>单独线程</em>负责回源处理、<strong>不会阻塞</strong>调用线程的执行 —— 这也是异步处理的优势所在。</p><p>看到这里，也许会有小伙伴有疑问，虽然是异步执行的回源操作，但是最后还是要在调用线程里面阻塞等待异步执行结果的完成，似乎没有看出异步有啥优势？</p><p>异步处理的魅力，在于当一个耗时操作执行的同时，主线程可以继续去处理其它的事情，然后其余事务处理完成后，直接去取异步执行的结果然后继续往后处理。如果主线程无需执行其余处理逻辑，完全是阻塞等待异步线程加载完成，这种情况确实没有必要使用异步处理。</p><p>想象一个生活中的场景：</p><blockquote><p>周末休息的你出去逛街，去咖啡店点了一杯咖啡，然后服务员会给你一个订单小票。<br>当服务员在后台制作咖啡的时候，你并没有在店里等待，而是出门到隔壁甜品店又买了个面包。<br>当面包买好之后，你回到咖啡店，拿着订单小票去取咖啡。<br>取到咖啡后，你边喝咖啡边把面包吃了……嗝~</p></blockquote><p><img src="https://pics.codingcoder.cn/pics/165924635459460448860.png"></p><p>这种情况应该比较好理解了吧？如果是同步处理，你买咖啡的时候，需要在咖啡店一直等到咖啡做好然后才能再去甜品店买面包，这样耗时就比较长了。而采用异步处理的策略，你在等待咖啡制作的时候，继续去甜品店将面包买了，然后回来等待咖啡完成，这样整体的时间就缩短了。当然，如果你只想买个咖啡，也不需要买甜品面包，即你等待咖啡制作期间没有别的事情需要处理，那这时候你在不在咖啡店一直等到咖啡完成，都没有区别。</p><p>回到代码层面，下面代码演示了异步场景下<code>AsyncCache</code>的使用。</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public boolean isDevUser(String userId) &#123;    &#x2F;&#x2F; 获取用户信息    CompletableFuture&lt;User&gt; userFuture &#x3D; asyncCache.get(userId, s -&gt; userDao.getUser(s));    &#x2F;&#x2F; 获取公司研发体系部门列表    CompletableFuture&lt;List&lt;String&gt;&gt; devDeptFuture &#x3D;            CompletableFuture.supplyAsync(() -&gt; departmentDao.getDevDepartments());    &#x2F;&#x2F; 等用户信息、研发部门列表都拉取完成后，判断用户是否属于研发体系    CompletableFuture&lt;Boolean&gt; combineResult &#x3D;            userFuture.thenCombine(devDeptFuture,                    (user, devDepts) -&gt; devDepts.contains(user.getDepartmentId()));    &#x2F;&#x2F; 等待执行完成，调用线程获取最终结果    return combineResult.join();&#125;</code></pre><p>在上述代码中，需要获取到用户详情与研发部门列表信息，然后判断用户对应的部门是否属于研发部门，从而判断员工是否为研发人员。整体采用<strong>异步</strong>编程的思路，并使用了Caffeine<code>异步缓存</code>的操作方式，实现了用户获取与研发部门列表获取这两个耗时操作并行的处理，提升整体处理效率。</p><p><img src="https://pics.codingcoder.cn/pics/202211122053142.png"></p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h3 id="异步CacheLoader"><a href="#异步CacheLoader" class="headerlink" title="异步CacheLoader"></a>异步CacheLoader</h3><p>异步处理的时候，Caffeine也支持直接在创建的时候指定CacheLoader对象，然后生成支持异步回源操作的<code>AsyncLoadingCache</code>缓存对象，然后在使用<code>get</code>方法获取结果的时候，也是返回的<code>CompletableFuture</code>异步封装类型，满足在异步编程场景下的使用。</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public static void main(String[] args) &#123;    try &#123;        AsyncLoadingCache&lt;String, User&gt; asyncLoadingCache &#x3D;                Caffeine.newBuilder().maximumSize(1000L).buildAsync(key -&gt; userDao.getUser(key));        CompletableFuture&lt;User&gt; userCompletableFuture &#x3D; asyncLoadingCache.get(&quot;123&quot;);        System.out.println(userCompletableFuture.join());    &#125; catch (Exception e) &#123;        e.printStackTrace();    &#125;&#125;</code></pre><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h3 id="异步AsyncCacheLoader"><a href="#异步AsyncCacheLoader" class="headerlink" title="异步AsyncCacheLoader"></a>异步AsyncCacheLoader</h3><p>除了上述这种方式，在创建的时候给定一个用于回源处理的CacheLoader之外，Caffeine还有一个<code>buildAsync</code>的重载版本，允许传入一个同样是支持异步并行处理的<code>AsyncCacheLoader</code>对象。使用方式如下：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public static void main(String[] args) &#123;    try &#123;        AsyncLoadingCache&lt;String, User&gt; asyncLoadingCache &#x3D;                Caffeine.newBuilder().maximumSize(1000L).buildAsync(                        (key, executor) -&gt; CompletableFuture.supplyAsync(() -&gt; userDao.getUser(key), executor)                );        CompletableFuture&lt;User&gt; userCompletableFuture &#x3D; asyncLoadingCache.get(&quot;123&quot;);        System.out.println(userCompletableFuture.join());    &#125; catch (Exception e) &#123;        e.printStackTrace();    &#125;&#125;</code></pre><p>与上一章节中的代码比对可以发现，不管是使用<code>CacheLoader</code>还是<code>AsyncCacheLoader</code>对象，最终生成的缓存类型都是<strong>AsyncLoadingCache</strong>类型，使用的时候也并没有实质性的差异，两种方式的差异点仅在于传入<code>buildAsync</code>方法中的对象类型不同而已，使用的时候可以根据喜好自行选择。</p><p>进一步地，如果我们尝试将上面代码中的<code>asyncLoadingCache</code>缓存对象的具体类型打印出来，我们会发现其具体类型可能是：</p><pre class="line-numbers language-none"><code class="language-none">com.github.benmanes.caffeine.cache.BoundedLocalCache.BoundedLocalAsyncLoadingCache</code></pre><p>而如果我们在构造缓存对象的时候没有限制其最大容量信息，其构建出来的缓存对象类型还可能会是下面这个：</p><pre class="line-numbers language-none"><code class="language-none">com.github.benmanes.caffeine.cache.UnboundedLocalCache.UnboundedLocalAsyncLoadingCache</code></pre><p>与前面同步方式一样，我们也可以看下这两个具体的缓存类型对应的<code>UML类</code>图关系：</p><p><img src="https://pics.codingcoder.cn/pics/202211122125804.png"></p><p>可以看出，异步缓存不同类型最终都实现了同一个AsyncCache顶层接口类，而<code>AsyncLoadingCache</code>作为继承自<em>AsyncCache</em>的子类，除具备了AsyncCache的所有接口外，还额外扩展了部分的接口，以支持未命中目标时自动使用指定的CacheLoader或者AysncCacheLoader对象去执行回源逻辑。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h2 id="小结回顾"><a href="#小结回顾" class="headerlink" title="小结回顾"></a>小结回顾</h2><p>好啦，关于<code>Caffeine Cache</code>的同步、异步数据回源操作原理与使用方式的阐述，就介绍到这里了。不知道小伙伴们是否对Caffeine Cache的回源机制有了全新的认识了呢？而关于Caffeine Cache，你是否有自己的一些想法与见解呢？欢迎评论区一起交流下，期待和各位小伙伴们一起切磋、共同成长。</p><blockquote><p>下一篇文章中，我们将深入讲解下Caffeine改良过的异步数据驱逐处理实现，以及Caffeine支持的多种不同的数据淘汰驱逐机制和对应的实际使用。如有兴趣，欢迎关注后续更新。</p></blockquote><p>📣 <strong>补充说明1</strong> ：</p><blockquote><p>本文属于《<a href="https://juejin.cn/column/7140852038258147358">深入理解缓存原理与实战设计</a>》系列专栏的内容之一。该专栏围绕缓存这个宏大命题进行展开阐述，全方位、系统性地深度剖析各种缓存实现策略与原理、以及缓存的各种用法、各种问题应对策略，并一起探讨下缓存设计的哲学。</p><p>如果有兴趣，也欢迎关注此专栏。</p></blockquote><p>📣 <strong>补充说明2</strong> ：</p><ul><li>关于本文中涉及的<strong>演示代码</strong>的完整示例，我已经整理并提交到github中，如果您有需要，可以自取：<a href="https://github.com/veezean/JavaBasicSkills">https://github.com/veezean/JavaBasicSkills</a></li></ul><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><p><strong>我是悟道，聊技术、又不仅仅聊技术~</strong></p><p>如果觉得有用，请<strong>点赞 + 关注</strong>让我感受到您的支持。也可以关注下我的公众号【架构悟道】，获取更及时的更新。</p><p>期待与你一起探讨，一起成长为更好的自己。</p><p><img src="https://pics.codingcoder.cn/pics/202207091312091.gif"></p><p><img src="https://pics.codingcoder.cn/pics/202207091317876.png"></p>]]></content>
      
      
      <categories>
          
          <category> 缓存原理与实战设计 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JAVA </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>解读JVM级别本地缓存Caffeine青出于蓝的要诀 —— 缘何会更强、如何去上手</title>
      <link href="//post/20221207075417.html"/>
      <url>//post/20221207075417.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>继Guava Cache之后，我们再来聊一下各方面表现都更佳的Caffeine，看一下其具体使用方式、核心的优化改进点，窥探其青出于蓝的秘密所在。</p></blockquote><p><img src="https://pics.codingcoder.cn/pics/202210050807355.png"></p><p>大家好，又见面了。</p><hr><blockquote><p>本文是笔者作为掘金技术社区签约作者的身份输出的缓存专栏系列内容，将会通过系列专题，讲清楚缓存的方方面面。如果感兴趣，欢迎关注以获取后续更新。</p></blockquote><hr><p>在前面的几篇文章中，我们一起聊了下本地缓存的动手实现、本地缓存相关的规范等，也聊了下Google的Guava Cache的相关原理与使用方式。比较心急的小伙伴已经坐不住了，提到本地缓存，怎么能不提一下“<strong>地上最强</strong>”的<code>Caffeine Cache</code>呢？</p><p><img src="https://pics.codingcoder.cn/pics/202211092016433.png"></p><p>能被小伙伴称之为“地上最强”，可见<strong>Caffeine</strong>的魅力之大！的确，提到JAVA中的本地缓存框架，<code>Caffeine</code>是怎么也没法轻视的重磅嘉宾。前面几篇文章中，我们一起探索了JVM级别的优秀缓存框架Guava Cache，而相比之下，Caffeine可谓是站在巨人肩膀上，在很多方面做了深度的<strong>优化</strong>与<strong>改良</strong>，可以说在<em>性能表现</em>与<em>命中率</em>上全方位的碾压Guava Cache，表现堪称卓越。</p><p>下面就让我们一起来解读下Caffeine Cache的设计实现改进点原理，揭秘Caffeine Cache青出于蓝的秘密所在，并看下如何在项目中快速的上手使用。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h2 id="巨人肩膀上的产物"><a href="#巨人肩膀上的产物" class="headerlink" title="巨人肩膀上的产物"></a>巨人肩膀上的产物</h2><p>先来回忆下之前创建一个<code>Guava cache</code>对象时的代码逻辑：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public LoadingCache&lt;String, User&gt; createUserCache() &#123;    return CacheBuilder.newBuilder()            .initialCapacity(1000)            .maximumSize(10000L)            .expireAfterWrite(30L, TimeUnit.MINUTES)             .concurrencyLevel(8)            .recordStats()            .build((CacheLoader&lt;String, User&gt;) key -&gt; userDao.getUser(key));&#125;</code></pre><p>而使用<code>Caffeine</code>来创建Cache对象的时候，我们可以这么做：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public LoadingCache&lt;String, User&gt; createUserCache() &#123;    return Caffeine.newBuilder()            .initialCapacity(1000)            .maximumSize(10000L)            .expireAfterWrite(30L, TimeUnit.MINUTES)            &#x2F;&#x2F;.concurrencyLevel(8)            .recordStats()            .build(key -&gt; userDao.getUser(key));&#125;</code></pre><p>可以发现，两者的使用思路与方法定义非常相近，对于使用过Guava Cache的小伙伴而言，几乎可以<strong>无门槛</strong>的直接上手使用。当然，两者也还是有点差异的，比如Caffeine创建对象时<strong>不支持</strong>使用<code>concurrencyLevel</code>来指定并发量（因为改进了并发控制机制），这些我们在下面章节中具体介绍。</p><p>相较于Guava Cache，<code>Caffeine</code>在整体设计理念、实现策略以及接口定义等方面都基本继承了前辈的优秀特性。作为新时代背景下的后来者，Caffeine也做了很多细节层面的优化，比如：</p><ul><li><p><strong>基础数据结构层面优化</strong><br>借助JAVA8对<code>ConcurrentHashMap</code>底层由链表切换为<strong>红黑树</strong>、以及<strong>废弃分段锁</strong>逻辑的优化，提升了<em>Hash冲突</em>时的查询效率以及<em>并发场景</em>下的处理性能。</p></li><li><p><strong>数据驱逐（淘汰）策略的优化</strong><br>通过使用改良后的<code>W-TinyLFU</code>算法，提供了更佳的热点数据留存效果，提供了<strong>近乎完美</strong>的热点数据<code>命中率</code>，以及更低消耗的过程维护</p></li><li><p><strong>异步并行能力的全面支持</strong><br>完美适配<code>JAVA8</code>之后的<strong>并行编程</strong>场景，可以提供更为优雅的并行编码体验与并发效率。</p></li></ul><p>通过各种措施的改良，成就了Caffeine在功能与性能方面不俗的表现。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h2 id="Caffeine与Guava-——-是传承而非竞争"><a href="#Caffeine与Guava-——-是传承而非竞争" class="headerlink" title="Caffeine与Guava —— 是传承而非竞争"></a>Caffeine与Guava —— 是传承而非竞争</h2><p>很多人都知道Caffeine在各方面的表现都由于Guava Cache， 甚至对比之下有些小伙伴觉得Guava Cache简直一无是处。但不可否认的是，在曾经的一段时光里，Guava Cache提供了尽可能高效且轻量级的并发本地缓存工具框架。技术总是在不断的更新与迭代的，纵使优秀如<code>Guava Cache</code>这般，终究是难逃沦为<strong>时代眼泪</strong>的结局。</p><p>纵观<code>Caffeine</code>，其原本就是基于Guava cache基础上孵化而来的改良版本，众多的特性与设计思路都完全沿用了Guava Cache相同的逻辑，且提供的接口与使用风格也与Guava Cache无异。所以，从这个层面而言，本人更愿意将Caffeine看作是Guava Cache的一种优秀基因的<strong>传承</strong>与发扬光大，而非是<strong>竞争</strong>与打压关系。</p><p>那么Caffeine能够青出于蓝的秘诀在哪呢？下面总结了其最关键的<strong>3大要点</strong>，一起看下。</p><h3 id="贯穿始终的异步策略"><a href="#贯穿始终的异步策略" class="headerlink" title="贯穿始终的异步策略"></a>贯穿始终的异步策略</h3><p>Caffeine在请求上的处理流程做了很多的优化，效果比较显著的当属数据淘汰处理执行策略的改进。之前在<code>Guava Cache</code>的介绍中，有提过Guava Cache的策略是在请求的时候同时去执行对应的清理操作，也就是<strong>读请求中混杂着写操作</strong>，虽然Guava Cache做了一系列的策略来减少其触发的概率，但一旦触发总归是会对读取操作的性能有一定的影响。</p><p><img src="https://pics.codingcoder.cn/pics/202211142219373.png"></p><p><code>Caffeine</code>则采用了<strong>异步处理</strong>的策略，<code>get</code>请求中虽然也会触发淘汰数据的清理操作，但是将清理任务添加到了独立的线程池中进行异步的<strong>不会阻塞</strong> <code>get</code> 请求的执行与返回，这样大大缩短了<code>get</code>请求的执行时长，提升了响应性能。</p><p>除了对自身的异步处理优化，Caffeine还提供了全套的<code>Async</code>异步处理机制，可以支持业务在异步并行流水线式处理场景中使用以获得更加丝滑的体验。</p><p>Caffeine完美的支持了在异步场景下的<strong>流水线</strong>处理使用场景，回源操作也支持<strong>异步</strong>的方式来完成。<code>CompletableFuture</code>并行流水线能力，是<code>JAVA8</code>在<strong>异步编程</strong>领域的一个重大改进。可以将一系列耗时且无依赖的操作改为并行同步处理，并等待各自处理结果完成后继续进行后续环节的处理，由此来降低阻塞等待时间，进而达到降低请求链路时长的效果。</p><p>比如下面这段异步场景使用Caffeine并行处理的代码：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public static void main(String[] args) throws Exception &#123;    AsyncLoadingCache&lt;String, String&gt; asyncLoadingCache &#x3D; buildAsyncLoadingCache();    &#x2F;&#x2F; 写入缓存记录（value值为异步获取）    asyncLoadingCache.put(&quot;key1&quot;, CompletableFuture.supplyAsync(() -&gt; &quot;value1&quot;));    &#x2F;&#x2F; 异步方式获取缓存值    CompletableFuture&lt;String&gt; completableFuture &#x3D; asyncLoadingCache.get(&quot;key1&quot;);    String value &#x3D; completableFuture.join();    System.out.println(value);&#125;</code></pre><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h3 id="ConcurrentHashMap优化特性"><a href="#ConcurrentHashMap优化特性" class="headerlink" title="ConcurrentHashMap优化特性"></a>ConcurrentHashMap优化特性</h3><p>作为使用JAVA8新特性进行构建的Caffeine，充分享受了JAVA8语言层面优化改进所带来的性能上的增益。我们知道<code>ConcurrentHashMap</code>是JDK原生提供的一个线程安全的HashMap容器类型，而Caffeine底层也是基于ConcurrentHashMap进行构建与数据存储的。</p><p>在<strong>JAVA7</strong>以及更早的版本中，ConcurrentHashMap采用的是<code>分段锁</code>的策略来实现线程安全的（前面文章中我们讲过Guava Cache采用的也是分段锁的策略），分段锁虽然在一定程度上可以降低锁竞争的冲突，但是在一些极高并发场景下，或者并发请求分布较为集中的时候，仍然会出现较大概率的阻塞等待情况。此外，这些版本中ConcurrentHashMap底层采用的是<code>数组+链表</code>的存储形式，这种情况在<strong>Hash冲突</strong>较为明显的情况下，需要频繁的<em>遍历链表</em>操作，也会影响整体的处理性能。</p><p><strong>JAVA8</strong>中对ConcurrentHashMap的实现策略进行了较大调整，大幅提升了其在的并发场景的性能表现。主要可以分为<code>2个方面</code>的优化。</p><ul><li><strong>数组+链表结构自动升级为<code>数组+红黑树</code></strong></li></ul><p>默认情况下，ConcurrentHashMap的底层结构是<em>数组+链表</em>的形式，元素存储的时候会先计算下key对应的Hash值来将其划分到对应的数组对应的链表中，而当链表中的元素个数超过8个的时候，链表会自动转换为<code>红黑树</code>结构。如下所示：</p><p><img src="https://pics.codingcoder.cn/pics/202206281633385.png"></p><p>在遍历查询方面，红黑树有着比链表要更加卓越的性能表现。</p><ul><li><strong>分段锁升级为<code>synchronized+CAS</code>锁</strong></li></ul><p>分段锁的核心思想就是缩小锁的范围，进而降低锁竞争的概率。当数据量特别大的时候，其实每个锁涵盖的数据范围依旧会很大，如果并发请求量特别大的时候，依旧会出现很多线程抢夺同一把分段锁的情况。</p><p><img src="https://pics.codingcoder.cn/pics/165924683167139344194.png"></p><p>在JAVA8中，ConcurrentHashMap <strong>废弃分段锁</strong>的概念，改为了<code>synchronized+CAS</code>的策略，借助CAS的<strong>乐观锁</strong>策略，大大提升了<em>读多写少</em>场景下的并发能力。</p><p>得益于JAVA8对<code>ConcurrentHashMap</code>的优化，使得Caffeine在多线程并发场景下的表现非常的出色。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h3 id="淘汰算法W-LFU的加持"><a href="#淘汰算法W-LFU的加持" class="headerlink" title="淘汰算法W-LFU的加持"></a>淘汰算法W-LFU的加持</h3><p>常规的<strong>缓存淘汰算法</strong>一般采用<code>FIFO</code>、<code>LRU</code>或者<code>LFU</code>，但是这些算法在实际缓存场景中都会存在一些<strong>弊端</strong>：</p><table><thead><tr><th>算法</th><th>弊端说明</th></tr></thead><tbody><tr><td>FIFO</td><td><code>先进先出</code>策略，属于一种最为简单与原始的策略。如果缓存使用频率较高，会导致缓存数据<strong>始终在不停的进进出出</strong>，影响性能，且命中率表现也一般。</td></tr><tr><td>LRU</td><td><code>最近最久未使用</code>策略，保留最近被访问到的数据，而淘汰最久没有被访问的数据。如果遇到偶尔的批量刷数据情况，<strong>很容易将其他缓存内容都挤出内存</strong>，带来缓存击穿的风险。</td></tr><tr><td>LFU</td><td><code>最近少频率</code>策略，这种根据访问次数进行淘汰，相比而言内存中存储的热点数据命中率会更高些，缺点就是<strong>需要维护独立字段</strong>用来记录每个元素的访问次数，占用内存空间。</td></tr></tbody></table><p>为了保证命中率，一般缓存框架都会选择使用LRU或者LFU策略，很少会有使用FIFO策略进行数据淘汰的。Caffeine缓存的LFU采用了<code>Count-Min Sketch</code>频率统计算法（参见下图示意，图片来源：<a href="https://www.jianshu.com/p/3c6161e5337b">点此查看</a>），由于该LFU的计数器只有<code>4bit</code>大小，所以称为<strong>TinyLFU</strong>。在TinyLFU算法基础上引入一个基于LRU的<code>Window Cache</code>，这个新的算法叫就叫做<strong>W-TinyLFU</strong>。</p><p><img src="https://pics.codingcoder.cn/pics/202211142245058.png" alt="图源网络"><br><img src="https://pics.codingcoder.cn/pics/202211142247540.png" alt="图源网络"></p><p><code>W-TinyLFU</code>算法有效的解决了LRU以及LFU存在的弊端，为Caffeine提供了大部分场景下<strong>近乎完美</strong>的<strong>命中率</strong>表现。</p><p>关于<code>W-TinyLFU</code>的具体说明，有兴趣的话可以<a href="https://www.jianshu.com/p/3c6161e5337b">点此了解</a>。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h3 id="如何选择"><a href="#如何选择" class="headerlink" title="如何选择"></a>如何选择</h3><p>在Caffeine与Guava Cache之间如何选择？其实Spring已经给大家做了示范，从<code>Spring5</code>开始，其内置的本地缓存框架由Guava Cache切换到了Caffeine。应用到项目中的缓存选型，可以结合项目实际从多个方面进行抉择。</p><ul><li><p><strong>全新项目</strong>，闭眼选Caffeine<br>Java8也已经被广泛的使用多年，现在的新项目基本上都是JAVA8或以上的版本了。如果有新的项目需要做本地缓存选型，闭眼选择Caffeine就可以，错不了。</p></li><li><p>历史<strong>低版本JAVA项目</strong><br>由于Caffeine对JAVA版本有依赖要求，对于一些历史项目的维护而言，如果项目的<strong>JDK版本过低</strong>则无法使用Caffeine，这种情况下<code>Guava Cache</code>依旧是一个不错的选择。当然，也可以下定决心将项目的JDK版本升级到<code>JDK1.8+</code>版本，然后使用Caffeine来获得更好的性能体验 —— 但是对于一个历史项目而言，升级基础JDK版本带来的影响可能会比较大，需要提前评估好。</p></li><li><p>有同时使用<strong>Guava其它能力</strong><br>如果你的项目里面已经有引入并使用了Guava提供的相关功能，这种情况下为了避免太多外部组件的引入，也可以直接使用Guava提供的Cache组件能力，毕竟Guava Cache的表现并不算差，应付常规场景的本都缓存诉求完全足够。当然，为了追求更加极致的性能表现，另外引入并使用Caffeine也完全没有问题。</p></li></ul><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h2 id="Caffeine使用"><a href="#Caffeine使用" class="headerlink" title="Caffeine使用"></a>Caffeine使用</h2><h3 id="依赖引入"><a href="#依赖引入" class="headerlink" title="依赖引入"></a>依赖引入</h3><p>使用Caffeine，首先需要引入对应的库文件。如果是<em>Maven</em>项目，则可以在<code>pom.xml</code>中添加依赖声明来完成引入。</p><pre class="line-numbers language-markup" data-language="markup"><code class="language-markup">&lt;dependency&gt;    &lt;groupId&gt;com.github.ben-manes.caffeine&lt;&#x2F;groupId&gt;    &lt;artifactId&gt;caffeine&lt;&#x2F;artifactId&gt;    &lt;version&gt;3.1.1&lt;&#x2F;version&gt;&lt;&#x2F;dependency&gt;</code></pre><p>注意，如果你的本地<em>JDK版本比较低</em>，引入上述较新版本的时候可能会编译报错：</p><p><img src="https://pics.codingcoder.cn/pics/202211092150853.png"></p><p>遇到这种情况，可以考虑升级本地JDK版本（实际项目中升级可能有难度），或者将Caffeine版本降低一些，比如使用<code>2.9.3</code>版本。具体的版本列表，可以<a href="https://mvnrepository.com/artifact/com.github.ben-manes.caffeine/caffeine">点击此处</a>进行查询。</p><p>这样便大功告成啦。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h3 id="容器创建"><a href="#容器创建" class="headerlink" title="容器创建"></a>容器创建</h3><p>和之前我们聊过的Guava Cache创建缓存对象的操作相似，我们可以通过构造器来方便的创建出一个Caffeine对象。</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">Cache&lt;Integer, String&gt; cache &#x3D; Caffeine.newBuilder().build();</code></pre><p>除了上述这种方式，Caffeine还支持使用不同的构造器方法，构建不同类型的Caffeine对象。对各种构造器方法梳理如下：</p><table><thead><tr><th>方法</th><th>含义说明</th></tr></thead><tbody><tr><td>build()</td><td>构建一个手动回源的Cache对象</td></tr><tr><td>build(CacheLoader)</td><td>构建一个支持使用给定CacheLoader对象进行自动回源操作的LoadingCache对象</td></tr><tr><td>buildAsync()</td><td>构建一个支持异步操作的异步缓存对象</td></tr><tr><td>buildAsync(CacheLoader)</td><td>使用给定的CacheLoader对象构建一个支持异步操作的缓存对象</td></tr><tr><td>buildAsync(AsyncCacheLoader)</td><td>与buildAsync(CacheLoader)相似，区别点仅在于传入的参数类型不一样。</td></tr></tbody></table><p>为了便于<strong>异步场景</strong>中处理，可以通过<code>buildAsync()</code>构建一个手动回源数据加载的缓存对象：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public static void main(String[] args) &#123;    AsyncCache&lt;String, User&gt; asyncCache &#x3D; Caffeine.newBuilder()    .buildAsync();    User user &#x3D; asyncCache.get(&quot;123&quot;, s -&gt; &#123;        System.out.println(&quot;异步callable thread:&quot; + Thread.currentThread().getId());        return userDao.getUser(s);    &#125;).join();&#125;</code></pre><p>当然，为了支持异步场景中的自动异步回源，我们可以通过<code>buildAsync(CacheLoader)</code>或者<code>buildAsync(AsyncCacheLoader)</code>来实现：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public static void main(String[] args) throws Exception&#123;    AsyncLoadingCache&lt;String, User&gt; asyncLoadingCache &#x3D;            Caffeine.newBuilder().maximumSize(1000L).buildAsync(key -&gt; userDao.getUser(key));    User user &#x3D; asyncLoadingCache.get(&quot;123&quot;).join();&#125;</code></pre><p>在创建缓存对象的同时，可以指定此缓存对象的一些处理策略，比如<em>容量限制</em>、比如<em>过期策略</em>等等。作为以替换Guava Cache为己任的后继者，Caffeine在缓存容器对象创建时的相关构建API也沿用了与Guava Cache相同的定义，常见的方法及其含义梳理如下：</p><table><thead><tr><th>方法</th><th>含义说明</th></tr></thead><tbody><tr><td>initialCapacity</td><td>待创建的缓存容器的初始容量大小（记录<strong>条数</strong>）</td></tr><tr><td>maximumSize</td><td>指定此缓存容器的最大容量(最大缓存记录<strong>条数</strong>)</td></tr><tr><td>maximumWeight</td><td>指定此缓存容器的最大容量（最大<strong>比重</strong>值），需结合<code>weighter</code>方可体现出效果</td></tr><tr><td>expireAfterWrite</td><td>设定过期策略，按照数据<strong>写入时间</strong>进行计算</td></tr><tr><td>expireAfterAccess</td><td>设定过期策略，按照数据最后<strong>访问时间</strong>来计算</td></tr><tr><td>expireAfter</td><td>基于<strong>个性化定制</strong>的逻辑来实现过期处理（可以定制基于<code>新增</code>、<code>读取</code>、<code>更新</code>等场景的过期策略，甚至支持为<em>不同记录指定不同过期时间</em>）</td></tr><tr><td>weighter</td><td>入参为一个函数式接口，用于指定每条存入的缓存数据的权重占比情况。这个需要与<code>maximumWeight</code>结合使用</td></tr><tr><td>refreshAfterWrite</td><td>缓存写入到缓存之后</td></tr><tr><td>recordStats</td><td>设定开启此容器的数据加载与缓存命中情况统计</td></tr></tbody></table><p>综合上述方法，我们可以创建出更加符合自己业务场景的缓存对象。</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public static void main(String[] args) &#123;    AsyncLoadingCache&lt;String, User&gt; asyncLoadingCache &#x3D; CaffeinenewBuilder()            .initialCapacity(1000) &#x2F;&#x2F; 指定初始容量            .maximumSize(10000L) &#x2F;&#x2F; 指定最大容量            .expireAfterWrite(30L, TimeUnit.MINUTES) &#x2F;&#x2F; 指定写入30分钟后过期            .refreshAfterWrite(1L, TimeUnit.MINUTES) &#x2F;&#x2F; 指定每隔1分钟刷新下数据内容            .removalListener((key, value, cause) -&gt;                    System.out.println(key + &quot;移除，原因：&quot; + cause)) &#x2F;&#x2F; 监听记录移除事件            .recordStats() &#x2F;&#x2F; 开启缓存操作数据统计            .buildAsync(key -&gt; userDao.getUser(key)); &#x2F;&#x2F; 构建异步CacheLoader加载类型的缓存对象&#125;</code></pre><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h3 id="业务使用"><a href="#业务使用" class="headerlink" title="业务使用"></a>业务使用</h3><p>在上一章节创建缓存对象的时候，Caffeine支持创建出<strong>同步缓存</strong>与<strong>异步缓存</strong>，也即<code>Cache</code>与<code>AsyncCache</code>两种不同类型。而如果指定了CacheLoader的时候，又可以细分出<code>LoadingCache</code>子类型与<code>AsyncLoadingCache</code>子类型。对于常规业务使用而言，知道这四种类型的缓存类型基本就可以满足大部分场景的正常使用了。但是Caffeine的整体缓存类型其实是细分成了很多不同的具体类型的，从下面的<code>UML图</code>上可以看出一二。</p><ul><li><strong>同步缓存</strong></li></ul><p><img src="https://pics.codingcoder.cn/pics/202211132205284.png"></p><ul><li><strong>异步缓存</strong></li></ul><p><img src="https://pics.codingcoder.cn/pics/202211132205364.png"></p><p>业务层面对缓存的使用，无外乎往缓存里面写入数据、从缓存里面读取数据。不管是同步还是异步，常见的用于操作缓存的方法梳理如下：</p><table><thead><tr><th>方法</th><th>含义说明</th></tr></thead><tbody><tr><td>get</td><td>根据key获取指定的缓存值，如果没有则执行<strong>回源</strong>操作获取</td></tr><tr><td>getAll</td><td>根据给定的key列表批量获取对应的缓存值，返回一个<code>map格式</code>的结果，没有命中缓存的部分会执行<strong>回源</strong>操作获取</td></tr><tr><td>getIfPresent</td><td><strong>不执行回源</strong>操作，直接从缓存中尝试获取key对应的缓存值</td></tr><tr><td>getAllPresent</td><td><strong>不执行回源</strong>操作，直接从缓存中尝试获取给定的key列表对应的值，返回查询到的map格式结果， <em>异步场景不支持</em>此方法</td></tr><tr><td>put</td><td>向缓存中写入指定的key与value记录</td></tr><tr><td>putAll</td><td>批量向缓存中写入指定的key-value记录集，<em>异步场景不支持</em>此方法</td></tr><tr><td>asMap</td><td>将缓存中的数据转换为map格式返回</td></tr></tbody></table><p>针对<strong>同步</strong>缓存，业务代码中操作使用举例如下：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public static void main(String[] args) throws Exception &#123;    LoadingCache&lt;String, String&gt; loadingCache &#x3D; buildLoadingCache();    loadingCache.put(&quot;key1&quot;, &quot;value1&quot;);    String value &#x3D; loadingCache.get(&quot;key1&quot;);    System.out.println(value);&#125;</code></pre><p>同样地，<strong>异步</strong>缓存的时候，业务代码中操作示意如下：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public static void main(String[] args) throws Exception &#123;    AsyncLoadingCache&lt;String, String&gt; asyncLoadingCache &#x3D; buildAsyncLoadingCache();    &#x2F;&#x2F; 写入缓存记录（value值为异步获取）    asyncLoadingCache.put(&quot;key1&quot;, CompletableFuture.supplyAsync(() -&gt; &quot;value1&quot;));    &#x2F;&#x2F; 异步方式获取缓存值    CompletableFuture&lt;String&gt; completableFuture &#x3D; asyncLoadingCache.get(&quot;key1&quot;);    String value &#x3D; completableFuture.join();    System.out.println(value);&#125;</code></pre><h2 id="小结回顾"><a href="#小结回顾" class="headerlink" title="小结回顾"></a>小结回顾</h2><p>好啦，关于<code>Caffeine Cache</code>的具体使用方式、核心的优化改进点相关的内容，以及与<code>Guava Cache</code>的比较，就介绍到这里了。不知道小伙伴们是否对Caffeine Cache有了全新的认识了呢？而关于Caffeine Cache与Guava Cache的差别，你是否有自己的一些想法与见解呢？欢迎评论区一起交流下，期待和各位小伙伴们一起切磋、共同成长。</p><blockquote><p>下一篇文章中，我们将深入讲解下Caffeine同步、异步回源操作的各种不同实现，以及对应的实现与底层设计逻辑。如有兴趣，欢迎关注后续更新。</p></blockquote><p>📣 <strong>补充说明1</strong> ：</p><blockquote><p>本文属于《<a href="https://juejin.cn/column/7140852038258147358">深入理解缓存原理与实战设计</a>》系列专栏的内容之一。该专栏围绕缓存这个宏大命题进行展开阐述，全方位、系统性地深度剖析各种缓存实现策略与原理、以及缓存的各种用法、各种问题应对策略，并一起探讨下缓存设计的哲学。</p><p>如果有兴趣，也欢迎关注此专栏。</p></blockquote><p>📣 <strong>补充说明2</strong> ：</p><ul><li>关于本文中涉及的<strong>演示代码</strong>的完整示例，我已经整理并提交到github中，如果您有需要，可以自取：<a href="https://github.com/veezean/JavaBasicSkills">https://github.com/veezean/JavaBasicSkills</a></li></ul><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><p><strong>我是悟道，聊技术、又不仅仅聊技术~</strong></p><p>如果觉得有用，请<strong>点赞 + 关注</strong>让我感受到您的支持。也可以关注下我的公众号【架构悟道】，获取更及时的更新。</p><p>期待与你一起探讨，一起成长为更好的自己。</p><p><img src="https://pics.codingcoder.cn/pics/202207091312091.gif"></p><p><img src="https://pics.codingcoder.cn/pics/202207091317876.png"></p>]]></content>
      
      
      <categories>
          
          <category> 缓存原理与实战设计 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JAVA </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>重新认识下JVM级别的本地缓存框架Guava Cache(3)——探寻实现细节与核心机制</title>
      <link href="//post/20221129090317.html"/>
      <url>//post/20221129090317.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>本篇文章我们将进一步探讨下Guava Cache 实现层面的一些逻辑与设计策略，让我们可以对Guava Cache整体有个更加明朗的认识，促进实际使用中对其的理解。</p></blockquote><p><img src="https://pics.codingcoder.cn/pics/202210050807355.png"></p><p>大家好，又见面了。</p><hr><blockquote><p>本文是笔者作为掘金技术社区签约作者的身份输出的缓存专栏系列内容，将会通过系列专题，讲清楚缓存的方方面面。如果感兴趣，欢迎关注以获取后续更新。</p></blockquote><hr><p>通过《<a href="https://juejin.cn/post/7160459619075096583">重新认识下JVM级别的本地缓存框架Guava Cache——优秀从何而来</a>》一文，我们知道了<code>Guava Cache</code>作为JVM级别的本地缓存组件的诸多<strong>暖心</strong>特性，也一步步地学习了在项目中集成并使用Guava Cache进行缓存相关操作。Guava Cache作为一款优秀的本地缓存组件，其内部很多实现机制与设计策略，同样值得开发人员深入的掌握与借鉴。</p><p>作为系列专栏，本篇文章我们将进一步探讨下Guava Cache <strong>实现层面</strong>的一些逻辑与设计策略，让我们可以对Guava Cache整体有个更加明朗的认识。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h2 id="数据回源与回填策略"><a href="#数据回源与回填策略" class="headerlink" title="数据回源与回填策略"></a>数据回源与回填策略</h2><p>前面我们介绍过，Guava Cache提供的是一种<strong>穿透型缓存</strong>模式，当缓存中没有获取到对应记录的时候，支持自动去源端获取数据并回填到缓存中。这里<strong>回源</strong>获取数据的策略有两种，即<code>CacheLoader</code>方式与<code>Callable</code>方式，两种方式适用于不同的场景,实际使用中可以按需选择。</p><p>下面一起看下这两种方式。</p><h3 id="CacheLoader"><a href="#CacheLoader" class="headerlink" title="CacheLoader"></a>CacheLoader</h3><p><code>CacheLoader</code>适用于数据加载方式比较固定且统一的场景，在缓存容器创建的时候就需要指定此具体的加载逻辑。常见的使用方式如下：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public LoadingCache&lt;String, User&gt; createUserCache() &#123;    return CacheBuilder.newBuilder()            .build(new CacheLoader&lt;String, User&gt;() &#123;                @Override                public User load(String key) throws Exception &#123;                    System.out.println(key + &quot;用户缓存不存在，尝试CacheLoader回源查找并回填...&quot;);                    return userDao.getUser(key);                &#125;            &#125;);    &#125;</code></pre><p>上述代码中，在使用<em>CacheBuilder</em>创建缓存容器的时候，如果在<code>build()</code>方法中传入一个<strong>CacheLoader</strong>实现类的方式，则最终创建出来的是一个<code>LoadingCache</code>具体类型的Cache容器：</p><p><img src="https://pics.codingcoder.cn/pics/202210312136285.png"></p><p>默认情况下，我们需要继承CacheLoader类并实现其<code>load</code>抽象方法即可。</p><p><img src="https://pics.codingcoder.cn/pics/202210312150011.png"></p><p>当然，<code>CacheLoader</code>类中还有一些其它的方法，我们也可以选择性的进行覆写来实现自己的自定义诉求。比如我们需要设定<code>refreshAfterWrite</code>来支持<strong>定时刷新</strong>的时候，就推荐覆写<code>reload</code>方法，提供一个<strong>异步</strong>数据加载能力，避免数据刷新操作对业务请求造成阻塞。</p><p><img src="https://pics.codingcoder.cn/pics/202210312216077.png"></p><p>另外，有一点需要注意下，如果创建缓存的时候使用<code>refreshAfterWrite</code>指定了需要定时更新缓存数据内容，则必须在创建的时候指定CacheLoader实例，否则执行的时候会<strong>报错</strong>。因为在执行<code>refresh</code>操作的时候，必须调用CacheLoader对象的<code>reload</code>方法去执行数据的回源操作。</p><p><img src="https://pics.codingcoder.cn/pics/202210310831521.png"></p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h3 id="Callable"><a href="#Callable" class="headerlink" title="Callable"></a>Callable</h3><p>与CacheLoader不同，<code>Callable</code>的方式在每次数据获取请求中进行指定，可以在不同的调用场景中，分别指定并使用不同的数据获取策略，更加的<strong>灵活</strong>。</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public static void main(String[] args) &#123;    try &#123;        GuavaCacheService cacheService &#x3D; new GuavaCacheService();        Cache&lt;String, User&gt; cache &#x3D; cacheService.createCache();        String userId &#x3D; &quot;123&quot;;        &#x2F;&#x2F; 获取userId， 获取不到的时候执行Callable进行回源        User user &#x3D; cache.get(userId, () -&gt; cacheService.queryUserFromDb(userId));        System.out.println(&quot;get对应用户信息：&quot; + user);    &#125; catch (Exception e) &#123;        e.printStackTrace();    &#125;&#125;</code></pre><p>通过提供<code>Callable</code>实现函数并作为参数传递的方式，可以根据业务的需要，在不同业务调用场景下，指定使用不同的Callable回源策略。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h3 id="不回源查询"><a href="#不回源查询" class="headerlink" title="不回源查询"></a>不回源查询</h3><p>前面介绍了基于<code>CacheLoader</code>方式自动回源，或者基于<code>Callable</code>方式显式回源的两种策略。但是实际使用缓存的时候，并非是缓存中获取不到数据时就一定需要去执行回源操作。</p><p>比如下面这个场景：</p><blockquote><p>用户论坛中维护了个黑名单列表，每次用户登录的时候，需要先判断下是否在黑名单中，如果在则禁止登录。</p></blockquote><p>因为论坛中黑名单用户占整体用户量的比重是极少的，也就是几乎绝大部分登录的时候去查询缓存都是无法命中黑名单缓存的。这种时候如果每次查询缓存中没有的情况下都去执行回源操作，那几乎等同于每次请求都需要去访问一次DB了，这显然是<strong>不合理</strong>的。</p><p>所以，为了支持这种场景的访问，Guava cache也提供了一种<strong>不会触发回源</strong>操作的访问方式。如下：</p><table><thead><tr><th>接口</th><th>功能说明</th></tr></thead><tbody><tr><td>getIfPresent</td><td>从内存中查询，如果存在则返回对应值，不存在则返回null</td></tr><tr><td>getAllPresent</td><td>批量从内存中查询，如果存在则返回存在的键值对，不存在的key则不出现在结果集里</td></tr></tbody></table><p>上述两种接口，执行的时候仅会从当前内存中已有的缓存数据里面进行查询，不会触发回源的操作。</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public static void main(String[] args) &#123;    try &#123;        GuavaCacheService cacheService &#x3D; new GuavaCacheService();        Cache&lt;String, User&gt; cache &#x3D; cacheService.createCache();        cache.put(&quot;123&quot;, new User(&quot;123&quot;, &quot;123&quot;));        cache.put(&quot;124&quot;, new User(&quot;124&quot;, &quot;124&quot;));        System.out.println(cache.getIfPresent(&quot;125&quot;));        ImmutableMap&lt;String, User&gt; allPresentUsers &#x3D;                cache.getAllPresent(Stream.of(&quot;123&quot;, &quot;124&quot;, &quot;125&quot;).collect(Collectors.toList()));        System.out.println(allPresentUsers);    &#125; catch (Exception e) &#123;        e.printStackTrace();    &#125;&#125;</code></pre><p>执行后，输入结果如下：</p><pre class="line-numbers language-none"><code class="language-none">null&#123;123&#x3D;User(userName&#x3D;123, userId&#x3D;123), 124&#x3D;User(userName&#x3D;124, userId&#x3D;124)&#125;</code></pre><h2 id="Guava-Cache的数据清理与加载刷新机制"><a href="#Guava-Cache的数据清理与加载刷新机制" class="headerlink" title="Guava Cache的数据清理与加载刷新机制"></a>Guava Cache的数据清理与加载刷新机制</h2><p>在前面的CacheBuilder类中有提供了几种<code>expire</code>与<code>refresh</code>的方法，即<code>expireAfterAccess</code>、<code>expireAfterWrite</code>以及<code>refreshAfterWrite</code>。</p><p>这里我们对几个方法进行一些探讨。</p><h3 id="数据过期"><a href="#数据过期" class="headerlink" title="数据过期"></a>数据过期</h3><p>对于数据有过期时效诉求的场景，我们可以通过几种方式设定缓存的过期时间：</p><ul><li><p>expireAfterAccess</p></li><li><p>expireAfterWrite</p></li></ul><p>现在我们思考一个问题：数据过期之后，会立即被删除吗？在前面的文章中，我们自己构建本地缓存框架的时候，有介绍过缓存数据删除的几种机制：</p><table><thead><tr><th>删除机制</th><th>具体说明</th></tr></thead><tbody><tr><td>主动删除</td><td>搞个定时线程不停的去扫描并清理所有已经过期的数据。</td></tr><tr><td>惰性删除</td><td>在数据访问的时候进行判断，如果过期则删除此数据。</td></tr><tr><td>两者结合</td><td>采用惰性删除为主，低频定时主动删除为兜底，兼顾处理性能与内存占用。</td></tr></tbody></table><p>在Guava Cache中，为了最大限度的保证并发性，采用的是<strong>惰性删除</strong>的策略，而没有设计独立清理线程。所以这里我们就可以回答前面的问题，也即<strong>过期的数据，并非是立即被删除的</strong>，而是在<code>get</code>等操作访问缓存记录时触发过期数据的删除操作。</p><p>在get执行逻辑中进行数据过期清理以及重新回源加载的执行判断流程，可以简化为下图中的关键环节：</p><p><img src="https://pics.codingcoder.cn/pics/202211062119555.png"></p><p>在执行get请求的时候，会先判断下当前查询的数据是否过期，如果已经过期，则会触发对当前操作的<code>Segment</code>的过期数据清理操作。</p><h3 id="数据刷新"><a href="#数据刷新" class="headerlink" title="数据刷新"></a>数据刷新</h3><p>除了上述的2个过期时间设定方法，Guava Cache还提供了个<code>refreshAfterWrite</code>方法，用于设定定时自动<code>refresh</code>操作。项目中可能会有这么个情况：</p><blockquote><p>为了提升性能，将最近访问系统的用户信息缓存起来，设定有效期30分钟。如果用户的角色出现变更，或者用户昵称、个性签名之类的发生更改，则需要最长等待30分钟缓存失效重新加载后才能够生效。</p></blockquote><p>这种情况下，我们就可以在设定了过期时间的基础上，再设定一个每隔1分钟重新<code>refresh</code>的逻辑。这样既可以保证数据在缓存中的留存时长，又可以尽可能的缩短缓存变更生效的时间。这种情况，便该<code>refreshAfterWrite</code>登场了。</p><p><img src="https://pics.codingcoder.cn/pics/202211062104479.png"></p><p>与expire清理逻辑相同，refresh操作依旧是采用一种<strong>被动触发</strong>的方式来实现。当get操作执行的时候会判断下如果创建时间已经超过了设定的刷新间隔，则会重新去执行一次数据的加载逻辑（前提是数据并没有过期）。</p><p>鉴于缓存<strong>读多写少</strong>的特点，Guava Cache在数据refresh操作执行的时候，采用了一种<strong>非阻塞式</strong>的加载逻辑，尽可能的保证并发场景下对读取线程的性能影响。</p><p>看下面的代码，模拟了两个并发请求同时请求一个需要刷新的数据的场景：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public static void main(String[] args) &#123;    try &#123;        LoadingCache&lt;String, User&gt; cache &#x3D;                CacheBuilder.newBuilder().refreshAfterWrite(1L, TimeUnit.SECONDS).build(new MyCacheLoader());        cache.put(&quot;123&quot;, new User(&quot;123&quot;, &quot;ertyu&quot;));        Thread.sleep(1100L);        Runnable task &#x3D; () -&gt; &#123;            try &#123;                System.out.println(Thread.currentThread().getId() + &quot;线程开始执行查询操作&quot;);                User user &#x3D; cache.get(&quot;123&quot;);                System.out.println(Thread.currentThread().getId() + &quot;线程查询结果：&quot; + user);            &#125; catch (Exception e) &#123;                e.printStackTrace();            &#125;        &#125;;        CompletableFuture.allOf(                CompletableFuture.runAsync(task), CompletableFuture.runAsync(task)        ).thenRunAsync(task).join();    &#125; catch (Exception e) &#123;        e.printStackTrace();    &#125;&#125;</code></pre><p>执行后，结果如下：</p><pre class="line-numbers language-none"><code class="language-none">14线程开始执行查询操作13线程开始执行查询操作13线程查询结果：User(userName&#x3D;ertyu, userId&#x3D;123)14线程执行CacheLoader.reload()，oldValue&#x3D;User(userName&#x3D;ertyu, userId&#x3D;123)14线程执行CacheLoader.load()...14线程执行CacheLoader.load()结束...14线程查询结果：User(userName&#x3D;97qx6, userId&#x3D;123)15线程开始执行查询操作15线程查询结果：User(userName&#x3D;97qx6, userId&#x3D;123)</code></pre><p>从执行结果可以看出，两个并发同时请求的线程只有1个执行了<code>load</code>数据操作，且两个线程所获取到的结果是不一样的。具体而言，可以概括为如下几点：</p><ul><li><p>同一时刻仅允许一个线程执行数据重新加载操作，并<strong>阻塞等待</strong>重新加载完成之后该线程的查询请求才会返回对应的新值作为结果。</p></li><li><p>当一个线程正在阻塞执行<code>refresh</code>数据刷新操作的时候，其它线程此时来执行get请求的时候，会判断下数据需要refresh操作，但是因为没有获取到refresh执行锁，这些其它线程的请求<strong>不会被阻塞</strong>等待refresh完成，而是<strong>立刻返回</strong>当前refresh前的<strong>旧值</strong>。</p></li><li><p>当执行refresh的线程操作完成后，此时另一个线程再去执行get请求的时候，会判断无需refresh，直接返回当前内存中的当前值即可。</p></li></ul><p>上述的过程，按照时间轴的维度来看，可以囊括成如下的执行过程：</p><p><img src="https://pics.codingcoder.cn/pics/202211061655253.png"></p><h3 id="数据expire与refresh关系"><a href="#数据expire与refresh关系" class="headerlink" title="数据expire与refresh关系"></a>数据expire与refresh关系</h3><p><code>expire</code>与<code>refresh</code>在某些实现逻辑上有一定的相似度，很多的文章中介绍的时候甚至很直白的说refresh比expire更好，因为其不会阻塞业务端的请求。个人认为这种看法有点片面，从单纯的字面含义上也可以看出这两种机制不是互斥的、而是一种<strong>相互补充</strong>的存在，并不存在谁比谁更好这一说，关键要看具体是应用场景。</p><p><img src="https://pics.codingcoder.cn/pics/202211062023920.png"></p><p><code>expire</code>操作就是采用的一种<strong>严苛</strong>的更新锁定机制，当一个线程执行数据重新加载的时候，其余的线程则阻塞等待。<code>refresh</code>操作执行过程中不会阻塞其余线程的get查询操作，会直接返回旧值。这样的设计<strong>各有利弊</strong>：</p><table><thead><tr><th>操作</th><th>优势</th><th>弊端</th></tr></thead><tbody><tr><td>expire</td><td>有效防止缓存击穿问题，且阻塞等待的方式可以保证业务层面获取到的缓存数据的强一致性。</td><td>高并发场景下，如果回源的耗时较长，会导致多个读线程被阻塞等待，影响整体的并发效率。</td></tr><tr><td>refresh</td><td>可以最大限度的保证查询操作的执行效率，避免过多的线程被阻塞等待。</td><td>多个线程并发请求同一个key对应的缓存值拿到的结果可能不一致，在对于一致性要求特别严苛的业务场景下可能会引发问题。</td></tr></tbody></table><p>Guava Cache中的expire与fefresh两种机制，给人的另一个<strong>困惑点</strong>在于：两者都是被动触发的数据加载逻辑，不管是expire还是refresh，只要超过指定的时间间隔，其实都是依旧存在与内存中，等有新的请求查询的时候，都会执行自动的最新数据加载操作。那这两个实际使用而言，仅仅只需要依据是否需要阻塞加载这个维度来抉择？</p><p>并非如此。</p><p>expire存在的意义更多的是一种<strong>数据生命周期终结</strong>的意味，超过了expire有效期的数据，虽然依旧会存在于内存中，但是在一些触发了<code>cleanUp</code>操作的情况下，是会被释放掉以减少内存占用的。而refresh则仅仅只是执行数据更新，框架无法判断是否需要从内存释放掉，会始终占据内存。</p><p>所以在具体使用时，需要根据场景综合判断：</p><ul><li><p>数据需要<strong>永久存储</strong>，且<strong>不会变更</strong>，这种情况下<code>expire</code>和<code>refresh</code>都并不需要设定</p></li><li><p>数据<strong>极少变更</strong>，或者对变更的感知诉求不强，且并发请求同一个key的竞争压力不大，直接使用<code>expire</code>即可</p></li><li><p>数据<strong>无需过期</strong>，但是可能<strong>会被修改</strong>，需要及时感知并更新缓存数据，直接使用<code>refresh</code></p></li><li><p>数据<strong>需要过期</strong>（避免不再使用的数据始终留在内存中）、也需要在有效期内尽可能保证数据的<strong>更新一致性</strong>，则采用<code>expire</code>与<code>refresh</code>两者<strong>结合</strong>。</p></li></ul><p>对于expire与refresh结合使用的场景，两者的时间间隔设置，需要注意：</p><blockquote><p>expire时间设定要<strong>大于</strong>refresh时间，否则的话refresh将永远没有机会执行</p></blockquote><h2 id="Guava-Cache并发能力支持"><a href="#Guava-Cache并发能力支持" class="headerlink" title="Guava Cache并发能力支持"></a>Guava Cache并发能力支持</h2><h3 id="采用分段锁降低锁争夺"><a href="#采用分段锁降低锁争夺" class="headerlink" title="采用分段锁降低锁争夺"></a>采用分段锁降低锁争夺</h3><p>前面我们提过Guava Cache支持多线程环境下的安全访问。我们知道锁的粒度越大，多线程请求的时候对锁的竞争压力越大，对性能的影响越大。而如果将锁的粒度拆分小一些，这样<strong>同时请求到同一把锁的概率就会降低</strong>，这样线程间争夺锁的竞争压力就会降低。</p><p><img src="https://pics.codingcoder.cn/pics/165924683167139344194.png"></p><p>Guava Cache中采用的也就是这种<strong>分段锁</strong>策略来降低锁的粒度，可以在创建缓存容器的时候使用<code>concurrencyLevel</code>来指定允许的<strong>最大并发线程数</strong>，使得线程安全的前提下尽可能的减少锁争夺。而<em>concurrencyLevel</em>值与分段<em>Segment</em>的数量之间也存在一定的关系，这个关系相对来说会比较复杂、且受是否限制总容量等因素的影响，源码中这部分的计算逻辑可以看下：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">int segmentShift &#x3D; 0;int segmentCount &#x3D; 1;while (segmentCount &lt; concurrencyLevel &amp;&amp; (!evictsBySize() || segmentCount * 20 &lt;&#x3D; maxWeight)) &#123;    ++segmentShift;    segmentCount &lt;&lt;&#x3D; 1;&#125;</code></pre><p>根据上述的控制逻辑代码，可以将<code>segmentCount</code>的取值约束概括为下面几点：</p><ul><li><p>segmentCount 是 2 的整数倍</p></li><li><p>segmentCount 最大可能为<code>(concurrencyLevel -1)*2</code></p></li><li><p>如果有按照权重设置容量，则segmentCount不得超过总权重值的<code>1/20</code></p></li></ul><p>从源码中可以比较清晰的看出这一点，Guava Cache在put写操作的时候，会首先计算出key对应的hash值，然后根据hash值来确定数据应该写入到哪个Segment中，进而对该Segment加锁执行写入操作。</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">@Overridepublic V put(K key, V value) &#123;    &#x2F;&#x2F; ... 省略部分逻辑    int hash &#x3D; hash(key);    return segmentFor(hash).put(key, hash, value, false);&#125;@NullableV put(K key, int hash, V value, boolean onlyIfAbsent) &#123;  lock();    try &#123;        &#x2F;&#x2F; ... 省略具体逻辑    &#125; finally &#123;        unlock();        postWriteCleanup();    &#125;&#125;</code></pre><p>根据上述源码也可以得出一个结论，<code>concurrencyLevel</code>只是一个<strong>理想状态</strong>下的最大同时并发数，也取决于同一时间的操作请求是否会平均的分散在各个不同的Segment中。极端情况下，如果多个线程操作的目标对象都在同一个分片中时，那么只有1个线程可以持锁执行，其余线程都会阻塞等待。</p><p><img src="https://pics.codingcoder.cn/pics/165924684317551010494.png"></p><p>实际使用中，比较推荐的是将concurrencyLevel设置为<strong>CPU核数的2倍</strong>，以获得较优的并发性能。当然，concurrencyLevel也不是可以随意设置的，从其源码设置里面可以看出，允许的最大值为<code>65536</code>。</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">static final int MAX_SEGMENTS &#x3D; 1 &lt;&lt; 16; &#x2F;&#x2F; 65536LocalCache(CacheBuilder&lt;? super K, ? super V&gt; builder, @Nullable CacheLoader&lt;? super K, V&gt; loader) &#123;    concurrencyLevel &#x3D; Math.min(builder.getConcurrencyLevel(), MAX_SEGMENTS);    &#x2F;&#x2F; ... 省略其余逻辑&#125;</code></pre><h3 id="佛系抢锁策略"><a href="#佛系抢锁策略" class="headerlink" title="佛系抢锁策略"></a>佛系抢锁策略</h3><p>在put等写操作场景下，Guava Cache采用的是上述分段锁的策略，通过优化锁的粒度，来提升并发的性能。但是加锁毕竟还是对性能有一定的影响的，为了追求更加极致的性能表现，在get等读操作自身并没有发现加锁操作 —— 但是Guava Cache的get等处理逻辑也并非是纯粹的只读操作，它还兼具触发数据淘汰清理操作的删除逻辑，所以只在判断需要执行清理的时候才会尝试去<strong>佛系抢锁</strong>。</p><p>那么它是如何减少抢锁的几率的呢？从源码中可以看出，并非是每次请求都会去触发<code>cleanUp</code>操作，而是会尝试积攒一定次数之后再去尝试清理：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">static final int DRAIN_THRESHOLD &#x3D; 0x3F;void postReadCleanup() &#123;  if ((readCount.incrementAndGet() &amp; DRAIN_THRESHOLD) &#x3D;&#x3D; 0) &#123;    cleanUp();  &#125;&#125;</code></pre><p>在高并发场景下，如果查询请求量巨大的情况下，即使按照上述的情况限制每次达到一定请求数量之后才去执行清理操作，依旧可能会出现多个get操作线程同时去抢锁执行清理操作的情况，这样岂不是依旧会阻塞这些读取请求的处理吗？</p><p>继续看下源码：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">void cleanUp() &#123;  long now &#x3D; map.ticker.read();  runLockedCleanup(now);  runUnlockedCleanup();&#125;void runLockedCleanup(long now) &#123;    &#x2F;&#x2F; 尝试请求锁，请求到就处理，请求不到就放弃  if (tryLock()) &#123;    try &#123;      &#x2F;&#x2F; ... 省略部分逻辑      readCount.set(0);    &#125; finally &#123;      unlock();    &#125;  &#125;&#125;</code></pre><p>可以看到源码中采用的是<code>tryLock</code>方法来尝试去抢锁，如果抢到锁就继续后续的操作，如果没抢到锁就不做任何清理操作，直接返回 —— 这也是为什么前面将其形容为“<strong>佛系抢锁</strong>”的缘由。这样的小细节中也可以看出Google码农们还是有点内功修为的。</p><h2 id="承前启后-——-Caffeine-Cache"><a href="#承前启后-——-Caffeine-Cache" class="headerlink" title="承前启后 —— Caffeine Cache"></a>承前启后 —— Caffeine Cache</h2><p>技术的更新迭代始终没有停歇的时候，Guava工具包作为Google家族的优秀成员，在很多方面提供了非常优秀的能力支持。随着JAVA8的普及，Google也基于语言的新特性，对Guava Cache部分进行了重新实现，形成了后来的<code>Caffeine Cache</code>，并在SpringBoot2.x中取代了Guava Cache。</p><p>下一篇文章中，我们将一起再聊一聊令人上瘾的<strong>Caffeine Cache</strong>。</p><h2 id="小结回顾"><a href="#小结回顾" class="headerlink" title="小结回顾"></a>小结回顾</h2><p>好啦，关于<code>Guava Cache</code>中的典型<strong>实现机制</strong>与核心<strong>设计策略</strong>，就介绍到这里了。至此，我们完成了Guava Cache从简单会用到深度剖析的全过程，不知道小伙伴们是否对Guava Cache有了全新的认识了呢？关于Guava Cache，你是否有自己的一些想法与见解呢？欢迎评论区一起交流下，期待和各位小伙伴们一起切磋、共同成长。</p><p>📣 <strong>补充说明1</strong> ：</p><blockquote><p>本文属于《<a href="https://juejin.cn/column/7140852038258147358">深入理解缓存原理与实战设计</a>》系列专栏的内容之一。该专栏围绕缓存这个宏大命题进行展开阐述，全方位、系统性地深度剖析各种缓存实现策略与原理、以及缓存的各种用法、各种问题应对策略，并一起探讨下缓存设计的哲学。</p><p>如果有兴趣，也欢迎关注此专栏。</p></blockquote><p>📣 <strong>补充说明2</strong> ：</p><ul><li>关于本文中涉及的<strong>演示代码</strong>的完整示例，我已经整理并提交到github中，如果您有需要，可以自取：<a href="https://github.com/veezean/JavaBasicSkills">https://github.com/veezean/JavaBasicSkills</a></li></ul><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><p><strong>我是悟道，聊技术、又不仅仅聊技术~</strong></p><p>如果觉得有用，请<strong>点赞 + 关注</strong>让我感受到您的支持。也可以关注下我的公众号【架构悟道】，获取更及时的更新。</p><p>期待与你一起探讨，一起成长为更好的自己。</p><p><img src="https://pics.codingcoder.cn/pics/202207091312091.gif"></p><p><img src="https://pics.codingcoder.cn/pics/202207091317876.png"></p>]]></content>
      
      
      <categories>
          
          <category> 缓存原理与实战设计 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JAVA </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>重新认识下JVM级别的本地缓存框架Guava Cache(2)——深入解读其容量限制与数据淘汰策略</title>
      <link href="//post/20221125071617.html"/>
      <url>//post/20221125071617.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>对于缓存容器而言，容量限制与数据淘汰是两个基础且核心的关键点，也是实际使用的时候使用频率最高的特性。本篇在上一文基础上深入解读下Guava Cache中的容量限制与数据淘汰策略的实现与使用约束。</p></blockquote><p><img src="https://pics.codingcoder.cn/pics/202210050807355.png"></p><p>大家好，又见面了。</p><hr><blockquote><p>本文是笔者作为掘金技术社区签约作者的身份输出的缓存专栏系列内容，将会通过系列专题，讲清楚缓存的方方面面。如果感兴趣，欢迎关注以获取后续更新。</p></blockquote><hr><p>通过《<a href="https://juejin.cn/post/7160459619075096583">重新认识下JVM级别的本地缓存框架Guava Cache——优秀从何而来</a>》一文，我们知道了Guava Cache作为JVM级别的本地缓存组件的诸多<strong>暖心</strong>特性，也一步步地学习了在项目中集成并使用Guava Cache进行缓存相关操作。Guava Cache作为一款优秀的本地缓存组件，其内部很多实现机制与设计策略，同样值得开发人员深入的掌握与借鉴。</p><p>作为系列专栏，本篇文章我们将在上一文的基础上，继续探讨下Guava Cache对于缓存<strong>容量限制</strong>与<strong>数据清理</strong>相关的使用与设计机制，进而让我们在项目中使用起来可以更加的游刃有余，解锁更多使用技巧。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h2 id="容量限制时的Size与Weight区别"><a href="#容量限制时的Size与Weight区别" class="headerlink" title="容量限制时的Size与Weight区别"></a>容量限制时的Size与Weight区别</h2><h3 id="弄清Size与Weight"><a href="#弄清Size与Weight" class="headerlink" title="弄清Size与Weight"></a>弄清Size与Weight</h3><p>Guava Cache提供了对<strong>缓存总量</strong>的限制，并且支持从两个维度进行限制，这里我们首先要厘清<code>size</code>与<code>weight</code>两个概念的区别与联系。</p><p><img src="https://pics.codingcoder.cn/pics/202210312128949.png"></p><ul><li><strong>限制缓存条数size</strong></li></ul><pre class="line-numbers language-java" data-language="java"><code class="language-java">public Cache&lt;String, User&gt; createUserCache() &#123;    return CacheBuilder.newBuilder().maximumSize(10000L).build();&#125;</code></pre><ul><li><strong>限制缓存权重weight</strong></li></ul><pre class="line-numbers language-java" data-language="java"><code class="language-java">public Cache&lt;String, String&gt; createUserCache() &#123;    return CacheBuilder.newBuilder()            .maximumWeight(50000)            .weigher((key, value) -&gt; (int) Math.ceil(value.length() &#x2F; 1000))            .build();    &#125;</code></pre><p>一般而言，我们限制容器的容量的<strong>初衷</strong>，是为了防止内存占用过大导致<code>内存溢出</code>，所以本质上是限制<em>内存的占用量</em>。从实现层面，往往会根据总内存占用量与预估每条记录字节数进行估算，将其转换为对缓存记录条数的限制。这种做法相对简单易懂，但是对于单条缓存记录占用字节数差异较大的情况下，会导致基于条数控制的结果<strong>不够精准</strong>。</p><p>比如：</p><blockquote><p>需要限制缓存最大占用<code>500M</code>总量，缓存记录可能大小范围是1k~100k，按照每条<code>50k</code>进行估算，设定缓存容器最大容量为限制最大容量<code>1w</code>条。如果存储的都是1k大小的记录，则内存总占用量才10M（内存没有被有效利用起来）；若都存储的是100k大小的记录，又会导致内存占用为1000M，<strong>远大于</strong>预期的内存占用量（容易造成内存溢出）。</p></blockquote><p>为了解决这个问题，Guava Cache中提供了一种<strong>相对精准</strong>的控制策略，即<strong>基于权重</strong>的总量控制，根据一定的规则，计算出每条value记录所占的权重值，然后以权重值进行总量的计算。</p><p>还是上面的例子，我们按照权重进行设定，假定1k对应基础权重1，则100k可转换为权重100。这样一来：</p><blockquote><p>限制缓存最大占用<code>500M</code>，<code>1k</code>对应权重1,<code>Nk</code>代表权重N，则我们可以限制总权重为<code>50w</code>。这样假如存储的都是1k的记录，则最多可以缓存5w条记录；而如果都是100k大小的记录，则最多仅可以缓存5000条记录。根据存储数据的大小不同，最大存储的记录条数也不相同，但是最终占用的总体量可以实现基本吻合。</p></blockquote><p>所以，基于<code>weight</code>权重的控制方式，比较适用于这种对容器体量控制<strong>精度</strong>有<strong>严格诉求</strong>的场景，可以在创建容器的时候指定每条记录的权重计算策略（比如基于字符串长度或者基于bytes数组长度进行计算权重）。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h3 id="使用约束说明"><a href="#使用约束说明" class="headerlink" title="使用约束说明"></a>使用约束说明</h3><p>在实际使用中，这几个参数之间有一定的使用约束，需要特别注意一下：</p><ul><li><p>如果<em>没有指定</em>weight实现逻辑，则使用<code>maximumSize</code>来限制最大容量，按照容器中缓存记录的条数进行限制；这种情况下，即使设定了maximumWeight也不会生效。</p></li><li><p>如果<em>指定</em>了weight实现逻辑，则<strong>必须使用</strong> <code>maximumWeight</code> 来限制最大容量，按照容器中每条缓存记录的weight值累加后的总weight值进行限制。</p></li></ul><p>看下面的一个反面示例，指定了weighter和maximumSize，却<strong>没有指定</strong> maximumWeight属性：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public static void main(String[] args) &#123;    try &#123;        Cache&lt;String, String&gt; cache &#x3D; CacheBuilder.newBuilder()            .weigher((key, value) -&gt; 2)            .maximumSize(2)            .build();        cache.put(&quot;key1&quot;, &quot;value1&quot;);        cache.put(&quot;key2&quot;, &quot;value2&quot;);        System.out.println(cache.size());    &#125; catch (Exception e) &#123;        e.printStackTrace();    &#125;&#125;</code></pre><p>执行的时候，会报错，提示weighter和maximumSize不可以混合使用：</p><pre class="line-numbers language-none"><code class="language-none">java.lang.IllegalStateException: maximum size can not be combined with weigherat com.google.common.base.Preconditions.checkState(Preconditions.java:502)at com.google.common.cache.CacheBuilder.maximumSize(CacheBuilder.java:484)at com.veezean.skills.cache.guava.CacheService.main(CacheService.java:205)</code></pre><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h2 id="Guava-Cache淘汰策略"><a href="#Guava-Cache淘汰策略" class="headerlink" title="Guava Cache淘汰策略"></a>Guava Cache淘汰策略</h2><p>为了简单描述，我们将数据从缓存容器中移除的操作统称数据淘汰。按照触发形态不同，我们可以将数据的清理与淘汰策略分为<strong>被动淘汰</strong>与<strong>主动淘汰</strong>两种。</p><h3 id="被动淘汰"><a href="#被动淘汰" class="headerlink" title="被动淘汰"></a>被动淘汰</h3><ul><li><strong>基于数据量（size或者weight）</strong></li></ul><p>当容器内的缓存数量接近（注意是接近、而非达到）设定的最大阈值的时候，会触发guava cache的数据清理机制，会基于LRU或FIFO删除一些不常用的key-value键值对。这种方式需要在创建容器的时候指定其<code>maximumSize</code>或者<code>maximumWeight</code>，然后才会基于size或者weight进行判断并执行上述的清理操作。</p><p>看下面的实验代码：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public static void main(String[] args) &#123;    try &#123;        Cache&lt;String, String&gt; cache &#x3D; CacheBuilder.newBuilder()                .maximumSize(2)                .removalListener(notification -&gt; &#123;                    System.out.println(&quot;---监听到缓存移除事件：&quot; + notification);                &#125;)                .build();        System.out.println(&quot;put放入key1&quot;);        cache.put(&quot;key1&quot;, &quot;value1&quot;);        System.out.println(&quot;put放入key2&quot;);        cache.put(&quot;key2&quot;, &quot;value1&quot;);        System.out.println(&quot;put放入key3&quot;);        cache.put(&quot;key3&quot;, &quot;value1&quot;);        System.out.println(&quot;put操作后，当前缓存记录数：&quot; + cache.size());        System.out.println(&quot;查询key1对应值：&quot; + cache.getIfPresent(&quot;key1&quot;));    &#125; catch (Exception e) &#123;        e.printStackTrace();    &#125;&#125;</code></pre><p>上面代码中，没有设置数据的过期时间，理论上数据是长期有效、不会被过期删除。为了便于测试，我们设定缓存最大容量为2条记录，然后往缓存容器中插入3条记录，观察下输出结果如下：</p><pre class="line-numbers language-none"><code class="language-none">put放入key1put放入key2put放入key3---监听到缓存移除事件：key1&#x3D;value1put操作后，当前缓存记录数：2查询key1对应值：null</code></pre><p>从输出结果可以看到，即使<em>数据并没有过期</em>，但在插入第3条记录的时候，缓存容器还是自动将最初写入的key1记录给移除了，挪出了空间用于新的数据的插入。这个就是因为触发了Guava Cache的被动淘汰机制，以<strong>确保</strong>缓存容器中的数据量始终是在<strong>可控范围</strong>内。</p><ul><li><strong>基于过期时间</strong></li></ul><p>Guava Cache支持根据<code>创建时间</code>或者根据<code>访问时间</code>来设定数据过期处理，实际使用的时候可以根据具体需要来选择对应的方式。</p><table><thead><tr><th>过期策略</th><th>具体说明</th></tr></thead><tbody><tr><td>创建过期</td><td>基于缓存记录的插入时间判断。比如设定10分钟过期，则记录加入缓存之后，<em>不管有没有访问</em>，10分钟时间到则</td></tr><tr><td>访问过期</td><td>基于最后一次的访问时间来判断是否过期。比如设定10分钟过期，如果缓存记录被访问到，则以最后一次访问时间重新计时；只有连续10分钟没有被访问的时候才会过期，否则将一直存在缓存中不会被过期。</td></tr></tbody></table><p>看下面的实验代码：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public static void main(String[] args) &#123;    try &#123;        Cache&lt;String, String&gt; cache &#x3D; CacheBuilder.newBuilder()                .expireAfterWrite(1L, TimeUnit.SECONDS)                .recordStats()                .build();        cache.put(&quot;key1&quot;, &quot;value1&quot;);        cache.put(&quot;key2&quot;, &quot;value2&quot;);        cache.put(&quot;key3&quot;, &quot;value3&quot;);        System.out.println(&quot;put操作后，当前缓存记录数：&quot; + cache.size());        System.out.println(&quot;查询key1对应值：&quot; + cache.getIfPresent(&quot;key1&quot;));        System.out.println(&quot;统计信息：&quot; + cache.stats());        System.out.println(&quot;-------sleep 等待超过过期时间-------&quot;);        Thread.sleep(1100L);        System.out.println(&quot;执行key1查询操作：&quot; + cache.getIfPresent(&quot;key1&quot;));        System.out.println(&quot;当前缓存记录数：&quot; + cache.size());        System.out.println(&quot;当前统计信息：&quot; + cache.stats());        System.out.println(&quot;剩余数据信息：&quot; + cache.asMap());    &#125; catch (Exception e) &#123;        e.printStackTrace();    &#125;&#125;</code></pre><p>在实验代码中，我们设置了缓存记录1s有效期，然后等待其过期之后查看其缓存中数据情况，代码执行结果如下：</p><pre class="line-numbers language-none"><code class="language-none">put操作后，当前缓存记录数：3查询key1对应值：value1统计信息：CacheStats&#123;hitCount&#x3D;1, missCount&#x3D;0, loadSuccessCount&#x3D;0, loadExceptionCount&#x3D;0, totalLoadTime&#x3D;0, evictionCount&#x3D;0&#125;-------sleep 等待超过过期时间-------执行key1查询操作：null当前缓存记录数：1当前统计信息：CacheStats&#123;hitCount&#x3D;1, missCount&#x3D;1, loadSuccessCount&#x3D;0, loadExceptionCount&#x3D;0, totalLoadTime&#x3D;0, evictionCount&#x3D;2&#125;剩余数据信息：&#123;&#125;</code></pre><p>从结果中可以看出，超过过期时间之后，再次执行<code>get</code>操作已经获取不到已过期的记录，相关记录也被从缓存容器中移除了。请注意，上述代码中我们特地是在过期之后执行了一次<code>get</code>请求然后才去查看缓存容器中存留记录数量与统计信息的，主要是因为Guava Cache的过期数据淘汰是一种<strong>被动触发</strong>技能。</p><p>当然，细心的小伙伴可能会发现上面的执行结果有一个“问题”，就是前面一起<code>put</code>写入了3条记录，等到超过过期时间之后，只移除了2条过期数据，还剩了一条记录在里面？但是去获取剩余缓存里面的数据的时候又显示缓存里面是空的？</p><p><img src="https://pics.codingcoder.cn/pics/202211010755349.png"></p><p>Guava Cache作为一款优秀的本地缓存工具包，是不可能有这么个大的bug遗留在里面的，那是什么原因呢？</p><p>这个现象其实与Guava Cache的缓存淘汰实现机制有关系，前面说过Guava Cache的过期数据清理是一种被动触发技能，我们看下<code>getIfPresent</code>方法对应的实现源码，可以很明显的看出每次get请求的时候都会触发一次<code>cleanUp</code>操作：</p><p><img src="https://pics.codingcoder.cn/pics/202211011935449.png"></p><p>为了实现高效的多线程并发控制，Guava Cache采用了类似ConcurrentHashMap一样的<code>分段锁</code>机制，数据被分为了不同分片，每个分片同一时间只允许有一个线程执行写操作，这样降低并发锁争夺的竞争压力。而上面代码中也可以看出，执行清理的时候，仅针对当前查询的记录所在的<code>Segment</code>分片执行清理操作，而其余的分片的过期数据<strong>并不会</strong>触发清理逻辑 —— 这个也就是为什么前面例子中，明明3条数据都过期了，却只清理掉了其中的2条的原因。</p><p>为了验证上述的原因说明，我们可以在创建缓存容器的时候将<code>concurrencyLevel</code>设置为允许并发数为1，强制所有的数据都存放在同一个分片中：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public static void main(String[] args) &#123;    try &#123;        Cache&lt;String, String&gt; cache &#x3D; CacheBuilder.newBuilder()                .expireAfterWrite(1L, TimeUnit.SECONDS)                .concurrencyLevel(1)  &#x2F;&#x2F; 添加这一约束，强制所有数据放在一个分片中                .recordStats()                .build();                &#x2F;&#x2F; ...省略其余逻辑，与上一段代码相同    &#125; catch (Exception e) &#123;        e.printStackTrace();    &#125;&#125;</code></pre><p>重新运行后，从结果可以看出，这一次3条过期记录全部被清除了。</p><pre class="line-numbers language-none"><code class="language-none">put操作后，当前缓存记录数：3查询key1对应值：value1统计信息：CacheStats&#123;hitCount&#x3D;1, missCount&#x3D;0, loadSuccessCount&#x3D;0, loadExceptionCount&#x3D;0, totalLoadTime&#x3D;0, evictionCount&#x3D;0&#125;-------sleep 等待超过过期时间-------执行key1查询操作：null当前缓存记录数：0当前统计信息：CacheStats&#123;hitCount&#x3D;1, missCount&#x3D;1, loadSuccessCount&#x3D;0, loadExceptionCount&#x3D;0, totalLoadTime&#x3D;0, evictionCount&#x3D;3&#125;剩余数据信息：&#123;&#125;</code></pre><p>在实际的使用中，我们倒也无需过于关注数据过期是否有被从内存中真实移除这一点，因为Guava Cache会在保证业务数据准确的情况下，尽可能的兼顾处理性能，在该清理的时候，自会去执行对应的清理操作，所以也无需过于担心。</p><ul><li><strong>基于引用</strong></li></ul><p>基于引用回收的策略，核心是利用<code>JVM</code>虚拟机的<strong>GC机制</strong>来达到数据清理的目的。按照JVM的GC原理，当一个对象不再被引用之后，便会执行一系列的标记清除逻辑，并最终将其回收释放。这种实际使用的较少，此处不多展开。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h3 id="主动淘汰"><a href="#主动淘汰" class="headerlink" title="主动淘汰"></a>主动淘汰</h3><p>上述通过总体容量限制或者通过过期时间约束来执行的缓存数据清理操作，是属于一种<strong>被动触发</strong>的机制。</p><p>实际使用的时候也会有很多情况，我们需要从缓存中立即将指定的记录给删除掉。比如执行删除或者更新操作的时候我们就需要删除已有的历史缓存记录，这种情况下我们就需要<strong>主动调用</strong> Guava Cache提供的相关删除操作接口，来达到对应诉求。</p><table><thead><tr><th>接口名称</th><th>含义描述</th></tr></thead><tbody><tr><td>invalidate(key)</td><td>删除指定的记录</td></tr><tr><td>invalidateAll(keys)</td><td>批量删除给定的记录</td></tr><tr><td>invalidateAll()</td><td>清空整个缓存容器</td></tr></tbody></table><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h2 id="小结回顾"><a href="#小结回顾" class="headerlink" title="小结回顾"></a>小结回顾</h2><p>好啦，关于Guava Cache中的容量限制与数据淘汰策略，就介绍到这里了。关于本章的内容，你是否有自己的一些想法与见解呢？欢迎评论区一起交流下，期待和各位小伙伴们一起切磋、共同成长。</p><p>📣 <strong>补充说明1</strong> ：</p><blockquote><p>本文属于《<a href="https://juejin.cn/column/7140852038258147358">深入理解缓存原理与实战设计</a>》系列专栏的内容之一。该专栏围绕缓存这个宏大命题进行展开阐述，全方位、系统性地深度剖析各种缓存实现策略与原理、以及缓存的各种用法、各种问题应对策略，并一起探讨下缓存设计的哲学。</p><p>如果有兴趣，也欢迎关注此专栏。</p></blockquote><p>📣 <strong>补充说明2</strong> ：</p><ul><li>关于本文中涉及的<strong>演示代码</strong>的完整示例，我已经整理并提交到github中，如果您有需要，可以自取：<a href="https://github.com/veezean/JavaBasicSkills">https://github.com/veezean/JavaBasicSkills</a></li></ul><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><p><strong>我是悟道，聊技术、又不仅仅聊技术~</strong></p><p>如果觉得有用，请<strong>点赞 + 关注</strong>让我感受到您的支持。也可以关注下我的公众号【架构悟道】，获取更及时的更新。</p><p>期待与你一起探讨，一起成长为更好的自己。</p><p><img src="https://pics.codingcoder.cn/pics/202207091312091.gif"></p><p><img src="https://pics.codingcoder.cn/pics/202207091317876.png"></p>]]></content>
      
      
      <categories>
          
          <category> 缓存原理与实战设计 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JAVA </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>重新认识下JVM级别的本地缓存框架Guava Cache——优秀从何而来</title>
      <link href="//post/20221123080317.html"/>
      <url>//post/20221123080317.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>作为缓存系列专栏内容，秉持着不重复造轮子的理念，本篇文章中我们就开始深入剖析JAVA本地缓存的优秀轮子 —— 来自Google家族的Guava Cache。聊一聊其实现机制、看一看如何使用。</p></blockquote><p><img src="https://pics.codingcoder.cn/pics/202210050807355.png"></p><p>大家好，又见面了。</p><hr><blockquote><p>本文是笔者作为掘金技术社区签约作者的身份输出的缓存专栏系列内容，将会通过系列专题，讲清楚缓存的方方面面。如果感兴趣，欢迎关注以获取后续更新。</p></blockquote><hr><p>不知不觉，这已经是《<a href="https://juejin.cn/column/7140852038258147358">深入理解缓存原理与实战设计</a>》系列专栏的第6篇文章了。经过前面5篇文章的铺垫，我们系统且全面的介绍了缓存相关的概念与典型问题，也手动实操了如何构建一个本地最简版本的通用缓存框架，还对JAVA主流的本地缓存规范进行了解读。</p><p>秉持着不重复造轮子的理念，本篇文章中，我们就来一起深入剖析JAVA本地缓存的优秀“<strong>轮子</strong>” —— 来自<em>Google</em>家族的<code>Guava Cache</code>。聊一聊其实现<strong>机制</strong>、看一看如何<strong>使用</strong>。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h2 id="Guava-Cache初识"><a href="#Guava-Cache初识" class="headerlink" title="Guava Cache初识"></a>Guava Cache初识</h2><p><strong>Guava</strong>是Google提供的一套JAVA的工具包，而<code>Guava Cache</code>则是该工具包中提供的一套完善的<strong>JVM级别</strong>的高并发缓存框架。其实现机制类似<em>ConcurrentHashMap</em>，但是进行了众多的封装与能力扩展。作为JVM级别的本地缓存框架，<code>Guava Cache</code>具备缓存框架该有的众多基础特性。当然，Guava Cache能从众多本地缓存类产品中脱颖而出，除了具备上述基础缓存特性外，还有众多贴心的<em>能力增强</em>，绝对算得上是工具包届的<strong>超级暖男</strong>！为什么这么说呢？我们一起看下<em>Guava Cache</em>的能力介绍，应该可以有所体会。</p><p><img src="https://pics.codingcoder.cn/pics/202210302046179.png"></p><h3 id="支持缓存记录的过期设定"><a href="#支持缓存记录的过期设定" class="headerlink" title="支持缓存记录的过期设定"></a>支持缓存记录的过期设定</h3><p>作为一个合格的缓存容器，支持缓存记录过期是一个基础能力。<code>Guava Cache</code>不但支持设定过期时间，还支持选择是根据<code>插入时间</code>进行过期处理（<strong>创建过期</strong>）、或者是根据最后<code>访问时间</code>进行过期处理（<strong>访问过期</strong>）。</p><table><thead><tr><th>过期策略</th><th>具体说明</th></tr></thead><tbody><tr><td>创建过期</td><td>基于缓存记录的插入时间判断。比如设定10分钟过期，则记录加入缓存之后，<em>不管有没有访问</em>，10分钟时间到则</td></tr><tr><td>访问过期</td><td>基于最后一次的访问时间来判断是否过期。比如设定10分钟过期，如果缓存记录被访问到，则以最后一次访问时间重新计时；只有连续10分钟没有被访问的时候才会过期，否则将一直存在缓存中不会被过期。</td></tr></tbody></table><p>实际使用的时候，可以在创建缓存容器的时候指定过期策略即可：</p><ul><li>基于<strong>创建时间</strong>过期</li></ul><pre class="line-numbers language-java" data-language="java"><code class="language-java">public Cache&lt;String, User&gt; createUserCache() &#123;    return CacheBuilder.newBuilder()        .expireAfterWrite(30L, TimeUnit.MINUTES)        .build();&#125;</code></pre><ul><li>基于<strong>访问时间</strong>过期</li></ul><pre class="line-numbers language-java" data-language="java"><code class="language-java">public Cache&lt;String, User&gt; createUserCache() &#123;    return CacheBuilder.newBuilder()        .expireAfterAccess(30L, TimeUnit.MINUTES)        .build();&#125;</code></pre><p>是不是很方便？</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h3 id="支持缓存容量限制与不同淘汰策略"><a href="#支持缓存容量限制与不同淘汰策略" class="headerlink" title="支持缓存容量限制与不同淘汰策略"></a>支持缓存容量限制与不同淘汰策略</h3><p>作为内存型缓存，必须要防止出现内存溢出的风险。Guava Cache支持设定缓存容器的最大存储上限，并支持根据缓存记录<code>条数</code>或者基于每条缓存记录的<code>权重</code>（后面会具体介绍）进行判断是否达到容量阈值。</p><p>当容量触达阈值后，支持根据<code>FIFO + LRU</code>策略实施具体淘汰处理以腾出位置给新的记录使用。</p><table><thead><tr><th>淘汰策略</th><th>具体说明</th></tr></thead><tbody><tr><td>FIFO</td><td>根据缓存记录写入的顺序，先写入的先淘汰</td></tr><tr><td>LRU</td><td>根据访问顺序，淘汰最久没有访问的记录</td></tr></tbody></table><p>实际使用的时候，同样是在创建缓存容器的时候指定容量上限与淘汰策略，这样就可以放心大胆的使用而不用担心内存溢出问题咯。</p><ul><li>限制缓存<strong>记录条数</strong></li></ul><pre class="line-numbers language-java" data-language="java"><code class="language-java">public Cache&lt;String, User&gt; createUserCache() &#123;    return CacheBuilder.newBuilder()            .maximumSize(10000L)            .build();&#125;</code></pre><ul><li>限制缓存<strong>记录权重</strong></li></ul><pre class="line-numbers language-java" data-language="java"><code class="language-java">public Cache&lt;String, User&gt; createUserCache() &#123;    return CacheBuilder.newBuilder()            .maximumWeight(10000L)            .weigher((key, value) -&gt; (int) Math.ceil(instrumentation.getObjectSize(value) &#x2F; 1024L))            .build();    &#125;</code></pre><p>这里需要注意：按照权重进行限制缓存容量的时候必须要指定<code>weighter</code>属性才可以生效。上面代码中我们通过计算<code>value</code>对象的字节数（byte）来计算其权重信息，每1kb的字节数作为1个权重，整个缓存容器的总权重限制为1w，这样就可以实现将缓存内存占用控制在<code>10000*1k≈10M</code>左右。</p><p>有没有很省心？</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h3 id="支持集成数据源能力"><a href="#支持集成数据源能力" class="headerlink" title="支持集成数据源能力"></a>支持集成数据源能力</h3><p>在前面文章中，我们有介绍过缓存的<strong>三种模型</strong>，分别是<code>旁路型</code>、<code>穿透型</code>、<code>异步型</code>。Guava Cache作为一个封装好的缓存框架，是一个典型的<strong>穿透型缓存</strong>。正常业务使用缓存时通常会使用旁路型缓存，即先去缓存中尝试查询获取数据，如果获取不到则会从数据库中进行查询并加入到缓存中；而为了简化业务端使用复杂度，Guava Cache支持集成数据源，业务层面调用接口查询缓存数据的时候，如果缓存数据不存在，则会<em>自动</em>去数据源中进行数据获取并加入缓存中。</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public User findUser(Cache&lt;String, User&gt; cache, String userId) &#123;    try &#123;        return cache.get(userId, () -&gt; &#123;            System.out.println(userId + &quot;用户缓存不存在，尝试回源查找并回填...&quot;);            return userDao.getUser(userId);        &#125;);    &#125; catch (ExecutionException e) &#123;        e.printStackTrace();    &#125;    return null;&#125;</code></pre><p>实际使用的时候如果查询的用户不存在，则会自动去回源查找并写入缓存里，再次获取的时候便可以从缓存直接获取：</p><p><img src="https://pics.codingcoder.cn/pics/202210302145633.png"></p><p>上面的方法里，是通过在get方法里传入<code>Callable</code>实现的方式指定回源获取数据的方式，来实现缓存不存在情况的自动数据拉取与回填到缓存中的。实际使用的时候，除了Callable方式，还有一种<code>CacheLoader</code>的模式，也可以实现这一效果。</p><p>需要我们在创建缓存容器的时候声明容器为<strong>LoadingCache</strong>类型（下面的章节中有介绍），并且指定<code>CacheLoader</code>处理逻辑：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public LoadingCache&lt;String, User&gt; createUserCache() &#123;    return CacheBuilder.newBuilder()            .build(new CacheLoader&lt;String, User&gt;() &#123;                @Override                public User load(String key) throws Exception &#123;                    System.out.println(key + &quot;用户缓存不存在，尝试CacheLoader回源查找并回填...&quot;);                    return userDao.getUser(key);                &#125;            &#125;);    &#125;</code></pre><p>这样，获取不到数据的时候，也会自动回源查询并填充。比如我们执行如下调用逻辑：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public static void main(String[] args) &#123;    CacheService cacheService &#x3D; new CacheService();    LoadingCache&lt;String, User&gt; cache &#x3D; cacheService.createUserCache();    try &#123;        System.out.println(cache.get(&quot;123&quot;));        System.out.println(cache.get(&quot;124&quot;));        System.out.println(cache.get(&quot;123&quot;));    &#125; catch (Exception e) &#123;        e.printStackTrace();    &#125;&#125;</code></pre><p>执行结果如下：</p><pre class="line-numbers language-none"><code class="language-none">123用户缓存不存在，尝试CacheLoader回源查找并回填...User(userId&#x3D;123, userName&#x3D;铁柱, department&#x3D;研发部)124用户缓存不存在，尝试CacheLoader回源查找并回填...User(userId&#x3D;124, userName&#x3D;翠花, department&#x3D;测试部)User(userId&#x3D;123, userName&#x3D;铁柱, department&#x3D;研发部)</code></pre><p>两种方式都可以实现这一效果，实际可以根据需要与场景选择合适的方式。</p><p>当然，有些时候，可能也会涉及到<code>CacheLoader</code>与<code>Callable</code>两种方式结合使用的场景，这种情况下<strong>优先</strong>会执行<em>Callable</em>提供的逻辑，Callable缺失的场景会使用<em>CacheLoader</em>提供的逻辑。</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public static void main(String[] args) &#123;    CacheService cacheService &#x3D; new CacheService();    LoadingCache&lt;String, User&gt; cache &#x3D; cacheService.createUserCache();    try &#123;        System.out.println(cache.get(&quot;123&quot;, () -&gt; new User(&quot;xxx&quot;)));        System.out.println(cache.get(&quot;124&quot;));        System.out.println(cache.get(&quot;123&quot;));    &#125; catch (Exception e) &#123;        e.printStackTrace();    &#125;&#125;</code></pre><p>执行后，可以看出Callable逻辑被<em>优先执行</em>，而CacheLoader作为<em>兜底策略</em>存在：</p><pre class="line-numbers language-none"><code class="language-none">User(userId&#x3D;xxx, userName&#x3D;null, department&#x3D;null)124用户缓存不存在，尝试CacheLoader回源查找并回填...User(userId&#x3D;124, userName&#x3D;翠花, department&#x3D;测试部)User(userId&#x3D;xxx, userName&#x3D;null, department&#x3D;null)</code></pre><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h3 id="支持更新锁定能力"><a href="#支持更新锁定能力" class="headerlink" title="支持更新锁定能力"></a>支持更新锁定能力</h3><p>这个是与上面数据源集成一起的辅助增强能力。在高并发场景下，如果某个key值没有命中缓存，大量的请求同步打到下游模块处理的时候，很容易造成<strong>缓存击穿</strong>问题。</p><p><img src="https://pics.codingcoder.cn/pics/202210052100508.png"></p><p>为了防止缓存击穿问题，可以通过<strong>加锁</strong>的方式来规避。当缓存不可用时，仅<code>持锁的线程</code>负责从数据库中查询数据并写入缓存中，其余请求重试时先尝试从缓存中获取数据，避免所有的并发请求全部同时打到数据库上。</p><p>作为穿透型缓存的保护策略之一，<em>Guava Cache</em>自带了<code>并发锁定</code>机制，同一时刻仅允许一个请求去回源获取数据并回填到缓存中，而其余请求则阻塞等待，不会造成数据源的压力过大。</p><p>有没有被暖心到？</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h3 id="提供了缓存相关的一些监控统计"><a href="#提供了缓存相关的一些监控统计" class="headerlink" title="提供了缓存相关的一些监控统计"></a>提供了缓存相关的一些监控统计</h3><p>引入缓存的一个初衷是希望缓存能够提升系统的处理性能，而有限缓存容量中仅存储部分数据的时候，我们会希望存储的有限数据可以尽可能的覆盖并抗住大部分的请求流量，所以对缓存的<strong>命中率</strong>会非常关注。</p><p>Guava Cache深知这一点，所以提供了<code>stat</code>统计日志，支持查看缓存数据的<em>加载</em>或者<em>命中</em>情况统计。我们可以基于命中情况，不断的去优化代码中缓存的数据策略，以发挥出缓存的最大价值。</p><p>Guava Cache的统计信息封装为<code>CacheStats</code>对象进行承载，主要包含一下几个关键指标项：</p><table><thead><tr><th>指标</th><th>含义说明</th></tr></thead><tbody><tr><td>hitCount</td><td>命中缓存次数</td></tr><tr><td>missCount</td><td>没有命中缓存次数（查询的时候内存中没有）</td></tr><tr><td>loadSuccessCount</td><td>回源加载的时候加载成功次数</td></tr><tr><td>loadExceptionCount</td><td>回源加载但是加载失败的次数</td></tr><tr><td>totalLoadTime</td><td>回源加载操作总耗时</td></tr><tr><td>evictionCount</td><td>删除记录的次数</td></tr></tbody></table><p>缓存容器创建的时候，可以通过<code>recordStats()</code>开启缓存行为的统计记录：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public static void main(String[] args) &#123;    LoadingCache&lt;String, User&gt; cache &#x3D; CacheBuilder.newBuilder()            .recordStats()            .build(new CacheLoader&lt;String, User&gt;() &#123;                @Override                public User load(String key) throws Exception &#123;                    System.out.println(key + &quot;用户缓存不存在，尝试CacheLoader回源查找并回填...&quot;);                    User user &#x3D; userDao.getUser(key);                    if (user &#x3D;&#x3D; null) &#123;                        System.out.println(key + &quot;用户不存在&quot;);                    &#125;                    return user;                &#125;            &#125;);    try &#123;        System.out.println(cache.get(&quot;123&quot;);        System.out.println(cache.get(&quot;124&quot;));        System.out.println(cache.get(&quot;123&quot;));        System.out.println(cache.get(&quot;126&quot;));    &#125; catch (Exception e) &#123;    &#125; finally &#123;        CacheStats stats &#x3D; cache.stats();        System.out.println(stats);    &#125;&#125;</code></pre><p>上述代码执行之后结果输出如下：</p><pre class="line-numbers language-none"><code class="language-none">123用户缓存不存在，尝试CacheLoader回源查找并回填...User(userId&#x3D;123, userName&#x3D;铁柱, department&#x3D;研发部)124用户缓存不存在，尝试CacheLoader回源查找并回填...User(userId&#x3D;124, userName&#x3D;翠花, department&#x3D;测试部)User(userId&#x3D;123, userName&#x3D;铁柱, department&#x3D;研发部)126用户缓存不存在，尝试CacheLoader回源查找并回填...126用户不存在CacheStats&#123;hitCount&#x3D;1, missCount&#x3D;3, loadSuccessCount&#x3D;2, loadExceptionCount&#x3D;1, totalLoadTime&#x3D;1972799, evictionCount&#x3D;0&#125;</code></pre><p>可以看出，一共执行了4次请求，其中1次命中，3次回源处理，2次回源加载成功，1次回源没找到数据，与打印出来的<code>CacheStats</code>统计结果完全吻合。</p><p>有着上述能力的加持，前面将Guava Cache称作“<strong>暖男</strong>”不过分吧？</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h2 id="Guava-Cache适用场景"><a href="#Guava-Cache适用场景" class="headerlink" title="Guava Cache适用场景"></a>Guava Cache适用场景</h2><p>在本系列专栏的第一篇文章《<a href="https://juejin.cn/post/7151937376578142216">聊一聊作为高并发系统基石之一的缓存，会用很简单，用好才是技术活</a>》中，我们在缓存的一步步演进介绍中提过本地缓存与集中式缓存的区别，也聊了各自的优缺点。</p><p>作为一款纯粹的本地缓存框架，Guava Cache具备本地缓存该有的<strong>优势</strong>，也无可避免的存在着本地缓存的<strong>弊端</strong>。</p><table><thead><tr><th>维度</th><th>简要概述</th></tr></thead><tbody><tr><td>优势</td><td>基于<strong>空间换时间</strong>的策略，利用内存的高速处理效率，提升机器的处理性能，减少大量对外的<em>IO请求</em>交互，比如读取DB、请求外部网络、读取本地磁盘数据等等操作。</td></tr><tr><td>弊端</td><td>整体<strong>容量受限</strong>，可能对本机内存造成压力。此外，对于分布式多节点集群部署的场景，缓存更新场景会出现<strong>缓存漂移</strong>问题，导致各个节点之间的缓存<em>数据不一致</em>。</td></tr></tbody></table><p>鉴于上述优劣综合判断，可以大致圈定<code>Guava Cache</code>的实际适用场合：</p><ul><li>数据<strong>读多写少</strong>且对<strong>一致性要求不高</strong>的场景</li></ul><p>这类场景中，会将数据缓存到本地内存中，采用定时触发（或者事件推送）的策略重新加载到内存中。这样业务处理逻辑直接从内存读取需要的数据，修改系统配置项之后，需要等待一定的时间后方可生效。</p><p>很多的配置中心采用的都是这个缓存策略。统一配置中心中管理配置数据，然后各个业务节点会从统一配置中心拉取配置并存储在自己本地的内存中然后使用本地内存中的数据。这样可以有效规避配置中心的单点故障问题，降低了配置中心的请求压力，也提升了业务节点自身的业务处理性能（减少了与配置中心之间的网络交互请求）。</p><ul><li>对<strong>性能</strong>要求<strong>极其严苛</strong>的场景</li></ul><p>对于分布式系统而言，集中式缓存是一个常规场景中很好的选项。但是对于一些超大并发量且读性能要求严苛的系统而言，一个请求流程中需要频繁的去与Redis交互，其网络开销也是不可忍受的。所以可以采用将数据本机内存缓存的方式，分散redis的压力，降低对外请求交互的次数，提升接口响应速度。</p><ul><li>简单的本地数据缓存，作为<code>HashMap/ConcurrentHashMap</code>的<strong>替代品</strong></li></ul><p>这种场景也很常见，我们在项目中经常会遇到一些数据的需要临时缓存一下，为了方便很多时候直接使用的<code>HashMap</code>或者<code>ConcurrentHashMap</code>来实现。而Guava Cache聚焦缓存场景做了很多额外的功能增强（比如数据过期能力支持、容量上限约束等），可以完美替换掉<em>HashMap&#x2F;ConcurrentHashMap</em>，更适合缓存场景使用。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h2 id="Guava-Cache使用"><a href="#Guava-Cache使用" class="headerlink" title="Guava Cache使用"></a>Guava Cache使用</h2><h3 id="引入依赖"><a href="#引入依赖" class="headerlink" title="引入依赖"></a>引入依赖</h3><p>使用Guava Cache，首先需要引入对应的依赖包。对于Maven项目，可以在<code>pom.xml</code>中添加对应的依赖声明即可：</p><pre class="line-numbers language-markup" data-language="markup"><code class="language-markup">&lt;dependency&gt;    &lt;groupId&gt;com.google.guava&lt;&#x2F;groupId&gt;    &lt;artifactId&gt;guava&lt;&#x2F;artifactId&gt;    &lt;version&gt;31.1-jre&lt;&#x2F;version&gt;&lt;&#x2F;dependency&gt;</code></pre><p>这样，就完成了依赖引入。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h3 id="容器创建-——-CacheBuilder"><a href="#容器创建-——-CacheBuilder" class="headerlink" title="容器创建 —— CacheBuilder"></a>容器创建 —— CacheBuilder</h3><p>具体使用前首先面临的就是如何创建Guava Cache实例。可以借助<code>CacheBuilder</code>以一种优雅的方式来构建出合乎我们诉求的Cache实例。</p><p>对<em>CacheBuilder</em>中常见的属性方法，归纳说明如下：</p><table><thead><tr><th>方法</th><th>含义说明</th></tr></thead><tbody><tr><td>newBuilder</td><td>构造出一个Builder实例类</td></tr><tr><td>initialCapacity</td><td>待创建的缓存容器的初始容量大小（记录<strong>条数</strong>）</td></tr><tr><td>maximumSize</td><td>指定此缓存容器的最大容量(最大缓存记录<strong>条数</strong>)</td></tr><tr><td>maximumWeight</td><td>指定此缓存容器的最大容量（最大<strong>比重</strong>值），需结合<code>weighter</code>方可体现出效果</td></tr><tr><td>expireAfterWrite</td><td>设定过期策略，按照数据<strong>写入时间</strong>进行计算</td></tr><tr><td>expireAfterAccess</td><td>设定过期策略，按照数据最后<strong>访问时间</strong>来计算</td></tr><tr><td>weighter</td><td>入参为一个函数式接口，用于指定每条存入的缓存数据的权重占比情况。这个需要与<code>maximumWeight</code>结合使用</td></tr><tr><td>refreshAfterWrite</td><td>缓存写入到缓存之后</td></tr><tr><td>concurrencyLevel</td><td>用于控制缓存的并发处理能力，同时支持多少个线程<strong>并发写入</strong>操作</td></tr><tr><td>recordStats</td><td>设定开启此容器的数据加载与缓存命中情况统计</td></tr></tbody></table><p>基于<code>CacheBuilder</code>及其提供的各种方法，我们可以轻松的进行缓存容器的构建、并指定容器的各种约束条件。</p><p>比如下面这样：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public LoadingCache&lt;String, User&gt; createUserCache() &#123;    return CacheBuilder.newBuilder()            .initialCapacity(1000) &#x2F;&#x2F; 初始容量            .maximumSize(10000L)   &#x2F;&#x2F; 设定最大容量            .expireAfterWrite(30L, TimeUnit.MINUTES) &#x2F;&#x2F; 设定写入过期时间            .concurrencyLevel(8)  &#x2F;&#x2F; 设置最大并发写操作线程数            .refreshAfterWrite(1L, TimeUnit.MINUTES) &#x2F;&#x2F; 设定自动刷新数据时间            .recordStats() &#x2F;&#x2F; 开启缓存执行情况统计            .build(new CacheLoader&lt;String, User&gt;() &#123;                @Override                public User load(String key) throws Exception &#123;                    return userDao.getUser(key);                &#125;            &#125;);&#125;</code></pre><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h3 id="业务层使用"><a href="#业务层使用" class="headerlink" title="业务层使用"></a>业务层使用</h3><p>Guava Cache容器对象创建完成后，可以基于其提供的对外接口完成相关缓存的具体操作。首先可以了解下Cache提供的对外操作接口：</p><p><img src="https://pics.codingcoder.cn/pics/202210301758601.png"></p><p>对关键接口的含义梳理归纳如下：</p><table><thead><tr><th>接口名称</th><th>具体说明</th></tr></thead><tbody><tr><td>get</td><td>查询指定key对应的value值，如果缓存中没匹配，则基于给定的<code>Callable</code>逻辑去获取数据回填缓存中并返回</td></tr><tr><td>getIfPresent</td><td>如果缓存中存在指定的key值，则返回对应的value值，否则返回null（此方法<strong>不会触发</strong>自动回源与回填操作）</td></tr><tr><td>getAllPresent</td><td>针对传入的key列表，返回缓存中存在的对应value值列表（<strong>不会触发</strong>自动回源与回填操作）</td></tr><tr><td>put</td><td>往缓存中添加key-value键值对</td></tr><tr><td>putAll</td><td>批量往缓存中添加key-value键值对</td></tr><tr><td>invalidate</td><td>从缓存中删除指定的记录</td></tr><tr><td>invalidateAll</td><td>从缓存中批量删除指定记录，如果无参数，则清空所有缓存</td></tr><tr><td>size</td><td>获取缓存容器中的总记录数</td></tr><tr><td>stats</td><td>获取缓存容器当前的统计数据</td></tr><tr><td>asMap</td><td>将缓存中的数据转换为<code>ConcurrentHashMap</code>格式返回</td></tr><tr><td>cleanUp</td><td>清理所有的已过期的数据</td></tr></tbody></table><p>在项目中，可以基于上述接口，实现各种缓存操作功能。</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public static void main(String[] args) &#123;    CacheService cacheService &#x3D; new CacheService();    LoadingCache&lt;String, User&gt; cache &#x3D; cacheService.createUserCache6();    cache.put(&quot;122&quot;, new User(&quot;122&quot;));    cache.put(&quot;122&quot;, new User(&quot;122&quot;));    System.out.println(&quot;put操作后查询：&quot; + cache.getIfPresent(&quot;122&quot;));    cache.invalidate(&quot;122&quot;);    System.out.println(&quot;invalidate操作后查询：&quot; + cache.getIfPresent(&quot;122&quot;));    System.out.println(cache.stats());&#125;</code></pre><p>执行后，结果如下：</p><pre class="line-numbers language-none"><code class="language-none">put操作后查询：User(userId&#x3D;122, userName&#x3D;null, department&#x3D;null)invalidate操作后查询：nullCacheStats&#123;hitCount&#x3D;1, missCount&#x3D;1, loadSuccessCount&#x3D;0, loadExceptionCount&#x3D;0, totalLoadTime&#x3D;0, evictionCount&#x3D;0&#125;</code></pre><p>当然，上述示例代码中这种使用方式有个明显的弊端就是业务层面对Guava Cache的<code>私有API</code><strong>依赖过深</strong>，后续如果需要替换Cache组件的时候会比较痛苦，需要对业务调用的地方进行大改。所以真正项目里面，最好还是对其适当封装，以实现业务层面的<strong>解耦</strong>。如果你的项目是使用Spring框架，也可以基于<code>Spring Cache</code>统一规范来集成并使用Guava Cache，降低对业务逻辑的<strong>侵入</strong>。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h2 id="小结回顾"><a href="#小结回顾" class="headerlink" title="小结回顾"></a>小结回顾</h2><p>好啦，关于Guava Cache的功能与关键特性介绍，以及项目中具体的集成与使用方法，就介绍到这里了。总结一下，Guava Cache其实就是一个增强版的大号ConcurrentHashMap，在保证线程安全的情况下，增加了缓存必备的数据过期、容量限制、回源策略等能力，既保证了本身的精简，又使得整体能力足以满足大部分本地缓存场景的使用诉求。也正是由于这些原因，Guava Cache在JAVA领域广受好评，使用范围非常的广泛。</p><p>下一篇文章中，我们将继续对Guava Cache展开讨论，跳出使用层面，剖析其内部核心实现逻辑。如果有兴趣，欢迎关注后续文章的更新。</p><p>那么，关于本文中提及的内容，你是否有自己的一些想法与见解呢？欢迎评论区一起交流下，期待和各位小伙伴们一起切磋、共同成长。</p><p>📣 <strong>补充说明1</strong> ：</p><blockquote><p>本文属于《<a href="https://juejin.cn/column/7140852038258147358">深入理解缓存原理与实战设计</a>》系列专栏的内容之一。该专栏围绕缓存这个宏大命题进行展开阐述，全方位、系统性地深度剖析各种缓存实现策略与原理、以及缓存的各种用法、各种问题应对策略，并一起探讨下缓存设计的哲学。</p><p>如果有兴趣，也欢迎关注此专栏。</p></blockquote><p>📣 <strong>补充说明2</strong> ：</p><ul><li>关于本文中涉及的<strong>演示代码</strong>的完整示例，我已经整理并提交到github中，如果您有需要，可以自取：<a href="https://github.com/veezean/JavaBasicSkills">https://github.com/veezean/JavaBasicSkills</a></li></ul><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><p><strong>我是悟道，聊技术、又不仅仅聊技术~</strong></p><p>如果觉得有用，请<strong>点赞 + 关注</strong>让我感受到您的支持。也可以关注下我的公众号【架构悟道】，获取更及时的更新。</p><p>期待与你一起探讨，一起成长为更好的自己。</p><p><img src="https://pics.codingcoder.cn/pics/202207091312091.gif"></p><p><img src="https://pics.codingcoder.cn/pics/202207091317876.png"></p>]]></content>
      
      
      <categories>
          
          <category> 缓存原理与实战设计 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JAVA </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JAVA缓存规范 —— 虽迟但到的JCache API与天生不俗的Spring Cache</title>
      <link href="//post/20221116065417.html"/>
      <url>//post/20221116065417.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>业界各大厂商或开源团队都会构建并提供一些缓存框架组件提供给开发者按需选择，这里就会涉及到一个标准规范的遵循问题，本文我们一起聊聊JCache API规范与SpringCache规范。</p></blockquote><hr><p><img src="https://pics.codingcoder.cn/pics/202210050807355.png"></p><p>大家好，又见面了。</p><hr><blockquote><p>本文是笔者作为掘金技术社区签约作者的身份输出的缓存专栏系列内容，将会通过系列专题，讲清楚缓存的方方面面。如果感兴趣，欢迎关注以获取后续更新。</p></blockquote><hr><p>有诗云“纸上得来终觉浅，绝知此事要躬行”，在上一篇文章《<a href="https://juejin.cn/post/7155278117479645221">手写本地缓存实战2—— 打造正规军，构建通用本地缓存框架</a>》中，我们一起论证并逐步实现了一套简化版本的通用本地缓存框架，并在过程中逐步剖析了缓存设计关键要素的实现策略。本篇文章中，我们一起来聊一聊缓存框架实现所需要遵循的规范。</p><h2 id="为何需要规范"><a href="#为何需要规范" class="headerlink" title="为何需要规范"></a>为何需要规范</h2><p>上一章中构建的最简化版本的缓存框架，虽然可以使用，但是也存在一个问题，就是它对外提供的实现接口都是框架根据自己的需要而自定义的。这样一来，项目集成了此缓存框架，后续如果想要更换缓存框架的时候，业务层面的改动会比较大。 —— 因为是自定义的框架接口，无法基于<code>里氏替换</code>原则来进行灵活的更换。</p><p>在业界各大厂商或者开源团队都会构建并提供一些自己实现的缓存框架或者组件，提供给开发者按需选择使用。如果大家都是各自<strong>闭门造车</strong>，势必导致业务中集成并使用某一缓存实现之后，想要更换缓存实现组件会难于登天。</p><p>千古一帝秦始皇统一天下后，颁布了<em>书同文、车同轨</em>等一系列法规制度，使得所有的车辆都遵循统一的轴距，然后都可以在官道上正常的通行，大大提升了流通性。而正所谓“国有国法、行有行规”，为了保证缓存框架的通用性、提升项目的可移植性，JAVA行业也迫切需要这么一个<strong>缓存规范</strong>，来约束各个缓存提供商给出的缓存框架都遵循相同的规范接口，业务中按照标准接口进行调用，无需与缓存框架进行深度耦合，使得缓存组件的更换成为一件简单点的事情。</p><p><img src="https://pics.codingcoder.cn/pics/202210262122466.png"></p><p>在JAVA的缓存领域，流传比较广泛的主要是<code>JCache API</code>和<code>Spring Cache</code>两套规范，下面就一起来看下。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h2 id="虽迟但到的JSR107-——-JCache-API"><a href="#虽迟但到的JSR107-——-JCache-API" class="headerlink" title="虽迟但到的JSR107 —— JCache API"></a>虽迟但到的JSR107 —— JCache API</h2><p>提到JAVA中的“行业规矩”，<code>JSR</code>是一个绕不开的话题。它的全称为<code>Java Specification Requests</code>，意思是<strong>JAVA规范提案</strong>。在该规范标准中，有公布过一个关于JAVA缓存体系的规范定义，也即<code>JSR 107</code>规范（<em>JCache API</em>），主要明确了JAVA中基于内存进行对象缓存构建的一些要求，涵盖内存对象的<em>创建</em>、<em>查询</em>、<em>更新</em>、<em>删除</em>、<em>一致性保证</em>等方面内容。</p><p><strong>JSR107</strong>规范早在<code>2012年</code>时草案就被提出，但却直到<code>2014年</code>才正式披露首个规范版本，也即<code>JCache API 1.0.0</code>版本，至此JAVA领域总算是有个正式的关于缓存的官方规范要求。</p><h3 id="揭秘JSR107-——-JCache-API内容探究"><a href="#揭秘JSR107-——-JCache-API内容探究" class="headerlink" title="揭秘JSR107 —— JCache API内容探究"></a>揭秘JSR107 —— JCache API内容探究</h3><p><strong>JSR107</strong>规范具体的要求形式，都以接口的形式封装在<code>javax.cache</code>包中进行提供。我们要实现的缓存框架需要遵循该规范，也就是需要引入<em>javax.cache</em>依赖包，并实现其中提供的相关接口即可。对于使用maven构建的项目中，可以在<code>pom.xml</code>中引入javax.cache依赖：</p><pre class="line-numbers language-markup" data-language="markup"><code class="language-markup">&lt;dependency&gt;    &lt;groupId&gt;javax.cache&lt;&#x2F;groupId&gt;    &lt;artifactId&gt;cache-api&lt;&#x2F;artifactId&gt;    &lt;version&gt;1.1.1&lt;&#x2F;version&gt;&lt;&#x2F;dependency&gt;</code></pre><p>在<code>JCache API</code>规范中，定义的缓存框架相关接口类之间的关系逻辑梳理如下：</p><p><img src="https://pics.codingcoder.cn/pics/202210141512700.png"></p><p>我们要实现自己的本地缓存框架，也即需要实现上述各个接口。对上述各接口类的含义介绍说明如下：</p><table><thead><tr><th>接口类</th><th>功能定位描述</th></tr></thead><tbody><tr><td>CachingProvider</td><td><strong>SPI接口</strong>，缓存框架的加载入口。每个<code>Provider</code>中可以持有1个或者多个<code>CacheManager</code>对象，用来提供不同的缓存能力</td></tr><tr><td>CacheManager</td><td>缓存管理器接口，每个缓存管理器负责对具体的缓存容器的创建与管理，可以管理1个或者多个不同的<code>Cache</code>对象</td></tr><tr><td>Cache</td><td><code>Cache</code>缓存容器接口，负责存储具体的缓存数据，可以提供不同的容器能力</td></tr><tr><td>Entry</td><td><code>Cache</code>容器中存储的<code>key-value</code>键值对记录</td></tr></tbody></table><p>作为通用规范，这里将<code>CachingProvider</code>定义为了一个<strong>SPI接口</strong>（<code>Service Provider Interface</code>，服务提供接口），主要是借助JDK自带的服务提供发现能力，来实现按需加载各自实现的功能逻辑，有点<code>IOC</code>的意味。这样设计有一定的好处：</p><ul><li><strong>对于框架</strong>：</li></ul><p>需要遵循规范，提供上述接口的实现类。然后可以实现热插拔，与业务解耦。</p><ul><li><strong>对于业务</strong>：</li></ul><p>先指定需要使用的<code>SPI</code>的具体实现类，然后业务逻辑中便无需感知缓存具体的实现，直接基于<code>JCache API</code>通用接口进行使用即可。后续如果需要更换缓存实现框架，只需要切换下使用的<code>SPI</code>的具体实现类即可。</p><p>根据上述介绍，一个基于<strong>JCache API</strong>实现的缓存框架在实际项目中使用时的对象层级关系可能会是下面这种场景（假设使用<em>LRU策</em>略存储部门信息、使用<em>普通策略</em>存储用户信息）：</p><p><img src="https://pics.codingcoder.cn/pics/202210150833102.png"></p><p>那么如何去理解<code>JCache API</code>中几个接口类的关系呢？</p><p>几个简单的说明：</p><ol><li><p><strong>CachingProvider</strong>并无太多实际逻辑层面的功能，只是用来基于SPI机制，方便项目中集成插拔使用。内部持有CacheManager对象，实际的缓存管理能力，由CacheManager负责提供。</p></li><li><p><strong>CacheManager</strong>负责具体的缓存管理相关能力实现，实例由<code>CachingProvider</code>提供并持有，CachingProvider可以持有一个或者多个不同的<code>CacheManager</code>对象。这些CacheManager对象可以是相同类型，也可以是不同类型，比如我们可以实现2种缓存框架，一种是<code>基于内存</code>的缓存，一种是<code>基于磁盘</code>的缓存，则可以分别提供两种不同的<em>CacheManager</em>，供业务按需调用。</p></li><li><p><strong>Cache</strong>是CacheManager负责创建并管理的具体的缓存容器，也可以有一个或者多个，如业务中会涉及到为用户列表和部门列表分别创建独立的<code>Cache</code>存储。此外，Cache容器也可以根据需要提供不同的Cache容器类型，以满足不同场景对于缓存容器的不同诉求，如我们可以实现一个类似<code>HashMap</code>的普通键值对Cache容器，也可以提供一个基于<code>LRU</code>淘汰策略的Cache容器。</p></li></ol><p>至此呢，我们厘清了<strong>JCache API</strong>规范的大致内容。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h3 id="插叙-——-SPI何许人也"><a href="#插叙-——-SPI何许人也" class="headerlink" title="插叙 —— SPI何许人也"></a>插叙 —— SPI何许人也</h3><p>按照<code>JSR107</code>规范试编写缓存具体能力时，我们需要实现一个<strong>SPI接口</strong>的实现类，然后由JDK提供的加载能力将我们扩展的缓存服务加载到JVM中供使用。</p><p>提到<em>API</em>我们都耳熟能详，也就是我们常规而言的接口。但说起<strong>SPI</strong>也许很多小伙伴就有点陌生了。其实SPI也并非是什么新鲜玩意，它是<em>JDK内置</em>的一种服务的<strong>提供</strong>与<strong>发现</strong>、<strong>加载</strong>机制。按照JAVA的面向对象编码的思想，为了降低代码的耦合度、提升代码的灵活性，往往需要利用好<code>抽象</code>这一特性，比如一般会比较推荐基于接口进行编码、而尽量避免强依赖某个具体的功能实现类 —— 这样才能让构建出的系统具有更好的扩展性，更符合面向对象设计原则中的<code>里式替换</code>原则。SPI便是为了支持这一诉求而提供的能力，它允许将接口具体的实现类交由业务或者三方进行独立构建，然后加载到JVM中以供业务进行使用。</p><p>为了这一点，我们需要在<code>resource/META-INF/services</code>目录下新建一个文件，文件名即为SPI接口名称<code>javax.cache.spi.CachingProvider</code>，然后在文件内容中，写入我们要注入进入的我们自己的<strong>Provider</strong>实现类：</p><p><img src="https://pics.codingcoder.cn/pics/202210150945611.png"></p><p>这样，我们就完成了将我们自己的<code>MyCachingProvider</code>功能注入到系统中。在业务使用时，可以通过<code>Caching.getCachingProvider()</code>获取到注入的自定义<strong>Provider</strong>。</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public static void main(String[] args) &#123;    CachingProvider provider &#x3D;  Caching.getCachingProvider();    System.out.println(provider);&#125;</code></pre><p>从输出的结果可以看出，获取到了自定义的Provider对象：</p><pre class="line-numbers language-none"><code class="language-none">com.veezean.skills.cache.fwk.MyCachingProvider@7adf9f5f</code></pre><p>获取到<code>Provider</code>之后，便可以进一步的获取到<code>Manager</code>对象，进而业务层面层面可以正常使用。</p><h3 id="JCache-API规范的实现"><a href="#JCache-API规范的实现" class="headerlink" title="JCache API规范的实现"></a>JCache API规范的实现</h3><p><strong>JSR</strong>作为JAVA领域正统行规，制定的时候往往考虑到各种可能的灵活性与通用性。作为JSR中根正苗红的<code>JCache API</code>规范，也沿袭了这一风格特色，框架接口的定义与实现也非常的丰富，几乎可以扩展自定义任何你需要的处理策略。 —— 但恰是这一点，也让其整个框架的接口定义过于<strong>重量级</strong>。对于缓存框架实现者而言，遵循<code>JCache API</code>需要实现众多的接口，需要做很多额外的实现处理。</p><p>比如，我们实现<code>CacheManager</code>的时候，需要实现如下这么多的接口：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public class MemCacheManager implements CacheManager &#123;    private CachingProvider cachingProvider;    private ConcurrentHashMap&lt;String, Cache&gt; caches;    public MemCacheManager(CachingProvider cachingProvider, ConcurrentHashMap&lt;String, Cache&gt; caches) &#123;        this.cachingProvider &#x3D; cachingProvider;        this.caches &#x3D; caches;    &#125;    @Override    public CachingProvider getCachingProvider() &#123;    &#125;    @Override    public URI getURI() &#123;    &#125;    @Override    public ClassLoader getClassLoader() &#123;    &#125;    @Override    public Properties getProperties() &#123;    &#125;    @Override    public &lt;K, V, C extends Configuration&lt;K, V&gt;&gt; Cache&lt;K, V&gt; createCache(String s, C c) throws IllegalArgumentException &#123;    &#125;    @Override    public &lt;K, V&gt; Cache&lt;K, V&gt; getCache(String s, Class&lt;K&gt; aClass, Class&lt;V&gt; aClass1) &#123;    &#125;    @Override    public &lt;K, V&gt; Cache&lt;K, V&gt; getCache(String s) &#123;    &#125;    @Override    public Iterable&lt;String&gt; getCacheNames() &#123;    &#125;    @Override    public void destroyCache(String s) &#123;    &#125;    @Override    public void enableManagement(String s, boolean b) &#123;    &#125;    @Override    public void enableStatistics(String s, boolean b) &#123;    &#125;    @Override    public void close() &#123;    &#125;    @Override    public boolean isClosed() &#123;    &#125;    @Override    public &lt;T&gt; T unwrap(Class&lt;T&gt; aClass) &#123;    &#125;&#125;</code></pre><p>长长的一摞接口等着实现，看着都<strong>令人上头</strong>，作为缓存提供商，便需要按照自己的能力去实现这些接口，以保证相关缓存能力是按照规范对外提供。也正是因为JCache API这种不接地气的表现，让其虽是JAVA 领域的正统规范，却经常被<em>束之高阁</em>，沦落成为了一种名义规范。业界主流的本地缓存框架中，比较出名的当属<code>Ehcache</code>了（当然，<code>Spring4.1</code>中也增加了对JSR规范的支持）。此外，<strong>Redis</strong>的本地客户端<code>Redisson</code>也有实现全套JCache API规范，用户可以基于Redisson调用JCache API的标准接口来进行缓存数据的操作。</p><h3 id="JSR107提供的注解操作方法"><a href="#JSR107提供的注解操作方法" class="headerlink" title="JSR107提供的注解操作方法"></a>JSR107提供的注解操作方法</h3><p>前面提到了作为供应商想要实现<em>JSR107</em>规范的时候会比较复杂，需要做很多自己的处理逻辑。但是对于业务使用者而言，JSR107还是比较贴心的。比如JSR107中就将一些常用的API方法封装为<code>注解</code>，利用注解来大大简化编码的复杂度，降低缓存对于业务逻辑的<em>侵入性</em>，使得业务开发人员可以更加专注于业务本身的开发。</p><p><code>JSR107</code>规范中常用的一些缓存操作注解方法梳理如下面的表格：</p><table><thead><tr><th>注解</th><th>含义说明</th></tr></thead><tbody><tr><td>@CacheResult</td><td>将指定的<code>key</code>和<code>value</code>映射内容存入到缓存容器中</td></tr><tr><td>@CachePut</td><td>更新指定缓存容器中指定<code>key</code>值缓存记录内容</td></tr><tr><td>@CacheRemove</td><td>移除指定缓存容器中指定<code>key</code>值对应的缓存记录</td></tr><tr><td>@CacheRemoveAll</td><td>字面含义，移除指定缓存容器中的所有缓存记录</td></tr><tr><td>@CacheKey</td><td>作为接口参数前面修饰，用于指定特定的入参作为缓存<code>key</code>值的组成部分</td></tr><tr><td>@CacheValue</td><td>作为接口参数前面的修饰，用于指定特定的入参作为缓存<code>value</code>值</td></tr></tbody></table><p>上述注解主要是添加在方法上面，用于自动将方法的入参与返回结果之间进行一个映射与自动缓存，对于后续请求如果命中缓存则直接返回缓存结果而无需再次执行方法的具体处理，以此来提升接口的响应速度与承压能力。</p><p>比如下面的查询接口上，通过<code>@CacheResult</code>注解可以将查询请求与查询结果缓存起来进行使用：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">@CacheResult(cacheName &#x3D; &quot;books&quot;)public Book findBookByName(@CacheKey String bookName) &#123;    return bookDao.queryByName(bookName);&#125;</code></pre><p>当<strong>Book</strong>信息发生变更的时候，为了保证缓存数据的准确性，需要同步更新缓存内容。可以通过在更新方法上面添加<code>@CachePut</code>接口即可达成目的：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">@CachePut(cacheName &#x3D; &quot;books&quot;)public void updateBookInfo(@CacheKey String bookName, @CacheValue Book book) &#123;    bookDao.updateBook(bookName, book);&#125;</code></pre><p>这里分别适用了<code>@CacheKey</code>和<code>@CacheValue</code>指定了需要更新的缓存记录key值，以及需要将其更新为的新的value值。</p><p>同样地，借助注解<code>@CacheRemove</code>可以完成对应缓存记录的删除：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">@CacheRemove(cacheName &#x3D; &quot;books&quot;)public void deleteBookInfo(@CacheKey String bookName) &#123;    bookDao.deleteBookByName(bookName)&#125;</code></pre><h2 id="爱屋及乌-——-Spring框架制定的Cache规范"><a href="#爱屋及乌-——-Spring框架制定的Cache规范" class="headerlink" title="爱屋及乌 —— Spring框架制定的Cache规范"></a>爱屋及乌 —— Spring框架制定的Cache规范</h2><p>JSR 107（JCache API）规范的诞生可谓是一路坎坷，拖拖拉拉直到<strong>2014</strong>年才发布了首个<code>1.0.0</code>版本规范。但是在JAVA界风头无两的<strong>Spring</strong>框架早在<code>2011</code>年就已经在其3.1版本中提供了缓存抽象层的规范定义，并借助Spring的优秀设计与良好生态，迅速得到了各个软件开发团体的青睐，各大缓存厂商也陆续提供了符合<code>Spring Cache</code>规范的自家缓存产品。</p><p><strong>Spring Cache</strong>并非是一个具体的缓存实现，而是和JSR107类似的一套<em>缓存规范</em>，基于注解并可实现与Spring的各种高级特性无缝集成，受到了广泛的追捧。各大缓存提供商几乎都有基于Spring Cache规范进行实现的缓存组件。比如后面我们会专门介绍的<code>Guava Cache</code>、<code>Caffeine Cache</code>以及同样支持JSR107规范的<code>Ehcache</code>等等。</p><p>得力于Spring在JAVA领域无可撼动的地位，造就了<strong>Spring Cache</strong>已成为JAVA缓存领域的“事实标准”，深有“<em>功高盖主</em>”的味道。</p><h3 id="Spring-Cache使用不同缓存组件"><a href="#Spring-Cache使用不同缓存组件" class="headerlink" title="Spring Cache使用不同缓存组件"></a>Spring Cache使用不同缓存组件</h3><p>如果要基于<code>Spring Cache</code>规范来进行缓存的操作，首先在项目中需要引入此规范的定义：</p><pre class="line-numbers language-markup" data-language="markup"><code class="language-markup">&lt;dependency&gt;    &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt;    &lt;artifactId&gt;spring-boot-starter-cache&lt;&#x2F;artifactId&gt;&lt;&#x2F;dependency&gt;</code></pre><p>这样，在业务代码中，就可以使用Spring Cache规范中定义的一些注解方法。前面有提过，<em>Spring Cache只是一个规范声明</em>，可以理解为一堆接口定义，而并没有提供具体的接口功能实现。具体的功能实现，由业务根据实际选型需要，引入相应缓存组件的jar库文件依赖即可 —— 这一点是Spring框架中极其普遍的一种做法。</p><p>假如我们需要使用<code>Guava Cache</code>来作为我们实际缓存能力提供者，则我们只需要引入对应的依赖即可：</p><pre class="line-numbers language-markup" data-language="markup"><code class="language-markup">&lt;dependency&gt;    &lt;groupId&gt;com.google.guava&lt;&#x2F;groupId&gt;    &lt;artifactId&gt;guava&lt;&#x2F;artifactId&gt;    &lt;version&gt;30.1.1-jre&lt;&#x2F;version&gt;&lt;&#x2F;dependency&gt;</code></pre><p>这样一来，我们便实现了使用Guava cache作为存储服务提供者、且基于Spring Cache接口规范进行缓存操作。Spring作为JAVA领域的一个相当优秀的框架，得益于其优秀的<strong>封装</strong>设计思想，使得更换缓存组件也显得非常容易。比如现在想要将上面的<em>Guava cache</em>更换为<code>Caffeine cache</code>作为新的缓存能力提供者，则业务代码中将依赖包改为Caffeine cache并简单的做一些细节配置即可：</p><pre class="line-numbers language-markup" data-language="markup"><code class="language-markup">&lt;dependency&gt;    &lt;groupId&gt;com.github.ben-manes.caffeine&lt;&#x2F;groupId&gt;    &lt;artifactId&gt;caffeine&lt;&#x2F;artifactId&gt;    &lt;version&gt;3.1.1&lt;&#x2F;version&gt;&lt;&#x2F;dependency&gt;</code></pre><p>这样一来，对于业务使用者而言，可以方便的进行缓存具体实现者的替换。而作为缓存能力提供商而言，自己可以轻易的被同类产品替换掉，所以也鞭策自己去提供更好更强大的产品，巩固自己的地位，也由此促进整个生态的<strong>良性演进</strong>。</p><h3 id="Spring-Cache规范提供的注解"><a href="#Spring-Cache规范提供的注解" class="headerlink" title="Spring Cache规范提供的注解"></a>Spring Cache规范提供的注解</h3><p>需要注意的是，使用Spring Cache缓存前，需要先手动开启对于缓存能力的支持，可以通过<code>@EnableCaching</code>注解来完成。</p><p>除了*@EnableCaching*，在Spring Cache中还定义了一些其它的常用注解方法，梳理归纳如下：</p><table><thead><tr><th>注解</th><th>含义说明</th></tr></thead><tbody><tr><td>@EnableCaching</td><td>开启使用缓存能力</td></tr><tr><td>@Cacheable</td><td>添加相关内容到缓存中</td></tr><tr><td>@CachePut</td><td>更新相关缓存记录</td></tr><tr><td>@CacheEvict</td><td>删除指定的缓存记录，如果需要清空指定容器的全部缓存记录，可以指定<code>allEntities=true</code>来实现</td></tr></tbody></table><p>具体的使用上，其实和JSR107规范中提供的注解用法相似。</p><p>当然了，JAVA领域缓存事实规范地位虽已奠定，但是Spring Cache依旧是保持着一个兼收并蓄的姿态，并积极的兼容了JCache API相关规范，比如<code>Spring4.1</code>起项目中可以使用JSR107规范提供的相关注解方法来操作。</p><p><img src="https://pics.codingcoder.cn/pics/202210260726749.png"></p><h2 id="小结回顾"><a href="#小结回顾" class="headerlink" title="小结回顾"></a>小结回顾</h2><p>好啦，关于JAVA中的<strong>JSR107</strong>规范以及<strong>Spring Cache</strong>规范，以及各自典型代表，我们就聊到这里。</p><p>那么，关于本文中提及的缓存规范的内容，你是否有自己的一些想法与见解呢？欢迎评论区一起交流下，期待和各位小伙伴们一起切磋、共同成长。</p><p>📣 <strong>补充说明1</strong> ：</p><blockquote><p>本文属于《<a href="https://juejin.cn/column/7140852038258147358">深入理解缓存原理与实战设计</a>》系列专栏的内容之一。该专栏围绕缓存这个宏大命题进行展开阐述，全方位、系统性地深度剖析各种缓存实现策略与原理、以及缓存的各种用法、各种问题应对策略，并一起探讨下缓存设计的哲学。</p><p>如果有兴趣，也欢迎关注此专栏。</p></blockquote><p>📣 <strong>补充说明2</strong> ：</p><ul><li>关于本文中涉及的<strong>演示代码</strong>的完整示例，我已经整理并提交到github中，如果您有需要，可以自取：<a href="https://github.com/veezean/JavaBasicSkills">https://github.com/veezean/JavaBasicSkills</a></li></ul><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><p><strong>我是悟道，聊技术、又不仅仅聊技术~</strong></p><p>如果觉得有用，请<strong>点赞 + 关注</strong>让我感受到您的支持。也可以关注下我的公众号【架构悟道】，获取更及时的更新。</p><p>期待与你一起探讨，一起成长为更好的自己。</p><p><img src="https://pics.codingcoder.cn/pics/202207091312091.gif"></p><p><img src="https://pics.codingcoder.cn/pics/202207091317876.png"></p>]]></content>
      
      
      <categories>
          
          <category> 缓存原理与实战设计 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JAVA </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>手写本地缓存实战1——各个击破，按需应对实际使用场景</title>
      <link href="//post/20221107115817.html"/>
      <url>//post/20221107115817.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>本篇我们一起探讨下项目中本地缓存的各种使用场景与应对实现策略，也通过本篇介绍的几个本地缓存的实现策略与关键特性的支持，体会到本地缓存使用与构建的关注要点。</p></blockquote><p><img src="https://pics.codingcoder.cn/pics/202210050807355.png"></p><p>大家好，又见面了。</p><hr><blockquote><p>本文是笔者作为掘金技术社区签约作者的身份输出的缓存专栏系列内容，将会通过系列专题，讲清楚缓存的方方面面。如果感兴趣，欢迎关注以获取后续更新。</p></blockquote><hr><p>通过《<a href="https://juejin.cn/column/7140852038258147358">深入理解缓存原理与实战设计</a>》系列专栏的前两篇内容，我们介绍了缓存的<strong>整体架构</strong>、<strong>设计规范</strong>，也阐述了缓存的常见<strong>典型问题</strong>及其<strong>使用策略</strong>。作为该系列的第三篇文章，本篇我们将一起探讨下项目中本地缓存的各种使用场景与应对实现策略 —— 也通过本篇介绍的几个本地缓存的实现策略与关键特性的支持，体会到本地缓存使用与构建的关注要点，也作为我们下一篇文章要介绍的手写本地缓存通用框架的铺垫。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h2 id="本地缓存的递进史"><a href="#本地缓存的递进史" class="headerlink" title="本地缓存的递进史"></a>本地缓存的递进史</h2><p>从本质上来说，<code>缓存</code>其实就是一堆数据的<strong>集合</strong>（甚至有的时候，这个集合中只有<code>1个</code>元素，比如一些缓存计数器）。再直白点，它就是一个<strong>容器</strong>而已。在各个编程语言中，容器类的对象类型都有很多不同种类，这就需要开发人员根据业务场景不同的诉求，选择不同的缓存承载容器，并进行二次加工封装以契合自己的意愿。</p><p>下面我们就一起看下我们实现本地缓存的时候，可能会涉及到的一些常见的选型类型。</p><h3 id="小众诉求-——-最简化的集合缓存"><a href="#小众诉求-——-最简化的集合缓存" class="headerlink" title="小众诉求 —— 最简化的集合缓存"></a>小众诉求 —— 最简化的集合缓存</h3><p><code>List</code>或者<code>Array</code>算是比较简单的一种缓存承载形式，常用于一些<strong>黑白名单</strong>类数据的缓存，业务层面上用于判断某个值是否存在于集合中，然后作出对应的业务处理。</p><p><img src="https://pics.codingcoder.cn/pics/202210140656569.png"></p><p>比如有这么个场景：</p><blockquote><p>在一个论坛系统中，管理员会将一些违反规定的用户拉入黑名单中禁止其发帖，这些黑名单用户ID列表是存储在数据库中一个独立的表中。<br>当用户发帖的时候，后台需要判断此用户是否在被禁言的黑名单列表里。如果在，则禁止其发帖操作。</p></blockquote><p>因为黑名单ID的数量不会很多，为了避免每次用户发帖操作都查询一次DB，可以选择将黑名单<code>用户ID</code>加载到内存中进行缓存，然后每次发帖的时候判断下是否在黑名单中即可。实现时，可以简单的用List去承载：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public class UserBlackListCache &#123;    private List&lt;String&gt; blackList;    public boolean inBlackList(String userId) &#123;        return blackList.contains(userId);    &#125;    public void addIntoBlackList(String userId) &#123;        blackList.add(userId);    &#125;    public void removeFromBlackList(String userId) &#123;        blackList.remove(userId);    &#125;&#125;</code></pre><p>作为一个基于<code>List</code>实现的黑名单缓存，一共对外提供了三个<em>API</em>方法：</p><table><thead><tr><th>接口名称</th><th>功能说明</th></tr></thead><tbody><tr><td>inBlackList</td><td>判断某个用户是否在黑名单</td></tr><tr><td>addIntoBlackList</td><td>将某个用户添加到黑名单中</td></tr><tr><td>removeFromBlackList</td><td>将某个用户从黑名单中移除</td></tr></tbody></table><p>List或者Array形式，由于数据结构比较简单，无冗余数据，缓存存储的时候内存占用量相对会比较经济些。当然，受限于List和Array自身的数据结构特点，实现按条件查询操作的时候<strong>时间复杂度</strong>会比较高，所以使用场景相对有限。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h3 id="众生形态-——-常规键值对缓存"><a href="#众生形态-——-常规键值对缓存" class="headerlink" title="众生形态 —— 常规键值对缓存"></a>众生形态 —— 常规键值对缓存</h3><p>相比<code>List</code>这种线性集合容器而言，在实际项目中，更多的场景会选择使用一些<code>key-value</code>格式的映射集（比如<code>HashMap</code>）来作为容器 —— 这也是大部分缓存的最基础的数据结构形态。业务上可以将查询条件作为<em>key</em>值，然后将实际内容作为<em>value</em>值进行存储，可以实现高效的单条数据条件查询匹配。</p><p><img src="https://pics.codingcoder.cn/pics/202210140709866.png"></p><p>还是上述的发帖论坛系统的一个场景：</p><blockquote><p>用户登录论坛系统，查看帖子列表的时候，界面需调用后端提供的帖子列表查询请求。在帖子列表中，会显示每个帖子的发帖人信息。</p><p>由于帖子的发帖人只存储了个UID信息，而需要给到界面的是这个UID对应用户的简要信息，比如头像、昵称、注册年限等等，所以在帖子列表返回前，还需要根据UID查询到对应的用户信息，最后一并返回给前端。</p></blockquote><p>按照上述的要求，如果每次查询到帖子列表之后，再去DB中根据UID逐个去查询每个帖子对应的用户信息，势必会导致每个列表接口都需要调用很多次DB查询用户的操作。所以如果我们将用户的简要信息映射缓存起来，然后每次直接从缓存里面根据UID查询即可，这样可以大大简化每次查询操作与DB的交互次数。</p><p>使用<code>HashMap</code>来构建缓存，我们可以将UID作为<em>key</em>，而<code>UserInfo</code>作为<em>value</em>，代码如下：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public class UserCache &#123;    private Map&lt;String, UserInfo&gt; userCache &#x3D; new HashMap&lt;&gt;();    public void putUser(UserInfo user) &#123;        userCache.put(user.getUid(), user);    &#125;    public UserInfo getUser(String uid) &#123;        if (!userCache.containsKey(uid)) &#123;            throw new RuntimeException(&quot;user not found&quot;);        &#125;        return userCache.get(uid);    &#125;    public void removeUser(String uid) &#123;        userCache.remove(uid);    &#125;    public boolean hasUser(String uid) &#123;        return userCache.containsKey(uid);    &#125;&#125;</code></pre><p>为了满足业务场景需要，上述代码实现的缓存对外提供几个功能接口：</p><table><thead><tr><th>接口名称</th><th>功能说明</th></tr></thead><tbody><tr><td>putUser</td><td>将指定的用户信息存储到缓存中</td></tr><tr><td>getUser</td><td>根据UID获取对应的用户信息数据</td></tr><tr><td>removeUser</td><td>删除指定UID对应的用户缓存数据</td></tr><tr><td>hasUser</td><td>判断指定的用户是否存在</td></tr></tbody></table><p>使用<code>HashMap</code>构建缓存，可以轻松的实现<code>O(1)</code>复杂度的数据操作，执行性能可以得到有效保障。这也是为什么<code>HashMap</code>被广泛使用在缓存场景中的原因。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h2 id="容量约束-——-支持数据淘汰与容量限制的缓存"><a href="#容量约束-——-支持数据淘汰与容量限制的缓存" class="headerlink" title="容量约束 —— 支持数据淘汰与容量限制的缓存"></a>容量约束 —— 支持数据淘汰与容量限制的缓存</h2><p>通过类似<code>HashMap</code>的结构来缓存数据是一种简单的缓存实现策略，可以解决很多查询场景的实际诉求，但是在使用中，有些问题也会慢慢浮现。</p><blockquote><p>在线上问题定位过程中，经常会遇到一些内存溢出的问题，而这些问题的原因，很大一部分都是由于对容器类的使用不加约束导致的。</p></blockquote><p>所以很多情况下，出于可靠性或者业务自身诉求考量，会要求缓存的<code>HashMap</code>需要有<strong>最大容量限制</strong>，如支持<code>LRU策略</code>，保证最多仅缓存指定数量的数据。 </p><p>比如在上一节中，为了提升根据UID查询用户信息的效率，决定将用户信息缓存在内存中。但是这样一来：</p><ol><li><p>论坛的用户量是在一直增加的，这样就会导致加载到内存中的用户数据量也会越来越大，内存占用就会<code>无限制</code>增加，万一用户出现井喷式增长，很容易会把内存撑满，造成<strong>内存溢出</strong>问题；</p></li><li><p>论坛内的用户，其实有很多用户注册之后就是个僵尸号，或者是最近几年都没有再使用系统了，这些数据加载到内存中，业务几乎不会使用到，<strong>白白占用内存</strong>而已。</p></li></ol><p>这种情况，就会涉及到我们在前面文章中提到的一个缓存的基础特性了 —— <strong>缓存淘汰机制</strong>！也即支持<code>热点数据</code>存储而非全量数据存储。我们可以对上一节实现的缓存进行一个改造，使其支持限制缓存的最大容量条数，如果超过此条数，则基于<em>LRU策略</em>来淘汰最不常用的数据。</p><p>我们可以基于<code>LinkedHashMap</code>来实现。比如我们可以先实现一个支持<em>LRU</em>的缓存容器<code>LruHashMap</code>，代码示例如下：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public class LruHashMap&lt;K, V&gt; extends LinkedHashMap&lt;K, V&gt; &#123;    private static final long serialVersionUID &#x3D; 1287190405215174569L;    private int maxEntries;    public LruHashMap(int maxEntries, boolean accessOrder) &#123;        super(16, 0.75f, accessOrder);        this.maxEntries &#x3D; maxEntries;    &#125;        &#x2F;**     *  自定义数据淘汰触发条件，在每次put操作的时候会调用此方法来判断下     *&#x2F;    protected boolean removeEldestEntry(Map.Entry&lt;K, V&gt; eldest) &#123;        return size() &gt; maxEntries;    &#125;&#125;</code></pre><p>如上面实现的缓存容器，提供了一个构造方法，允许传入两个参数：</p><ul><li><p><strong>maxEntities</strong> ：此缓存容器允许存储的最大记录条数。</p></li><li><p><strong>accessOrder</strong> ：决定数据淘汰排序策略。传入<code>true</code>则表示基于<em>LRU策略</em>进行排序，<code>false</code>则表示基于数据<em>写入先后</em>进行排序。</p></li></ul><p>往缓存里面写入新数据的时候，会判断缓存容器中的数据量是否超过<code>maxEntities</code>，如果超过就会基于<code>accessOrder</code>所指定的排序规则进行数据排序，然后将排在最前面的元素给删除，挪出位置给新的待插入数据。</p><p>我们使用此改进后的缓存容器，改写下前面的缓存实现：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public class UserCache &#123;    private Map&lt;String, UserInfo&gt; userCache &#x3D; new LruHashMap&lt;&gt;(10000, true);    public void putUser(UserInfo user) &#123;        userCache.put(user.getUid(), user);    &#125;    public UserInfo getUser(String uid) &#123;        &#x2F;&#x2F; 因为是热点缓存，非全量，所以缓存中没有数据，则尝试去DB查询并加载到内存中（演示代码，忽略异常判断逻辑）        if (!userCache.containsKey(uid)) &#123;            UserInfo user &#x3D; queryFromDb(uid);            putUser(user);            return user;        &#125;        return userCache.get(uid);    &#125;&#125;</code></pre><p>相比于直接使用HashMap来构建的缓存，改造后的缓存增加了基于<em>LRU策略</em>进行数据淘汰的能力，可以限制缓存的最大记录数，既可以满足业务上对缓存数据有要求的场景使用，又可以规避因为调用方的原因导致的缓存无限增长然后导致内存溢出的风险，还可以减少无用冷数据对内存数据的占用浪费。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h2 id="线程并发场景"><a href="#线程并发场景" class="headerlink" title="线程并发场景"></a>线程并发场景</h2><p>为了减少内存浪费、以及防止内存溢出，我们上面基于<code>LinkedHashMap</code>定制打造了个支持<code>LRU策略</code>的限容缓存器，具备了更高级别的可靠性。但是作为缓存，很多时候是需要进程内整个系统全局共享共用的，势必会涉及到在<strong>并发场景</strong>下去调用缓存。</p><p>而前面我们实现的几种策略，都是非线程安全的，适合局部缓存或者单线程场景使用。多线程使用的时候，我们就需要对前面实现进行改造，使其变成线程安全的缓存容器。</p><p>对于简单的不需要淘汰策略的场景，我们可以使用<code>ConcurrentHashMap</code>来替代HashMap作为缓存的容器存储对象，以获取线程安全保障。</p><p>而对于我们基于LinkedHashMap实现的限容缓存容器，要使其支持线程安全，可以使用最简单粗暴的一种方式来实现 —— 基于<code>同步锁</code>。比如下面的实现，就是在原有的LruHashMap基础上嵌套了一层保护壳，实现了线程安全的访问：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public class ConcurrentLruHashMap&lt;K, V&gt; &#123;    private LruHashMap&lt;K, V&gt; lruHashMap;    public ConcurrentLruHashMap(int maxEntities) &#123;        lruHashMap &#x3D; new LruHashMap&lt;&gt;(maxEntities);    &#125;    public synchronized V get(Object key) &#123;        return lruHashMap.get(key);    &#125;    public synchronized void put(K key, V value) &#123;        lruHashMap.put(key, value);    &#125;    private static class LruHashMap&lt;K, V&gt; extends LinkedHashMap&lt;K, V&gt; &#123;        private int maxEntities;        public LruHashMap(int maxEntities) &#123;            super(16, 0.75f, true);            this.maxEntities &#x3D; maxEntities;        &#125;        @Override        protected boolean removeEldestEntry(Map.Entry&lt;K, V&gt; eldest) &#123;            return size() &gt; maxEntities;        &#125;    &#125;&#125;</code></pre><p>为了尽量降低锁对缓存操作性能的影响，我们也可以对同步锁的策略进行一些优化，比如可以基于<code>分段锁</code>来降低同步锁的粒度，减少锁的竞争，提升性能。</p><p>另外，<code>Google Guava</code>开源库中也有提供一个<code>ConcurrentLinkedHashMap</code>，同样支持LRU的策略，并且在保障线程安全方面的锁机制进行了优化，如果项目中有需要的话，也可以考虑直接引入对应的开源库进行使用。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h2 id="曲终人散-——-TTL缓存过期机制"><a href="#曲终人散-——-TTL缓存过期机制" class="headerlink" title="曲终人散 —— TTL缓存过期机制"></a>曲终人散 —— TTL缓存过期机制</h2><p>使用缓存的时候，经常会需要设置缓存记录对应的有效期，支持将过期的缓存数据删除。要实现此能力，需要确定两点处理策略：</p><ul><li><p>如何存储每条数据的过期时间</p></li><li><p>何种机制去删除已经过期的数据</p></li></ul><p>下面展开聊一聊。</p><p><img src="https://pics.codingcoder.cn/pics/202210140718064.png"></p><h3 id="过期时间存储与设定"><a href="#过期时间存储与设定" class="headerlink" title="过期时间存储与设定"></a>过期时间存储与设定</h3><p>既然要支持设定过期时间，也即需要将过期时间一并存储在每条记录里。对于常规的<code>key-value</code>类型的缓存架构，我们可以对<code>value</code>结构进行扩展，包裹一层公共的缓存对象外壳，用来存储一些缓存管理需要使用到的信息。比如下面这种实现：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">@Datapublic class CacheItem&lt;V&gt; &#123;    private V value;    private long expireAt;    &#x2F;&#x2F; 后续有其它扩展，在此补充。。。&#125;</code></pre><p>其中<code>value</code>用来存储真实的缓存数据，而其他的一些辅助参数则可以一并随value存储起来，比如用来记录过期时间的<code>expireAt</code>参数。</p><p>对于过期时间的设定，一般有两种时间表述形式：</p><ol><li><p>使用<strong>绝对时刻</strong>，比如指定2022-10-13 12:00:00过期</p></li><li><p>使用<strong>时间间隔</strong>，比如指定5分钟过期</p></li></ol><p>对于使用方而言，显然<code>第2种</code>形式设置起来更加方便、也更符合业务的实际使用场景。而对于缓存实现而言，显然使用<code>第1种</code>方式，管理每条数据是否过期的时候会更可行（如果用时间间隔，还需要额外存储时间间隔的计时起点，或者不停的去扣减剩余时长，比较麻烦）。作为应对之策，我们可以在缓存过期时间设置的时候进行一次转换，<em>将调用方设定的过期时间间隔，转换为实际存储的绝对时刻</em>，这样就可以满足两者的诉求。</p><p>结合上面的结论，我们可有写出如下代码：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public class DemoCache&lt;K, V&gt; &#123;    private Map&lt;K, CacheItem&lt;V&gt;&gt; cache &#x3D; new HashMap&lt;&gt;();    &#x2F;**     * 单独设置某个key对应过期时间     * @param key 唯一标识     * @param timeIntvl 过期时间     * @param timeUnit 时间单位     *&#x2F;    public void expireAfter(K key, int timeIntvl, TimeUnit timeUnit) &#123;        CacheItem&lt;V&gt; item &#x3D; cache.get(key);        if (item &#x3D;&#x3D; null) &#123;            return;        &#125;        long expireAt &#x3D; System.currentTimeMillis() + timeUnit.toMillis(timeIntvl);        item.setExpireAt(expireAt);    &#125;    &#x2F;**     * 写入指定过期时间的缓存信息     * @param key 唯一标识     * @param value 缓存实际值     * @param timeIntvl 过期时间     * @param timeUnit 时间单位     *&#x2F;    public void put(K key, V value, int timeIntvl, TimeUnit timeUnit) &#123;        long expireAt &#x3D; System.currentTimeMillis() + timeUnit.toMillis(timeIntvl);        CacheItem&lt;V&gt; item &#x3D; new CacheItem&lt;&gt;();        item.setValue(value);        item.setExpireAt(expireAt);        cache.put(key, item);    &#125;    &#x2F;&#x2F; 省略其他方法&#125;</code></pre><p>上面代码中，支持设定不同的时长单位，比如是<code>Second</code>、<code>Minute</code>、<code>Hour</code>、<code>Day</code>等，这样可以省去业务方自行换算时间长度的操作。并且，提供了一个2个途径设定超时时间：</p><ul><li><p>独立接口指定某个数据的过期时长</p></li><li><p>写入或者更新缓存的时候直接设置对应的过期时长</p></li></ul><p>而最终存储的时候，也是在缓存内部将调用方设定的超时时长信息，转换为了一个绝对时间戳值，这样后续的缓存过期判断与数据清理的时候就可以直接使用。</p><p>具体业务调用的时候，可以根据不同的场景，灵活的进行过期时间的设定。比如当我们登录的时候会生成一个token，我们可以将token信息缓存起来，使其保持一定时间内有效：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public void afterLogin(String token, User user) &#123;    &#x2F;&#x2F; ... 省略业务逻辑细节    &#x2F;&#x2F; 将新创建的帖子加入缓存中，缓存30分钟    cache.put(token, user, 30, TimeUnit.MINUTES);&#125;</code></pre><p>而对于一个已有的记录我们也可以单独去设置，这种经常使用于在<strong>缓存续期</strong>的场景中。比如上面说的登录成功后会将token信息缓存30分钟，而这个时候我们希望用户如果一直在操作的话，就不要使其token失效，否则使用到一半就要求用户重新登录，这种体验就会很差。我们可以这样：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public PostInfo afterAuth(String token) &#123;    &#x2F;&#x2F; 每次使用后，都重新设置过期时间为30分钟后（续期）    cache.expireAfter(token, 30, TimeUnit.MINUTES);&#125;</code></pre><p>这样一来，只要用户登录后并且一直在做操作，token就一直不会失效，直到用户连续30分钟未做任何操作的时候，token才会从缓存中被过期删除。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h3 id="过期数据删除机制"><a href="#过期数据删除机制" class="headerlink" title="过期数据删除机制"></a>过期数据删除机制</h3><p>上面一节中，我们已经确定了缓存过期时间的存储策略，也给定了调用方设定缓存时间的操作接口。这里还剩一个最关键的问题需要解决：对于设定了过期时间的数据，如何在其过期的时候使其不可用？下面给出<strong>三种</strong>处理的思路。</p><h4 id="定时清理"><a href="#定时清理" class="headerlink" title="定时清理"></a>定时清理</h4><p>这是最容易想到的一种实现，我们可以搞个<code>定时任务</code>，定时的扫描所有的记录，判断是否有过期，如果过期则将对应记录删除。因为涉及到多个线程对缓存的数据进行处理操作，出于并发安全性考虑，我们的缓存可以采用一些线程安全的容器（比如前面提过的<code>ConcurrentHashMap</code>）来实现，如下所示：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public class DemoCache&lt;K, V&gt; &#123;    private Map&lt;K, CacheItem&lt;V&gt;&gt; cache &#x3D; new ConcurrentHashMap&lt;&gt;();    public DemoCache() &#123;        timelyCleanExpiredItems();    &#125;    private void timelyCleanExpiredItems() &#123;        new Timer().schedule(new TimerTask() &#123;            @Override            public void run() &#123;                cache.entrySet().removeIf(entry -&gt; entry.getValue().hasExpired());            &#125;        &#125;, 1000L, 1000L * 10);    &#125;    &#x2F;&#x2F; 省略其它方法&#125;</code></pre><p>这样，我们就可以根据缓存的总体数据量以及缓存对数据过期时间的精度要求，来设定一个合理的定时执行策略，比如我们设定每隔<code>10s</code>执行一次过期数据清理任务。那么当一个任务过期之后，最坏情况可能会在过期10s后才会被删除（所以过期时间精度控制上会存在一定的误差范围）。</p><p><img src="https://pics.codingcoder.cn/pics/202210141037034.png"></p><p>此外，为了尽可能保证控制的精度，我们就需要将定时清理间隔尽可能的缩短，但是当缓存数据量较大时，频繁的全量扫描操作，也会对<em>系统性能</em>造成一定的影响。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h4 id="惰性删除"><a href="#惰性删除" class="headerlink" title="惰性删除"></a>惰性删除</h4><p>这是另一种数据过期的处理策略，与定时清理这种主动出击的激进型策略相反，<code>惰性删除</code>不会主动去判断缓存是否失效，而是在使用的时候进行判断。每次读取缓存的时候，先判断对应记录是否已经过期，如果过期则直接删除并且告知调用方没有此缓存数据。</p><p><img src="https://pics.codingcoder.cn/pics/202210141139219.png"></p><p>代码如下所示：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public class DemoCache&lt;K, V&gt; &#123;    private Map&lt;K, CacheItem&lt;V&gt;&gt; cache &#x3D; new HashMap&lt;&gt;();    &#x2F;**     * 从缓存中查询对应值     * @param key 缓存key     * @return 缓存值     *&#x2F;    public V get(K key) &#123;        CacheItem&lt;V&gt; item &#x3D; cache.get(key);        if (item &#x3D;&#x3D; null) &#123;            return null;        &#125;        &#x2F;&#x2F; 如果已过期，则删除，并返回null        if (item.hasExpired()) &#123;            cache.remove(key);            return null;        &#125;        return item.getValue();    &#125;    &#x2F;&#x2F; 省略其它方法&#125;</code></pre><p>相比于定时清理机制，基于惰性删除的策略，在代码实现上无需额外的独立清理服务，且可以保证数据一旦过期后立刻就不可用。但是惰性删除也存在一个很大的问题，这种依靠外部调用来触发自身数据清理的机制<em>不可控因素太多</em>，如果一个记录已经过期但是没有请求来查询它，那这条已过期的记录就会一直驻留在缓存中，造成内存的浪费。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h4 id="两者结合"><a href="#两者结合" class="headerlink" title="两者结合"></a>两者结合</h4><p>如前所述，不管是主动出击的定时清理策略，还是躺平应付的惰性删除，都不是一个完美的解决方案：</p><ul><li><p>定时清理可以保证内存中过期数据都被删除，但是<em>频繁执行易造成性能影响</em>、且过期时间存在精度问题</p></li><li><p>惰性删除可以保证过期时间控制精准，且可以解决性能问题，但是<em>易造成内存中残留过期数据</em>无法删除的问题</p></li></ul><p>但是上述两种方案的优缺点恰好又是可以相互弥补的，所以我们可以将其结合起来使用，取长补短。</p><p><img src="https://pics.codingcoder.cn/pics/202210141141720.png"></p><p>看下面的实现：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public class DemoCache&lt;K, V&gt; &#123;    private Map&lt;K, CacheItem&lt;V&gt;&gt; cache &#x3D; new ConcurrentHashMap&lt;&gt;();    public DemoCache() &#123;        timelyCleanExpiredItems();    &#125;    private void timelyCleanExpiredItems() &#123;        new Timer().schedule(new TimerTask() &#123;            @Override            public void run() &#123;                cache.entrySet().removeIf(entry -&gt; entry.getValue().hasExpired());            &#125;        &#125;, 1000L, 1000L * 60 * 60 *24);    &#125;    public V get(K key) &#123;        CacheItem&lt;V&gt; item &#x3D; cache.get(key);        if (item &#x3D;&#x3D; null) &#123;            return null;        &#125;        &#x2F;&#x2F; 如果已过期，则删除，并返回null        if (item.hasExpired()) &#123;            cache.remove(key);            return null;        &#125;        return item.getValue();    &#125;&#125;</code></pre><p>上面的实现中：</p><p>1.使用<code>惰性删除</code>策略，每次使用的时候判断是否过期并执行删除策略，保证过期数据不会被继续使用。</p><ol start="2"><li>配合一个<code>低频定时任务</code>作为兜底（比如24小时执行一次），用于清理已过期但是始终未被访问到的缓存数据，保证已过期数据不会长久残留内存中。由于执行频率较低，也不会对性能造成太大影响。</li></ol><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h2 id="小结回顾"><a href="#小结回顾" class="headerlink" title="小结回顾"></a>小结回顾</h2><p>回顾下本篇的内容，作为手写本地缓存框架的前菜，我们先介绍了一些项目中本地缓存实现的几种情况，一起一些诸如<code>淘汰策略</code>、<code>过期失效</code>等能力的开发初体验。</p><p><img src="https://pics.codingcoder.cn/pics/202210131713721.png"></p><p>这些内容在项目开发中出现的频率极高，几乎在任何有点规模的项目中都会或多或少使用到。我们将其称之为手写本地缓存的“<strong>前菜</strong>”，是因为这些都是一些零散的独立场景应对策略，就像一个个<em>游击队</em>，分散出击，各自撑起自己的一小块根据地。在本篇内容的基础上，我们下一篇文章将会一起聊一聊如何在游击队经验的基础上，打造一支正规军 —— 构建一个通用化、系统化的完整本地缓存框架。</p><p>那么，关于本篇前面提到的各种“游击队”式的本地缓存，你在编码中是否有涉及过呢？你是如何实现的呢？欢迎评论区一起交流下，期待和各位小伙伴们一起切磋、共同成长。</p><p>📣 <strong>补充说明</strong> ：</p><blockquote><p>本文属于《<a href="https://juejin.cn/column/7140852038258147358">深入理解缓存原理与实战设计</a>》系列专栏的内容之一。该专栏围绕缓存这个宏大命题进行展开阐述，全方位、系统性地深度剖析各种缓存实现策略与原理、以及缓存的各种用法、各种问题应对策略，并一起探讨下缓存设计的哲学。</p><p>如果有兴趣，也欢迎关注此专栏。</p></blockquote><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><p><strong>我是悟道，聊技术、又不仅仅聊技术~</strong></p><p>如果觉得有用，请<strong>点赞 + 关注</strong>让我感受到您的支持。也可以关注下我的公众号【架构悟道】，获取更及时的更新。</p><p>期待与你一起探讨，一起成长为更好的自己。</p><p><img src="https://pics.codingcoder.cn/pics/202207091312091.gif"></p><p><img src="https://pics.codingcoder.cn/pics/202207091317876.png"></p>]]></content>
      
      
      <categories>
          
          <category> 缓存原理与实战设计 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JAVA </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>手写本地缓存实战2—— 打造正规军，构建通用本地缓存框架</title>
      <link href="//post/20221107085417.html"/>
      <url>//post/20221107085417.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>作为缓存系列专栏的第四篇文章，我们将在上一篇的基础之上进行升华，一起思考如何构建一个完整且通用的本地缓存框架，并在过程中体会缓存实现的关键点与架构设计的思路。</p></blockquote><p><img src="https://pics.codingcoder.cn/pics/202210050807355.png"></p><p>大家好，又见面了。</p><hr><blockquote><p>本文是笔者作为掘金技术社区签约作者的身份输出的缓存专栏系列内容，将会通过系列专题，讲清楚缓存的方方面面。如果感兴趣，欢迎关注以获取后续更新。</p></blockquote><hr><p>村上春树有本著名的小说名叫《当我谈跑步时我谈些什么》，讲述了一个人怎么样通过跑步去悟道出人生的很多哲理与感悟。而读书的价值，就是让我们可以将别人参悟出的道理化为己用，将别人走过的路化为充实自己的养料。</p><p>在上一篇文章《<a href="https://juejin.cn/post/7154212378316374030">手写本地缓存实战1——各个击破，按需应对实际使用场景</a>》中，我们领略了实际项目中一些零散的缓存场景的实现方式，并对缓存实现中的<code>LRU淘汰策略</code>、<code>TTL过期清理</code>机制实现方案进行了探讨。作为《<a href="https://juejin.cn/column/7140852038258147358">深入理解缓存原理与实战设计</a>》系列专栏的第四篇文章，我们将在上一篇的基础之上进行升华，一起思考如何构建一个<strong>完整且通用</strong>的本地缓存框架，并在过程中体会缓存实现的关键点与架构设计的思路。</p><p>有的小伙伴可能会有疑问，现在有很多成熟的开源库，比如JAVA项目<code>的Guava cache</code>、<code>Caffeine Cache</code>、<code>Spring Cache</code>等（这些在我们的系列文章中，后面都会逐个介绍），它们都提供了相对完善、开箱即用的本地缓存能力，为什么这里还要去自己手写本地缓存呢？这不是重复造轮子吗？</p><p>是也？非也！在编码的进阶之路上，“会用”永远都只是让自己停留在入门级别。正所谓知其然更要知其所以然，通过一起探讨手写缓存的实现与设计关键点，来切身的体会蕴藏在缓存架构中的设计哲学。只有真正的掌握其原理，才能在使用中更好的去发挥其最大价值。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h2 id="缓存框架定调"><a href="#缓存框架定调" class="headerlink" title="缓存框架定调"></a>缓存框架定调</h2><p>在一个项目系统中需要缓存数据的场景会非常多，而且需要缓存的数据类型也不尽相同。如果每个使用到缓存的地方，我们都单独的去实现一套缓存，那开发小伙伴们的工作量又要上升了，且后续各业务逻辑独立的缓存部分代码的维护也是一个可预见的头疼问题。</p><p>作为应对之法，我们的本地缓存必须往一个<strong>更高层级</strong>进行演进，使得项目中不同的缓存场景都可以通用 —— 也即将其抽象封装为一个通用的<code>本地缓存框架</code>。既然定位为业务通用的本地缓存框架，那至少从规范或者能力层面，具备一些框架该有的样子：</p><ul><li><p><strong>泛型化设计</strong>，不同业务维度可以通用</p></li><li><p><strong>标准化接口</strong>，满足大部分场景的使用诉求</p></li><li><p><strong>轻量级集成</strong>，对业务逻辑不要有太强侵入性</p></li><li><p><strong>多策略可选</strong>，允许选择不同实现策略甚至是缓存存储机制，打破众口难调的困局</p></li></ul><p>下面，我们以上述几个点要求作为出发点，一起来勾勒一个符合上述诉求的本地缓存框架的模样。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h2 id="缓存框架实现"><a href="#缓存框架实现" class="headerlink" title="缓存框架实现"></a>缓存框架实现</h2><h3 id="缓存容器接口设计"><a href="#缓存容器接口设计" class="headerlink" title="缓存容器接口设计"></a>缓存容器接口设计</h3><p>在前一篇文章中，我们有介绍过项目中常见的缓存使用场景。基于提及的几种具体应用场景，我们可以归纳出业务对本地缓存的<em>API接口</em>层的一些共性诉求。如下表所示：</p><table><thead><tr><th>接口名称</th><th>含义说明</th></tr></thead><tbody><tr><td>get</td><td>根据key查询对应的值</td></tr><tr><td>put</td><td>将对应的记录添加到缓存中</td></tr><tr><td>remove</td><td>将指定的缓存记录删除</td></tr><tr><td>containsKey</td><td>判断缓存中是否有指定的值</td></tr><tr><td>clear</td><td>清空缓存</td></tr><tr><td>getAll</td><td>传入多个key，然后批量查询各个key对应的值，批量返回，提升调用方的使用效率</td></tr><tr><td>putAll</td><td>一次性批量将多个键值对添加到缓存中，提升调用方的使用效率</td></tr><tr><td>putIfAbsent</td><td>如果不存在的情况下则添加到缓存中，如果存在则不做操作</td></tr><tr><td>putIfPresent</td><td>如果key已存在的情况下则去更新key对应的值，如果不存在则不做操作</td></tr></tbody></table><p>为了满足一些场景对数据过期的支持，还需要提供或者重载一些接口用于设定<em>过期时间</em>：</p><table><thead><tr><th>接口名称</th><th>含义说明</th></tr></thead><tbody><tr><td>expireAfter</td><td>用于指定某个记录的过期时间长度</td></tr><tr><td>put</td><td>重载方法，增加过期时间的参数设定</td></tr><tr><td>putAll</td><td>重载方法，增加过期时间的参数设定</td></tr></tbody></table><p>基于上述提供的各个API方法，我们可以确定缓存的具体接口类定义：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">&#x2F;** * 缓存容器接口 * * @author 架构悟道 * @since 2022&#x2F;10&#x2F;15 *&#x2F;public interface ICache&lt;K, V&gt; &#123;    V get(K key);    void put(K key, V value);    void put(K key, V value, int timeIntvl, TimeUnit timeUnit);    V remove(K key);    boolean containsKey(K key);    void clear();    boolean containsValue(V value);    Map&lt;K, V&gt; getAll(Set&lt;K&gt; keys);    void putAll(Map&lt;K, V&gt; map);    void putAll(Map&lt;K, V&gt; map, int timeIntvl, TimeUnit timeUnit);    boolean putIfAbsent(K key, V value);    boolean putIfPresent(K key, V value);    void expireAfter(K key, int timeIntvl, TimeUnit timeUnit);&#125;</code></pre><p>此外，为了方便框架层面对缓存数据的管理与维护，我们也可以定义一套统一的<em>管理API</em>接口：</p><table><thead><tr><th>接口名称</th><th>含义说明</th></tr></thead><tbody><tr><td>removeIfExpired</td><td>如果给定的key过期则直接删除</td></tr><tr><td>clearAllExpiredCaches</td><td>清除当前容器中已经过期的所有缓存记录</td></tr></tbody></table><p>同样地，我们可以基于上述接口说明，敲定接口定义如下：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public interface ICacheClear&lt;K&gt; &#123;    void removeIfExpired(K key);    void clearAllExpiredCaches();&#125;</code></pre><p>至此，我们已完成了缓存的操作与管理维护接口的定义，下面我们看下如何对缓存进行维护管理。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h3 id="缓存管理能力构建"><a href="#缓存管理能力构建" class="headerlink" title="缓存管理能力构建"></a>缓存管理能力构建</h3><p>在一个项目中，我们会涉及到多种不同业务维度的数据缓存，而不同业务缓存对应的数据存管要求也各不相同。</p><p>比如对于一个公司行政管理系统而言，其涉及到如下数据的缓存：</p><ul><li>部门信息</li></ul><p>部门信息量比较少，且部门组织架构相对固定，所以需要<em>全量存储</em>，数据<strong>不允许过期</strong>。</p><ul><li>员工信息</li></ul><p>员工信息总体体量也不大，但是员工信息可能会变更，如员工可能会修改签名、头像或者更换部门等。这些操作对实时性的要求并不高，所以需要设置每条记录缓存30分钟，<em>超时</em>则从缓存中删除，后续使用到之后重新查询DB并写入缓存中。</p><p>从上面的示例场景中，可以提炼出缓存框架需要关注到的两个管理能力诉求：</p><ol><li><p>需要支持<strong>托管多个缓存容器</strong>，分别存储不同的数据，比如部门信息和员工信息，需要存储在两个独立的缓存容器中，需要支持获取各自独立的缓存容器进行操作。</p></li><li><p>需要支持选择多种<strong>不同能力</strong>的缓存容器，比如常规的容器、支持数据过期的缓存容器等。</p></li><li><p>需要能够支持对缓存容器的管理，以及缓存基础维护能力的支持，比如<strong>销毁</strong>缓存容器、比如<strong>清理</strong>容器内的过期数据。</p></li></ol><p>基于上述诉求，我们敲定管理接口类如下：</p><table><thead><tr><th>接口名称</th><th>含义说明</th></tr></thead><tbody><tr><td>createCache</td><td>创建一个新的缓存容器</td></tr><tr><td>getCache</td><td>获取指定的缓存容器</td></tr><tr><td>destoryCache</td><td>销毁指定的缓存容器</td></tr><tr><td>destoryAllCache</td><td>销毁所有的缓存容器</td></tr><tr><td>getAllCacheNames</td><td>获取所有的缓存容器名称</td></tr></tbody></table><p>对应地，可以完成接口类的定义：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public interface ICacheManager &#123;    &lt;K, V&gt; ICache&lt;K, V&gt; getCache(String key, Class&lt;K&gt; keyType, Class&lt;V&gt; valueType);    void createCache(String key, CacheType cacheType);    void destoryCache(String key);    void destoryAllCache();    Set&lt;String&gt; getAllCacheNames();&#125;</code></pre><p>在上一节关于缓存容器的接口划定描述中，我们敲定了两大类的接口，一类是提供<strong>给业务调用</strong>的，另一类是<strong>给框架管理使用</strong>的。为了简化实现，我们的缓存容器可以同时实现这两类接口，对应UML图如下：</p><p><img src="https://pics.codingcoder.cn/pics/202210161053511.png"></p><p>为了能让业务自行选择使用的容器类型，可以通过专门的<strong>容器工厂</strong>来创建，根据传入的缓存容器类型，创建对应的缓存容器实例：</p><p><img src="https://pics.codingcoder.cn/pics/202210161054909.png"></p><p>这样，在<code>CacheManager</code>管理层面，我们可以很轻松的完成创建缓存容器或者获取缓存容器的接口实现：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">@Overridepublic void createCache(String key, CacheType cacheType) &#123;    ICache cache &#x3D; CacheFactory.createCache(cacheType);    caches.put(key, cache);&#125;@Overridepublic &lt;K, V&gt; ICache&lt;K, V&gt; getCache(String cacheCollectionKey, Class&lt;K&gt; keyType, Class&lt;V&gt;valueType) &#123;    try &#123;        return (ICache&lt;K, V&gt;) caches.get(cacheCollectionKey);    &#125; catch (Exception e) &#123;        throw new RuntimeException(&quot;failed to get cache&quot;, e);    &#125;&#125;</code></pre><h3 id="过期清理"><a href="#过期清理" class="headerlink" title="过期清理"></a>过期清理</h3><p>作为缓存，经常会需要设定一个缓存有效期，这个有效期可以基于<code>Entry</code>维度进行实现，并且需要支持到期后自动删除此条数据。在前一篇文章《<a href="https://juejin.cn/post/7154212378316374030">本地缓存实现的时候需要考虑什么——按需应对实际使用场景</a>》中我们有详细探讨过几种不同的过期数据清理机制，这里我们直接套用结论，采用<strong>惰性删除与定期清理</strong>结合的策略来实现。</p><p><img src="https://pics.codingcoder.cn/pics/202210141141720.png"></p><p>我们对实际缓存数据值套个外壳，用于存储一些管理类的属性，比如过期时间等。然后我们的容器类实现<code>ICacheClear</code>接口，并在对外提供的业务操作接口中进行惰性删除的实现逻辑。</p><p>比如对于默认的缓存容器而言，其<code>ICacheClear</code>的实现逻辑可能如下：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">@Overridepublic synchronized void removeIfExpired(K key) &#123;    Optional.ofNullable(data.get(key)).map(CacheItem::hasExpired).ifPresent(expired -&gt; &#123;        if (expired) &#123;            data.remove(key);        &#125;    &#125;);&#125;@Overridepublic synchronized void clearAllExpiredCaches() &#123;    List&lt;K&gt; expiredKeys &#x3D; data.entrySet().stream()            .filter(cacheItemEntry -&gt; cacheItemEntry.getValue().hasExpired())            .map(Map.Entry::getKey)            .collect(Collectors.toList());    for (K key : expiredKeys) &#123;        data.remove(key);    &#125;&#125;</code></pre><p>这样呢，按照<strong>惰性删除</strong>的策略，在各个业务接口中，需要先调用<code>removeIfExpired</code>方法移除已过期的数据：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">@Overridepublic Optional&lt;V&gt; get(K key) &#123;    removeIfExpired(key);    return Optional.ofNullable(data.get(key)).map(CacheItem::getValue);&#125;</code></pre><p>而在框架管理层面，作为兜底，需要提供<strong>定时机制</strong>，来清理各个容器中的过期数据：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public class CacheManager implements ICacheManager &#123;    private Map&lt;String, ICache&gt; caches &#x3D; new ConcurrentHashMap&lt;&gt;();    private List&lt;ICacheHandler&gt; handlers &#x3D; Collections.synchronizedList(new ArrayList&lt;&gt;());    public CacheManager() &#123;        new Timer().schedule(new TimerTask() &#123;            @Override            public void run() &#123;                System.out.println(&quot;start clean expired data timely&quot;);                handlers.forEach(ICacheHandler::clearAllExpiredCaches);            &#125;        &#125;, 60000L, 1000L * 60 * 60 * 24);    &#125;    &#x2F;&#x2F; 省略其它方法&#125;</code></pre><p>这样呢，对缓存的数据过期能力的支撑便完成了。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h3 id="构建不同能力的缓存容器"><a href="#构建不同能力的缓存容器" class="headerlink" title="构建不同能力的缓存容器"></a>构建不同能力的缓存容器</h3><p>作为缓存框架，势必需要面临不同的业务各不相同的诉求。在框架搭建层面，我们整体框架的设计实现遵循着<code>里式替换</code>的原则，且借助<code>泛型</code>进行构建。这样，我们就可以实现给定的接口类，提供不同的缓存容器来满足业务的场景需要。</p><p>比如我们需要提供两种类型的容器：</p><ul><li><p>普通的键值对容器</p></li><li><p>支持设定最大容量且使用LRU策略淘汰的键值对容器</p></li></ul><p>可以直接创建两个不同的容器类，然后分别实现接口方法即可。对应UML示意如下：</p><p><img src="https://pics.codingcoder.cn/pics/202210161122487.png"></p><p>最后，需要将我们创建的不同的容器类型在<code>CacheType</code>中注册下，这样调用方便可以通过指定不同的<code>CacheType</code>来选择使用不同的缓存容器。</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">@AllArgsConstructor@Getterpublic enum CacheType &#123;    DEFAULT(DefaultCache.class),    LRU(LruCache.class);    private Class&lt;? extends ICache&gt; classType;&#125;</code></pre><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h2 id="缓存框架使用初体验"><a href="#缓存框架使用初体验" class="headerlink" title="缓存框架使用初体验"></a>缓存框架使用初体验</h2><p>至此呢，我们的本地缓存框架就算是搭建完成了。在业务中有需要使用缓存的场景直接使用<code>CacheManager</code>中的<code>createCache</code>方法创建出对应缓存容器，然后调用缓存容器的接口进行缓存的操作即可。</p><p>我们来调用一下，看看使用体验与功能如何。比如我们现在需要为用户信息创建一个独立的缓存，然后往里面写入一个用户记录并设定<code>1s</code>后过期：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public static void main(String[] args) &#123;    manager.createCache(&quot;userData&quot;, CacheType.LRU);    ICache&lt;String, User&gt; userDataCache &#x3D; manager.getCache(&quot;userData&quot;, String.class, User.class);    userDataCache.put(&quot;user1&quot;, new User(&quot;user1&quot;));    userDataCache.expireAfter(&quot;user1&quot;, 1, TimeUnit.SECONDS);    userDataCache.get(&quot;user1&quot;).ifPresent(value -&gt; System.out.println(&quot;找到用户：&quot; + value));    try &#123;        Thread.sleep(2000L);    &#125; catch (Exception e) &#123;    &#125;    boolean present &#x3D; userDataCache.get(&quot;user1&quot;).isPresent();    if (!present) &#123;        System.out.println(&quot;用户不存在&quot;);    &#125;&#125;</code></pre><p>执行之后，输出结果为:</p><pre class="line-numbers language-none"><code class="language-none">找到用户：User(userName&#x3D;user1)用户不存在</code></pre><p>可以发现，完全符合我们的预期，且过期数据清理机也已生效。同样地，如果需要为其它数据创建独立的缓存存储，也参考上面的逻辑，创建自己独立的缓存容器即可。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h2 id="扩展探讨"><a href="#扩展探讨" class="headerlink" title="扩展探讨"></a>扩展探讨</h2><h3 id="分布式场景下本地缓存漂移现象应对策略"><a href="#分布式场景下本地缓存漂移现象应对策略" class="headerlink" title="分布式场景下本地缓存漂移现象应对策略"></a>分布式场景下本地缓存漂移现象应对策略</h3><p>在本系列的开篇文章《<a href="https://juejin.cn/post/7151937376578142216">聊一聊作为高并发系统基石之一的缓存，会用很简单，用好才是技术活</a>》中，我们有提到过一个本地缓存在分布式场景下存在的一个缓存漂移问题：</p><p><img src="https://pics.codingcoder.cn/pics/202210010815833.png"></p><p>解决缓存漂移问题，一个简单的方案就是借助集中式缓存来解决（比如<code>Redis</code>）。但是在一些简单的小型分布式节点中，不太值得引入太多额外公共组件服务的时候，也可以考虑对本地缓存进行增强，提供一些同步更新各节点缓存的机制。</p><p>下面介绍两个两个实现思路。</p><ul><li>组网广播</li></ul><p>在一些小型组网中，当某一个节点执行缓存更新操作的时候，都同时广播一个事件通知给其余节点，各个节点都进行节点自身缓存数据的更新。</p><p><img src="https://pics.codingcoder.cn/pics/202210122207674.png"></p><ul><li>定时轮询式</li></ul><p>一般的系统中，都会有个数据库节点（比如<code>MySQL</code>），我们可以借助数据库作为一个中间辅助，每次更新之后，都将缓存的更新信息写入一个独立的表中，然后各个缓存节点都定时从DB中拉取增量更新的记录，然后更新到本地缓存中。</p><p><img src="https://pics.codingcoder.cn/pics/202210122156938.png"></p><p>值得注意的是，上面这些思路仅适用于写操作不是很频繁、并且对实时一致性要求不是特别严苛的场景 —— 当然，在实际项目中，真正这么搞的情况比较少。因为本地缓存设计存在的初衷就是用来应对单进程内的缓存独立缓存使用，而这种涉及到多节点之间缓存数据一致保证的场景，本就不是本地缓存的擅长领域。所以在分布式场景下，往往都会直接选择使用集中式缓存。</p><p>当然啦，上面我们提到的两种本地缓存同步的机制，都是相对简单的一种实现。一些比较主流的本地缓存框架，也有提供一些集群化数据同步的机制，比如<code>Ehcache</code>就提供了高达<strong>5种</strong>不同的集群化策略，以达到各个本地缓存节点数据保持一致的效果：</p><ul><li><p><code>RMI</code>组播方式</p></li><li><p><code>JMS</code>消息方式</p></li><li><p><code>Cache Server</code>模式</p></li><li><p><code>JGroup</code>方式</p></li><li><p><code>Terracotta</code>方式</p></li></ul><p>后续文章中我们会一起探讨下Ehcache的相关内容，这里先卖个关子，到时候我们细聊。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h2 id="小结回顾"><a href="#小结回顾" class="headerlink" title="小结回顾"></a>小结回顾</h2><p>好啦，关于手写本地通用缓存框架的内容，我们就聊这么多。通过本篇内容，我们完成了对前面文章中提过的一些缓存设计理论原则的实践，并一步步的阐述了缓存的设计与实现关键点，更展示了如何让一个缓存模块从简单的能用变为好用、通用。</p><p>当然，本篇内容主要是为了通过手写缓存的模式，来让大家更切身的体会缓存实现中的关键点与架构设计思路，并能在后续的使用中更正确的去使用。在实际项目中，除非一些特殊定制诉求需要手动实现缓存机制外，我们倒也不必自己费时劳神地去手写缓存框架，直接采用现有的开源方案即可。比如JAVA类的项目，目前有很多开源库（比如<code>Guava cache</code>、<code>Caffeine Cache</code>、<code>Spring Cache</code>等）都提供了相对完善、开箱即用的本地缓存能力，可以直接使用，在后面的系列文章中，我们将逐个剖析。</p><p>那么，关于缓存模块的设计与实现，你是否也曾手动编写过呢？你是如何解决这些问题的呢？你关于这些问题你是否有更好的理解与应对策略呢？欢迎评论区一起交流下，期待和各位小伙伴们一起切磋、共同成长。</p><p>📣 <strong>补充说明1</strong> ：</p><blockquote><p>本文属于《<a href="https://juejin.cn/column/7140852038258147358">深入理解缓存原理与实战设计</a>》系列专栏的内容之一。该专栏围绕缓存这个宏大命题进行展开阐述，全方位、系统性地深度剖析各种缓存实现策略与原理、以及缓存的各种用法、各种问题应对策略，并一起探讨下缓存设计的哲学。</p><p>如果有兴趣，也欢迎关注此专栏。</p></blockquote><p>📣 <strong>补充说明2</strong> ：</p><ul><li>关于本文中涉及的<strong>演示代码</strong>的完整示例，我已经整理并提交到github中，如果您有需要，可以自取：<a href="https://github.com/veezean/JavaBasicSkills">https://github.com/veezean/JavaBasicSkills</a></li></ul><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><p><strong>我是悟道，聊技术、又不仅仅聊技术~</strong></p><p>如果觉得有用，请<strong>点赞 + 关注</strong>让我感受到您的支持。也可以关注下我的公众号【架构悟道】，获取更及时的更新。</p><p>期待与你一起探讨，一起成长为更好的自己。</p><p><img src="https://pics.codingcoder.cn/pics/202207091312091.gif"></p><p><img src="https://pics.codingcoder.cn/pics/202207091317876.png"></p>]]></content>
      
      
      <categories>
          
          <category> 缓存原理与实战设计 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JAVA </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>聊一聊安全且正确使用缓存的那些事 —— 关于缓存可靠性、关乎数据一致性</title>
      <link href="//post/20221102081617.html"/>
      <url>//post/20221102081617.html</url>
      
        <content type="html"><![CDATA[<blockquote><p>在分布式系统盛行的今天，缓存充当着扛压屏障的作用，一旦缓存出现问题，对系统影响也是致命的。本文我们一起聊聊如何安全且可靠的使用缓存，聊聊缓存击穿、缓存雪崩、缓存穿透以及数据一致性、热点数据淘汰机制等。</p></blockquote><hr><p><img src="https://pics.codingcoder.cn/pics/202210050807355.png"></p><p>大家好，又见面了。</p><hr><blockquote><p>本文是笔者作为掘金技术社区签约作者的身份输出的缓存专栏系列内容，将会通过系列专题，讲清楚缓存的方方面面。如果感兴趣，欢迎关注以获取后续更新。</p></blockquote><hr><p>在上一篇文档《<a href="https://juejin.cn/post/7151937376578142216">聊一聊作为高并发系统基石之一的缓存，会用很简单，用好才是技术活</a>》中，我们对缓存的庞大体系进行了个初步的探讨，浮光掠影般的介绍了<code>本地缓存</code>、<code>集中缓存</code>、<code>多级缓存</code>的不同形式，也走马观花似的初识了缓存设计的<code>关键原则</code>与需要关注的<code>典型问题</code>。</p><p>作为《<a href="https://juejin.cn/column/7140852038258147358">深入理解缓存原理与实战设计</a>》系列专栏的第二篇内容，从本篇开始，我们将聚焦缓存体系中的具体场景，分别进行深入的阐述与探讨。本篇我们就一起具体地聊一聊缓存使用中需要关注的<strong>典型问题</strong>与<strong>可靠性防护</strong>措施。</p><p>在分布式系统盛行的今天，尤其是在一些用户体量比较大的互联网业务系统里面，<strong>缓存充当着扛压屏障的作用</strong>。当前各互联网系统可以扛住动辄数万甚至数十万的并发请求量，缓存机制功不可没。而一旦缓存出现问题，对系统的影响往往也是致命的。所以在缓存的使用时必须要考虑完备的<strong>兜底与灾难应对</strong>策略。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h2 id="热点数据与淘汰策略"><a href="#热点数据与淘汰策略" class="headerlink" title="热点数据与淘汰策略"></a>热点数据与淘汰策略</h2><p>大部分服务端使用的抗压型缓存，为了保证缓存执行速度，普遍都是将数据存储在<strong>内存</strong>中。而受限于硬件与成本约束，内存的容量不太可能像磁盘一样近乎无限的去随意扩容使用。对于实际数据量极其庞大且无法将其全部存储于缓存中的时候，我们需要保证存储在缓存中的有限部分数据要尽可能的命中更多的请求，即要求缓存中存储的都是<strong>热点数据</strong>。</p><p>说到这里，就会存在一个不得不面对的问题：当数据量超级大而缓存的内存容量有限的情况下，<strong>如果容量满了该怎么办</strong>？</p><p>断舍离！</p><p>缓存实现的时候，必须要有一种机制，能够保证内存中的数据不会无限制增加 —— 也即<code>数据淘汰机制</code>。<strong>数据淘汰机制，是一个成熟的缓存体系所必备的基础能力</strong>。这里有个概念需要厘清，即<code>数据淘汰</code>策略与<code>数据过期</code>是两个不同的概念。</p><ul><li><p><strong>数据过期</strong>，是缓存系统的一个正常逻辑，是符合业务预期的一种数据删除机制。即设定了有效期的缓存数据，过期之后从缓存中移除。</p></li><li><p><strong>数据淘汰</strong>，是缓存系统的一种“<em>有损自保</em>”的<code>降级策略</code>，是业务预期之外的一种数据删除手段。指的是所存储的数据没达到过期时间，但缓存空间满了，对于新的数据想要加入缓存中时，缓存模块需要执行的一种应对策略。</p></li></ul><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><p>我们把缓存当做一个容器，试想一下，一个容器已满的情况下，继续往里面放东西，可以有什么应对之法？无外乎两种：</p><ol><li><p>直接拒绝，因为满了，放不下了。</p></li><li><p>从容器里面扔掉一些已有内容，然后腾挪出部分空间出来，将新的东西放进来。</p></li></ol><p><img src="https://pics.codingcoder.cn/pics/202210051001463.png"></p><p>进一步地，当决定采用先从容器中扔掉一些已有内容的时候，又会面临一个新的抉择，应该扔掉哪些内容？实践中常用的也有几种方案：</p><ol><li><p><strong>一切随缘，随机决定</strong>。从容器中现有的内容中<code>随机</code>扔掉剔除一些。</p></li><li><p><strong>按需排序，保留常用</strong>。即基于<code>LRU</code>策略，将最久没有被使用过的数据给剔除掉。</p></li><li><p><strong>提前过期，淘汰出局</strong>。对于一些设置了过期时间的记录，将其按照过期时间点进行排序，将最近即将过期的数据剔除（类似让其<code>提前过期</code>）。</p></li><li><p><strong>其它策略</strong>。自行实现缓存时，除了上述集中常见策略，也可以根据业务的场景构建业务自定义的淘汰策略。比如根据<code>创建日期</code>、根据最后<code>修改日期</code>、根据<code>优先级</code>、根据<code>访问次数</code>等等。</p></li></ol><p>一些主流的缓存中间件的淘汰机制大都也是遵循上述的方案来实现的。比如<code>Redis</code>提供了高达<code>6种</code>不同的数据淘汰机制，供使用方按需选择，将有限的空间仅用来存储热点数据，实现缓存的价值最大化。如下：</p><p><img src="https://pics.codingcoder.cn/pics/202210031841474.png"></p><p>从上图可以看出，<code>Redis</code>对随机淘汰和LRU策略进行的更精细化的实现，支持将淘汰目标范围细分为全部数据和设有过期时间的数据，这种策略相对更为合理一些。因为一般设置了过期时间的数据，本身就具备可删除性，将其直接淘汰对业务不会有逻辑上的影响；而没有设置过期时间的数据，通常是要求常驻内存的，往往是一些配置数据或者是一些需要当做白名单含义使用的数据（比如用户信息，如果用户信息不在缓存里，则说明用户不存在），这种如果强行将其删除，可能会造成业务层面的一些逻辑异常。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h2 id="缓存雪崩：避免缓存的集中失效"><a href="#缓存雪崩：避免缓存的集中失效" class="headerlink" title="缓存雪崩：避免缓存的集中失效"></a>缓存雪崩：避免缓存的集中失效</h2><p>为了限制缓存的数量，很多的缓存记录都会设置一定的有效期，到期后自动失效。这种在一些批量缓存构建或者全量缓存重建时，因为设置了相同的失效时间，会导致大量甚至全部的缓存数据在短时间内<strong>集体失效</strong>，这样会导致大量的请求无法命中缓存而直接流转到了下游模块，导致系统瘫痪，也即<code>缓存雪崩</code>。</p><p><img src="https://pics.codingcoder.cn/pics/202210031105732.png"></p><p>其实解决的思路也很简单，<strong>避免出现集中失效</strong>就好咯。如何避免呢？</p><p>一种简单的策略，就是批量加载的场景，将过期时间在一个固定时间段内以毫秒级别进行<strong>随机打散</strong>，比如本来要设置每条记录过期时间为5分钟，则批量加载的时候可以设置过期时间为5~10分钟之间的任意一个毫秒数。这样就可以有效的避免数据集中失效，避免出现缓存雪崩而影响业务稳定。</p><p>此外，在一些大型系统里面，尤其是一些分布式微服务化的系统中，很多情况下都会有多个独立的缓存服务，而最终持久化数据则集中存储。如果某个独立缓存真的出现了缓存雪崩，业务层面应该如何将受损范围控制在仅自身模块、避免殃及数据库以及下游公共服务模块，进而避免业务出现系统性瘫痪呢？这个就需要结合服务治理中的一些手段来综合防范了，比如<code>服务降级</code>、<code>服务熔断</code>、以及<code>接口限流</code>等策略。</p><p><img src="https://pics.codingcoder.cn/pics/202210051140921.png"></p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h2 id="缓存击穿：有效的冷数据预热加载机制"><a href="#缓存击穿：有效的冷数据预热加载机制" class="headerlink" title="缓存击穿：有效的冷数据预热加载机制"></a>缓存击穿：有效的冷数据预热加载机制</h2><p>正如前面所提到的，基于内存的缓存，受内存容量限制，往往都会加载一些<strong>热点数据</strong>。而这些热点缓存数据，可以命中大部分的业务请求。少部分没有命中缓存的数据，则直接转由业务模块进行处理（比如从<code>MySQL</code>里面进行查询）。</p><p>先来看一个例子：</p><blockquote><p>互动论坛系统，使用Redis作为缓存，缓存最近1年的帖子信息。如果用户查看的帖子是最近1年的，则直接从Redis中查询并返回，如果用户查看的帖子是1年前的，则从MySQL中进行捞取并返回。</p></blockquote><p>因为论坛系统中，大部分人会阅读或者查看的都是最近新发的帖子，只有极少数的人可能会偶尔“挖坟”查看一年前的历史帖子。系统上线前会根据冷热请求的比例与总量情况，评估需要部署的硬件规模，以确保可以支撑住线上正常的访问请求。但为了避免缓存数据被无限撑满，一般业务缓存数据都会设置一个过期时间，来保证缓存数据的定期清理与更新。</p><p>近段时间，娱乐圈的雷声不断，各种新鲜的大瓜也让吃瓜群众撑到打嗝。</p><blockquote><p>有一天，娱乐圈当红流量明星李某某突然被爆料与某网红存在某些不正当的关系，甚至被爆有多次PC被捕的惊天大瓜，引起粉丝和路人的强烈关注。</p></blockquote><p>吃瓜群众们群情高涨、热搜一波盖过一波、帖子的浏览量光速攀升，论坛系统在缓存模块的加持下，虽然整体CPU和内存占用都飙升上去了，倒也相安无事。</p><p>但天有不测风云，恰好这个时候，<strong>这条帖子的记录在缓存中过期被删除了</strong>。然后狂涛巨浪般的请求涌向了后端的数据库，让数据库原地瘫痪，进而陆陆续续殃及了整个论坛系统。这就是典型的一个<code>缓存击穿</code>的问题。</p><p><img src="https://pics.codingcoder.cn/pics/202210052100508.png"></p><p><code>缓存击穿</code>和前面提到的<code>缓存雪崩</code>产生的原因其实很相似。<strong>区别点</strong>在于：</p><ul><li><p>缓存雪崩是<strong>大面积的缓存失效</strong>导致大量请求涌入数据库。</p></li><li><p>缓存击穿是<strong>少量缓存失效</strong>的时候恰好失效的数据<strong>遭遇大并发量的请求</strong>，导致这些请求全部涌入数据库中。</p></li></ul><p>针对这种情况，我们可以为热点数据设置一个过期时间<strong>续期</strong>的操作，比如每次请求的时候自动将过期时间续期一下。此外，也可以在数据库记录访问的时候借助<strong>分布式锁</strong>来防止缓存击穿问题的出现。当缓存不可用时，仅<code>持锁的线程</code>负责从数据库中查询数据并写入缓存中，其余请求重试时先尝试从缓存中获取数据，避免所有的并发请求全部同时打到数据库上。如下图所示：</p><p><img src="https://pics.codingcoder.cn/pics/202210051107194.png"></p><p>对上面的处理过程描述说明如下：</p><ol><li><p>没有命中缓存的时候，先请求获取分布式锁，获取到分布式锁的线程，执行<code>DB查询</code>操作，然后将查询结果写入到缓存中；</p></li><li><p>没有抢到分布式锁的请求，原地<code>自旋等待</code>一定时间后进行再次重试；</p></li><li><p>未抢到锁的线程，再次重试的时候，先尝试去缓存中获取下是否能获取到数据，如果可以获取到数据，则<code>直接取缓存</code>已有的数据并返回；否则重复上述<code>1</code>、<code>2</code>、<code>3</code>步骤。</p></li></ol><p>按照上面的策略，经过一番通宵紧急上线操作后，系统终于恢复了正常。正当开发人员长舒了口气准备下班回家睡觉的时候，系统警报再次响起，系统再次宕机了。</p><blockquote><p>有人扒出了一个2年前的帖子，这个帖子在2年前就已经爆料李某某由于PC被警方拘捕，当时大家都不信。于是这个2年前的帖子得到了众人狂热的转发与阅读查看。</p></blockquote><p>其实宕机的原因很明显，因为系统只规划缓存了最近1年的所有帖子信息，而对超过1年的帖子的操作，都会直接请求到数据库上。这个2年前的帖子突然爆火导致大量的用户来请求直接打到了下游，再次将数据库压垮 —— 也就是说又一次出现了<code>缓存击穿</code>，在同一块石头上摔倒了两次！</p><p><img src="https://pics.codingcoder.cn/pics/202210031157350.png"></p><p>对于业务中最常使用的<code>旁路型缓存</code>而言，通常会先读取缓存，如果不存在则去数据库查询，并将查询到的数据添加到缓存中，这样就可以使得后面的请求继续命中缓存。</p><p><img src="https://pics.codingcoder.cn/pics/202210031755019.png"></p><p>但是这种常规操作存在个“漏洞”，因为大部分缓存容量有限制，且很多场景会基于<code>LRU策略</code>进行内存中热点数据的淘汰，假如有个恶意程序(比如爬虫)一直在刷历史数据，容易将内存中的热点数据变为历史数据，导致真正的用户请求被打到数据库层。因而又出现了一些业务场景，会使用类似上面所举的例子的策略，缓存指定时间段内的数据（比如最近1年），且<strong>数据不存在时从DB获取内容之后也不会回写到缓存</strong>中。针对这种场景，在缓存的设计时，需要考虑到对这种<strong>冷数据的加热机制</strong>进行一些额外处理，如设定一个门槛，如果指定时间段内对一个冷数据的访问次数达到阈值，则将冷数据加热，添加到热点数据缓存中，并设定一个独立的过期时间，来解决此类问题。</p><p>比如上面的例子中，我们可以约定同一秒内对某条冷数据的请求超过<code>10次</code>，则将此条冷数据加热作为<strong>临时热点</strong>数据存入缓存，设定缓存过期时间为30天（一般一个陈年八卦一个月足够消停下去了）。通过这样的机制，来解决冷数据的突然窜热对系统带来的不稳定影响。如下图所示：</p><p><img src="https://pics.codingcoder.cn/pics/202210031802418.png"></p><p>又是一番紧急上线，终于，系统又恢复正常了。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h2 id="缓存穿透：合理的防身自保手段"><a href="#缓存穿透：合理的防身自保手段" class="headerlink" title="缓存穿透：合理的防身自保手段"></a>缓存穿透：合理的防身自保手段</h2><p>我们的系统对外开放并运行的时候，面对的环境<strong>险象环生</strong>。你不知道请求是来自一个正常用户还是某些别有用心的盗窃者、亦或是个纯粹的破坏者。</p><p>还是上面的论坛的例子：</p><blockquote><p>用户在互动论坛上点击帖子并查看内容的时候，界面调用查询帖子详情接口时会传入帖子ID，然后后端基于帖子ID先去缓存中查询，如果缓存中存在则直接返回数据，否则会尝试从MySQL中查询数据并返回。</p><p>有些人盯上了论坛的内容，便搞了个爬虫程序，模拟帖子ID的生成规则，调用查询详情接口并传入自己生成的ID去遍历挖取系统内的帖子数据，这样导致很多传入的ID是无效的、系统内并不存在对应ID的帖子数据。</p></blockquote><p><img src="https://pics.codingcoder.cn/pics/202210031810564.png"></p><p>所以，上面大量无效的ID请求到系统内，因为<strong>无法命中缓存</strong>而被转到MySQL中查询，而MySQL中其实也无法查询到对应的数据（因为这些ID是恶意生成的、压根不存在）。大量此类请求频繁的传入，就会导致请求<strong>一直依赖MySQL进行处理</strong>，极易冲垮下游模块。这个便是经典的<code>缓存穿透</code>问题（<em>缓存穿透</em>与<em>缓存击穿</em>非常相似，区别点在于<strong>缓存穿透</strong>的实际请求数据在数据库中也没有，而<strong>缓存击穿</strong>是仅仅在缓存中没命中，但是在数据库中其实是存在对应数据的）。</p><p><code>缓存穿透</code>的情况往往出现在一些外部干扰或者攻击情景中，比如<strong>外部爬虫</strong>、比如<strong>黑客攻击</strong>等等。为了解决缓存穿透的问题，可以考虑基于一些类似<strong>白名单</strong>的机制（比如基于<code>布隆过滤器</code>的策略，后面系列文章中会详细探讨），当然，有条件的情况下，也可以构建一些反爬策略，比如添加请求签名校验机制、比如添加IP访问限制策略等等。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h2 id="缓存的数据一致性"><a href="#缓存的数据一致性" class="headerlink" title="缓存的数据一致性"></a>缓存的数据一致性</h2><p>缓存作为持久化存储（如数据库）的辅助存在，毕竟属于两套系统。理想情况下是缓存数据与数据库中数据完全一致，但是业务最常使用的旁路缓存架构下，在一些分布式或者高并发的场景中，可能会出现<strong>缓存不一致</strong>的情况。</p><h3 id="数据库更新-缓存更新"><a href="#数据库更新-缓存更新" class="headerlink" title="数据库更新+缓存更新"></a>数据库更新+缓存更新</h3><p>在数据有变更的时候，需要同时更新缓存和数据库两个地方的数据。因为涉及到两个模块的数据更新，所以会有2种组合情况：</p><ul><li>先更新缓存，再更新数据库</li><li>先更新数据库， 再更新缓存</li></ul><p><img src="https://pics.codingcoder.cn/pics/202210032153862.png"></p><p>在<code>单线程</code>场景下，如果更新缓存和更新数据库操作都是成功的，则可以保证数据库与缓存数据是一致的。但是在多线程场景下，由于由于更新缓存和更新数据库是两个操作，不具备<code>原子性</code>，就有可能出现多个并发请求交叉的情况，进而导致缓存和数据库中的记录不一致的情况。比如下面这个场景：</p><p><img src="https://pics.codingcoder.cn/pics/202210041652366.png"></p><p>这种情况下，有很多的人会选择结合数据库的事务来一起控制。因为数据库有事务控制，而Redis等缓存没有事务性，所以会在一个<code>DB事务</code>中封装多个操作，比如<strong>先执行数据库操作，执行成功之后再进行缓存更新</strong>操作。这样如果缓存更新失败，则直接将当前数据库的事务回滚，企图用这种方式来保证缓存数据与DB数据的一致。</p><p><img src="https://pics.codingcoder.cn/pics/202210032210036.png"></p><p>乍看似乎没毛病，但是细想一下，其实是<strong>有前提条件</strong>的。我们知道数据库事务的<code>隔离级别</code>有几种不同的类型，需要保证使用的事务隔离级别为<code>Serializable</code>或者<code>Repeatable Read</code>级别，以此来保证并发更新的场景下不会出现数据不一致问题，但这也降低了<em>并发效率</em>，提高数据库的<em>CPU负载</em>（隔离级别与并发性能存在一定的关联关系，见下图所示）。</p><p><img src="https://pics.codingcoder.cn/pics/202210041631265.png"></p><p>所以对于一些<code>读多写少</code>、写操作并发竞争不是特别激烈且对一致性要求<em>不是特别高</em>的情况下，可以采用<strong>事务（高隔离级别） + 先更新数据库再更新缓存</strong>的方式来达到数据一致的诉求。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h3 id="数据库更新-缓存删除"><a href="#数据库更新-缓存删除" class="headerlink" title="数据库更新+缓存删除"></a>数据库更新+缓存删除</h3><p>在旁路型缓存的读操作分支中，从缓存中没有读取到数据而改为从DB中获取到数据之后，通常都会选择将记录写入到缓存中。所以我们也可以在写操作的时候选择<strong>将缓存直接删除</strong>，等待后续读取的时候重新加载到缓存中。</p><p>这样也会有两种组合情况：</p><ul><li>先删除缓存，再更新数据库</li><li>先更新数据库，再删除缓存</li></ul><p><img src="https://pics.codingcoder.cn/pics/202210032158937.png"></p><p>这种也会出现前面说的先操作成功，后操作失败的问题。<br>我们先看下先删除缓存再更新数据库的操作策略。如果先删除缓存成功，然后更新数据库失败，这种情况下，再次读取的时候，会从DB里面将旧数据重新加载回缓存中，数据是可以保持一致的。</p><p>虽然更新数据库失败这种场景下不会出现问题，但是在数据库更新成功这种正常情况下，却可能会在并发场景中出现问题。因为常见的缓存（如Redis）是没有事务的，所以可能会因为并发处理顺序的问题导致最终数据不一致。如下图所示：</p><p><img src="https://pics.codingcoder.cn/pics/202210041034338.png"></p><p>上图中，因为<code>删除缓存</code>和<code>更新DB</code>是<strong>非原子</strong>操作，所以在并发场景下可能的情况：</p><ol><li><p>A请求执行更新数据操作，先删除了缓存中的数据；</p></li><li><p>A这个时候还没来及往DB中更新数据的时候，B查询请求恰好进入；</p></li><li><p>B先查询缓存发现缓存中没有数据，又从数据库中查询记录并将记录写入缓存中（相当于A刚删了缓存，B又将原样数据写回缓存了）；</p></li><li><p>A执行完成更新逻辑，将变更后的数据写入到DB中。</p></li></ol><p>一番操作完成后，实际上缓存中存储的是A修改前的内容，而DB中存储的是A修改后的数据，两者因此出现了不一致的问题。这样导致后面的查询请求依旧是从缓存中获取到旧数据，而更新后的新数据无法生效。</p><p>那么，如果采用<strong>先更新数据库，再删除缓存</strong>的策略，又会有何种表现呢？假设数据库更新成功，但是缓存删除失败，我们也可以通过数据库事务回滚的方式将数据库更新操作回滚掉，这样在非并发状态下，可以确保数据库与缓存中数据是一致的。</p><p><img src="https://pics.codingcoder.cn/pics/202210041102902.png"></p><p>当然，因为基于数据库事务机制来控制，需要注意下事务的<strong>粒度不能过大</strong>，避免事务成为阻塞系统性能的瓶颈。在对并发性能要求极高的情况下，可以考虑非事物类的其余方式来实现，如<code>重试机制</code>、或<code>异步补偿机制</code>、或多者结合方式等。</p><p>比如下图所示的这种策略：</p><p><img src="https://pics.codingcoder.cn/pics/202210041121273.png"></p><p>上图的数据更新处理策略，可以有效的保证数据的最终一致性，降低极端情况可能出现数据不一致的概率，并兜底增加了数据不一致时的自恢复能力。</p><p>具体处理逻辑说明如下：</p><ul><li><p>先执行数据库的数据更新操作。</p></li><li><p>更新成功，再去执行缓存记录删除操作。</p></li><li><p>缓存如果删除失败，则按照预定的<code>重试策略</code>（比如对于指定错误码进行重试，最多重试3次，每次重试间隔100ms等）进行重试。</p></li><li><p>如果缓存删除失败，且重试依旧失败，则将此删除事件放入到MQ中。</p></li><li><p>独立的<code>补偿逻辑</code>，会去消费MQ中的消息事件请求，然后按照补偿策略继续尝试删除。</p></li><li><p>每个缓存记录设定过期事件，极端情况下，重试删除、补偿删除等策略全部失败时，等到数据记录<strong>过期</strong>自动从缓存中淘汰，作为<code>兜底策略</code>。</p></li></ul><p>这种处理方式，虽然依旧无法百分百保证数据一致，但是整体出现数据不一致情况的概率与可能性非常的小。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><p>实际使用场景中，对于一致性要求不是特别高、且并发量不是特别大的场景，可以选择基于数据库事务保证的先更新数据库再更新&#x2F;删除缓存。而对于并发要求较高、且数据一致性要求较好的时候，推荐选择<strong>先更新数据库，再删除缓存，并结合删除重试 + 补偿逻辑 + 缓存过期TTL等综合手段</strong>。</p><h2 id="小结回顾"><a href="#小结回顾" class="headerlink" title="小结回顾"></a>小结回顾</h2><p>本篇内容中，我们主要探讨了下缓存的使用过程中的一些典型异常的<strong>触发场景</strong>与<strong>防护策略</strong>，并一起聊了下保持缓存与数据库<strong>数据一致性</strong>的一些保障手段。</p><p>关于这些内容，我们本篇就聊到这里。</p><p>那么，你是否在使用缓存的时候遇到过类似的问题呢？你是如何解决这些问题的呢？你关于这些问题你是否有更好的理解与应对策略呢？欢迎评论区一起交流下，期待和各位小伙伴们一起切磋、共同成长。</p><p>📣 <strong>补充说明</strong> ：</p><blockquote><p>本文属于《<a href="https://juejin.cn/column/7140852038258147358">深入理解缓存原理与实战设计</a>》系列专栏的内容之一。该专栏围绕缓存这个宏大命题进行展开阐述，全方位、系统性地深度剖析各种缓存实现策略与原理、以及缓存的各种用法、各种问题应对策略，并一起探讨下缓存设计的哲学。</p><p>如果有兴趣，也欢迎关注此专栏。</p></blockquote><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><p><strong>我是悟道，聊技术、又不仅仅聊技术~</strong></p><p>如果觉得有用，请<strong>点赞 + 关注</strong>让我感受到您的支持。也可以关注下我的公众号【架构悟道】，获取更及时的更新。</p><p>期待与你一起探讨，一起成长为更好的自己。</p><p><img src="https://pics.codingcoder.cn/pics/202207091312091.gif"></p><p><img src="https://pics.codingcoder.cn/pics/202207091317876.png"></p>]]></content>
      
      
      <categories>
          
          <category> 缓存原理与实战设计 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JAVA </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>聊一聊作为高并发系统基石之一的缓存，会用很简单，用好才是技术活</title>
      <link href="//post/20221028085417.html"/>
      <url>//post/20221028085417.html</url>
      
        <content type="html"><![CDATA[<p><img src="https://pics.codingcoder.cn/pics/202210050807355.png"></p><p>大家好，又见面了。</p><hr><blockquote><p>本文是笔者作为掘金技术社区签约作者的身份输出的缓存专栏系列内容，将会通过系列专题，讲清楚缓存的方方面面。如果感兴趣，欢迎关注以获取后续更新。</p></blockquote><hr><p>在服务端开发中，<strong>缓存</strong>常常被当做系统<em>性能扛压</em>的不二之选。在实施方案上，缓存使用策略虽有一定普适性，却也并非完全绝对，需要结合实际的项目诉求与场景进行综合权衡与考量，进而得出符合自己项目的最佳实践。</p><h2 id="缓存使用的演进"><a href="#缓存使用的演进" class="headerlink" title="缓存使用的演进"></a>缓存使用的演进</h2><p>现有这么一个系统：</p><blockquote><p>一个互动论坛系统，用户登录系统之后，可以在论坛上查看帖子列表、查看帖子详情、发表帖子、评论帖子、为帖子点赞等操作。</p></blockquote><p>系统中所有的配置数据与业务数据均存储在<code>数据库</code>中。随着业务的发展，注册用户量越来越多，然后整个系统的响应速度也越来越慢，用户体验越来越差，用户逐渐出现流失。</p><h3 id="本地缓存的牛刀小试"><a href="#本地缓存的牛刀小试" class="headerlink" title="本地缓存的牛刀小试"></a>本地缓存的牛刀小试</h3><p>为了挽救这一局面，开发人员需要介入去分析性能瓶颈并尝试优化提升响应速度，并很快找到响应慢的瓶颈在数据库的频繁操作，于是想到了使用<code>缓存</code>来解决问题。</p><p>于是，开发人员在项目中使用了<strong>基于接口</strong>维度的<strong>短期缓存</strong>，对每个接口的<code>请求参数</code>（帖子ID）与<code>响应内容</code>缓存一定的时间（比如1分钟），对于相同的请求，如果匹配到缓存则直接返回缓存的结果即可，不用再次去执行查询数据库以及业务维度的运算逻辑。</p><p><img src="https://pics.codingcoder.cn/pics/202210010704311.png"></p><p><code>JAVA</code>中有很多的开源框架都有提供类似的能力支持，比如<code>Ehcache</code>或者<code>Guava Cache</code>、<code>Caffeine Cache</code>等，可以通过简单的添加注解的方式就实现上述需要的缓存效果。比如使用<em>Ehcache</em>来实现接口接口缓存的时候，代码使用方式如下（这里先简单的演示下，后续的系列文档中会专门对这些框架进行深入的探讨）：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">@Cacheable(value&#x3D;&quot;UserDetailCache&quot;, key&#x3D;&quot;#userId&quot;)public UserDetail queryUserDetailById(String userId) &#123;    UserEntity userEntity &#x3D; userMapper.queryByUserId(userId);    return convertEntityToUserDetail(userEntity);&#125;</code></pre><p>基上面的本地缓存策略改动后重新上线，整体的响应性能上果然提升了很多。<strong>本地缓存</strong>的策略虽然有效地提升了处理请求的速度，<em>但新的问题也随之浮现</em>。有用户反馈，社区内的帖子列表多次刷新后会出现内容不一致的情况，有的帖子刷新之后会从列表消失，多次刷新后偶尔会出现。</p><p>其实这就是本地缓存在集群多节点场景下会遇到的一个很常见的<strong>缓存漂移</strong>现象：</p><p><img src="https://pics.codingcoder.cn/pics/202210010815833.png"></p><p>因为业务集群存在多个节点，而缓存是每个业务节点本地独立构建的，所以才出现了更新场景导致的本地缓存不一致的问题，进而表现为上述问题现象。</p><h3 id="集中式缓存的初露锋芒"><a href="#集中式缓存的初露锋芒" class="headerlink" title="集中式缓存的初露锋芒"></a>集中式缓存的初露锋芒</h3><p>为了解决集群内多个节点间执行写操作之后，各节点本地缓存不一致的问题，开发人员想到可以构建一个<strong>集中式缓存</strong>，然后所有业务节点都读取或者更新同一份缓存数据，这样就可以完美地解决节点间缓存不一致的问题了。</p><p><img src="https://pics.codingcoder.cn/pics/202210010812002.png"></p><p>业界成熟的集中式缓存有很多，最出名的莫过于很多人都耳熟能详的<code>Redis</code>，或者是在各种面试中常常被拿来与Redis进行比较的<code>Memcached</code>。也正是由于它们出色的自身性能表现，在当前的各种分布式系统中，Redis近乎已经成为了一种标配，常常与<code>MySQL</code>等持久化数据库搭配使用，放在数据库前面进行扛压。比如下面图中示例的一种最简化版本的组网架构：</p><p><img src="https://pics.codingcoder.cn/pics/202210041757340.png"></p><p>开发人员对缓存进行了整改，将<strong>本地缓存</strong>改为了<strong>Redis集中式缓存</strong>。这样一来：</p><ol><li><p><strong>缓存不一致问题解决</strong>：解决了各个节点间数据不一致的问题。</p></li><li><p><strong>单机内存容量限制解决</strong>：使用了Redis这种分布式的集中式缓存，扩大了内存缓存的容量范围，可以顺便将很多业务层面的数据全部加载到Redis中分片进行缓存，性能也相比而言得到了提升。</p></li></ol><p>似乎使用集中式缓存已经是分布式系统中的最优解了，但是现实情况真的就这么简单么？<em>也不尽然</em>！</p><h3 id="多级缓存的珠联璧合"><a href="#多级缓存的珠联璧合" class="headerlink" title="多级缓存的珠联璧合"></a>多级缓存的珠联璧合</h3><p>在尝到了集中式缓存的甜头之后，暖心的程序员们想到要彻底为数据库减压，将所有业务中需要频繁使用的数据全部同步存储到<code>Redis</code>中，然后业务使用的时候直接从Redis中获取相关数据，大大地减少了数据库的请求频次。但是改完上线之后，发现有些处理流程中<strong>并没有</strong>太大的性能提升。缘何如此？只因为对<code>集中式缓存</code>的过分<strong>滥用</strong>！分析发现这些流程的处理需要涉及大量的交互与数据整合逻辑，一个流程需要访问近乎<code>30</code>次Redis！虽然Redis的单次请求处理性能极高，甚至可以达到微秒级别的响应速度，但是每个流程里面几十次的<code>网络IO</code>交互，导致频繁的<code>IO请求</code>，以及线程的<code>阻塞</code>与<code>唤醒</code>切换交替，使得系统在线程上下文切换层面<strong>浪费巨大</strong>。</p><p>那么，要想破局，最常规的手段便是尝试降低对集中式缓存（如Redis）的请求数量，降低网络IO交互次数。而如何来降低呢？ —— 又回到了<strong>本地缓存</strong>！集中式缓存并非是分布式系统中提升性能的银弹，但我们可以将本地缓存与集中式缓存结合起来使用，<strong>取长补短</strong>，实现效果最大化。如图所示：</p><p><img src="https://pics.codingcoder.cn/pics/202210031821363.png"></p><p>上图演示的也即<strong>多级缓存</strong>的策略。具体而言：</p><ul><li><p>对于一些<strong>变更频率比较高</strong>的数据，采用<code>集中式缓存</code>，这样可以确保数据变更之后所有节点都可以实时感知到，确保数据一致；</p></li><li><p>对于一些<strong>极少变更的数据</strong>（比如一些系统配置项）或者是一些<strong>对短期一致性要求不高</strong>的数据（比如用户昵称、签名等）则采用<code>本地缓存</code>，大大减少对远端集中式缓存的网络IO次数。</p></li></ul><p>这样一来，系统的响应性能又得到了进一步的提升。</p><p>通过对缓存使用策略的一步步演进，我们可以感受到缓存的恰当使用对系统性能的帮助作用。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h2 id="无处不在的缓存"><a href="#无处不在的缓存" class="headerlink" title="无处不在的缓存"></a>无处不在的缓存</h2><p>缓存存在的初衷，就是为了<strong>兼容两个处理速度不一致的场景对接适配</strong>的。在我们的日常生活中，也常常可以看到“<strong>缓存</strong>”的影子。比如对于几年前比较盛行的那种带桶的净水器（见下图），由于净水的功率比较小，导致实时过滤得到纯净水的水流特别的缓慢，用户倒一杯水要等<code>2分钟</code>，体验太差，所以配了个蓄水桶，净水机先慢慢的将净化后的水存储到桶中，然后用户倒水的时候可以从桶里快速的倒出，无需焦急等待 —— 这个蓄水桶，便是一个<strong>缓存器</strong>。</p><p><img src="https://pics.codingcoder.cn/pics/202209302224417.png"></p><p>编码源于生活，<code>CPU</code>的<strong>高速缓存</strong>设计就是这一生活实践在计算机领域的原样复制。缓存可以说在软件世界里无处不在，除了我们自己的业务系统外，在<code>网络传输</code>、<code>操作系统</code>、<code>中间件</code>、<code>基础框架</code>中都可以看到缓存的影子。如：</p><ol><li><strong>网络传输场景</strong>。</li></ol><p>比如<code>ARP协议</code>，基于ARP缓存表进行<code>IP</code>与终端硬件<code>MAC</code>地址之间的缓存映射。这样与对端主机之间有通信需求的时候，就可以在ARP缓存中查找到IP对应的对端设备MAC地址，避免每次请求都需要去发送ARP请求查询MAC地址。</p><ol start="2"><li><strong>MyBatis的多级缓存</strong>。</li></ol><p><code>MyBatis</code>作为<code>JAVA</code>体系中被广泛使用的数据库操作框架，其内部为了提升处理效率，构建了<strong>一级缓存</strong>与<strong>二级缓存</strong>，大大减少了对<code>SQL</code>的重复执行次数。</p><ol start="3"><li><strong>CPU中的缓存</strong>。</li></ol><p><code>CPU</code>与<code>内存</code>之间有个临时存储器（<strong>高速缓存</strong>），容量虽比内存小，但是处理速度却远快于普通内存。高速缓存的机制，有效地解决了<code>CPU运算速度</code>与<code>内存读写速度</code>不匹配的问题。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h2 id="缓存的使用场景"><a href="#缓存的使用场景" class="headerlink" title="缓存的使用场景"></a>缓存的使用场景</h2><p>缓存作为互联网类软件系统架构与实现中的<strong>基石</strong>般的存在，不仅仅是在<em>系统扛压</em>或者<em>接口处理速度提升</em>等性能优化方案，在其他多个方面都可以发挥其独一无二的关键价值。下面就让我们一起来看看缓存都可以用在哪些场景上，可以解决我们哪方面的痛点。</p><h3 id="降低自身CPU消耗"><a href="#降低自身CPU消耗" class="headerlink" title="降低自身CPU消耗"></a>降低自身CPU消耗</h3><p>如前面章节中提到的项目实例，缓存最典型的使用场景就是用在系统的<strong>性能优化</strong>上。而在性能优化层面，一个经典的策略就是“<strong>空间换时间</strong>”。比如：</p><ul><li><strong>在数据库表中做一些字段冗备</strong>。</li></ul><p>比如用户表<code>T_User</code>和部门表<code>T_Department</code>，在<code>T_User</code>表中除了有个<code>Department_Id</code>字段<code>与T_Department</code>表进行关联之外，还额外在<code>T_User</code>表中存储<code>Department_Name</code>值。这样在很多需要展示用户所属部门信息的时候就省去了多表关联查询的操作。</p><p><img src="https://pics.codingcoder.cn/pics/202210012126284.png"></p><ul><li><strong>对一些中间处理结果进行存储</strong>。</li></ul><p>比如系统中的<strong>数据报表</strong>模块，需要对整个系统内所有的关联业务数据进行计算统计，且需要多张表多来源数据之间的综合汇总之后才能得到最终的结果，整个过程的计算非常的耗时。如果借助缓存，则可以将一些<em>中间计算结果</em>进行<strong>暂存</strong>，然后报表请求中基于中间结果进行二次简单处理即可。这样可以大大降低基于请求触发的实时计算量。</p><p>在“<code>空间换时间</code>”实施策略中，<strong>缓存</strong>是该策略的<em>核心</em>、也是被使用的最为广泛的一种方案。借助缓存，可以将一些<code>CPU</code>耗时计算的处理结果进行缓存复用，以降低重复计算工作量，达到降低<code>CPU</code>占用的效果。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h3 id="减少对外IO交互"><a href="#减少对外IO交互" class="headerlink" title="减少对外IO交互"></a>减少对外IO交互</h3><p>上面介绍的使用缓存是为了不断降低请求处理时对自身CPU占用，进而提升服务的处理性能。这里我们介绍缓存的另一典型使用场景，就是减少系统<code>对外依赖</code>的<strong>请求频次</strong>。即通过将一些从远端请求回来的响应结果进行缓存，后面直接使用此缓存结果而无需再次发起网络IO请求交互。</p><p>对于服务端而言，通过构建缓存的方式来减少自身对外的<strong>IO请求</strong>，主要有几个考量出发点：</p><ol><li><p>从<strong>自身性能</strong>层面考虑，减少对外<code>IO操作</code>，降低了对外接口的<code>响应时延</code>，也对服务端自身处理性能有一定提升。</p></li><li><p>从<strong>对端服务</strong>稳定性层面考虑，避免对端服务<code>负载过大</code>。很多时候调用方和被调用方系统的承压能力是不匹配的，甚至有些被调用方系统可能是不承压的。为了避免将对端服务压垮，需要调用方缓存请求结果，<code>降低IO</code>请求。</p></li><li><p>从<strong>自身可靠性</strong>层面而言，将一些远端服务请求到的结果缓存起来，即使远端服务出现故障，自身业务依旧可以基于缓存数据进行正常业务处理，起到一个<code>兜底作用</code>，<strong>提升自身的抗风险能力</strong>。</p></li></ol><p>在分布式系统服务治理范畴内，服务注册管理服务是必不可少的，比如<code>SpringCloud</code>家族的<code>Eureka</code>，或者是<code>Alibaba</code>开源的<code>Nacos</code>。它们对于缓存的利用，可以说是对上面所提几点的完美阐述。</p><p>以<code>Nacos</code>为例：</p><p><img src="https://pics.codingcoder.cn/pics/202210012142276.png"></p><p>除了上述的因素之外，对一些移动端<code>APP</code>或者<code>H5</code>界面而言，缓存的使用还有一个层面的考虑，即<strong>降低用户的流量消耗</strong>，通过将一些资源类数据缓存到本地，避免反复去下载，给用户省点流量，也可以<strong>提升用户的使用体验</strong>（界面渲染速度快，减少出现白屏等待的情况）。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h3 id="提升用户个性化体验"><a href="#提升用户个性化体验" class="headerlink" title="提升用户个性化体验"></a>提升用户个性化体验</h3><p>缓存除了在系统性能提升或系统可靠性兜底等场景发挥价值外，在<code>APP</code>或者<code>web</code>类用户侧产品中，还经常被用于存储一些临时非永久的个性化使用习惯配置或者身份数据，以提升用户的个性化使用体验。</p><ul><li>缓存<code>cookie</code>、<code>session</code>等身份鉴权信息，这样就可以避免用户每次访问都需要进行身份验证。</li></ul><p><img src="https://pics.codingcoder.cn/pics/202209301615141.png"></p><ul><li><p>记住一些用户上次<code>操作习惯</code>，比如用户在一个页面上将列表分页查询设置为<code>100</code>条&#x2F;页，则后续在系统内访问其它列表页面时，都沿用这一设置。</p></li><li><p>缓存用户的一些<code>本地设置</code>，这个主要是<code>APP</code>端常用的功能，可以在缓存中保存些与当前设备绑定的设置信息，仅对当前设备有效。比如同一个账号登录某个APP，用户希望在手机端可以显示深色主题，而PAD端则显示浅色主体，这种基于设备的个性化设置，可以缓存到设备本身即可。</p></li></ul><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h2 id="业务与缓存的集成模式"><a href="#业务与缓存的集成模式" class="headerlink" title="业务与缓存的集成模式"></a>业务与缓存的集成模式</h2><p>如前所述，我们可以在不同的方面使用缓存来辅助达成项目在某些方面的诉求。而根据使用场景的不同，在结合缓存进行业务逻辑实现的时候，也会存在不同的<strong>架构模式</strong>，典型的会有<code>旁路型缓存</code>、<code>穿透型缓存</code>与<code>异步型缓存</code>三种。</p><h3 id="旁路型缓存"><a href="#旁路型缓存" class="headerlink" title="旁路型缓存"></a>旁路型缓存</h3><p>在<strong>旁路型缓存</strong>模式中，业务自行负责与缓存以及数据库之间的交互，可以<strong>自由决定缓存未命中场景的处理策略</strong>，更加契合大部分业务场景的定制化诉求。</p><p><img src="https://pics.codingcoder.cn/pics/202210032149778.png"></p><p>由于业务模块自行实现缓存与数据库之间的数据写入与更新的逻辑，实际实现的时候需要注意下在<strong>高并发</strong>场景的<code>数据一致性</code>问题，以及可能会出现的<code>缓存击穿</code>、<code>缓存穿透</code>、<code>缓存雪崩</code>等问题的防护。</p><p>旁路型缓存是实际业务中<strong>最常使用</strong>的一种架构模式，在后面的内容中，我们还会不断的涉及到旁路缓存中相关的内容。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h3 id="穿透型缓存"><a href="#穿透型缓存" class="headerlink" title="穿透型缓存"></a>穿透型缓存</h3><p><strong>穿透型缓存</strong>在实际业务中<em>使用的较少</em>，主要是应用在一些缓存类的中间件中，或者在一些大型系统中专门的数据管理模块中使用。</p><p>一般情况下，业务使用缓存的时候，会是先尝试读取缓存，在尝试读取<code>DB</code>，而使用穿透型缓存架构时，会有专门模块将这些动作封装成黑盒的，业务模块不会与数据库进行直接交互。如下图所示：</p><p><img src="https://pics.codingcoder.cn/pics/202210032116685.png"></p><p>这种模式对业务而言是比较友好的，业务只需调用缓存接口即可，无需自行实现缓存与DB之间的交互策略。</p><h3 id="异步型缓存"><a href="#异步型缓存" class="headerlink" title="异步型缓存"></a>异步型缓存</h3><p>还有一种缓存的使用模式，可以看作是穿透型缓存的演进异化版本，其使用场景也相对较少，即<strong>异步型缓存</strong>。其主要策略就是业务侧请求的实时读写交互都是基于缓存进行，任何数据的读写也完全基于缓存进行操作。此外，<strong>单独实现</strong>一个数据持久化操作(独立线程或者进程中执行)，用于将缓存中变更的数据写入到数据库中。</p><p><img src="https://pics.codingcoder.cn/pics/202210032116271.png"></p><p>这种情况，<strong>实时业务</strong>读写请求完全<strong>基于缓存</strong>进行，而将数据库仅仅作为一个数据持久化存储的备份盘。由于实时业务请求仅与缓存进行交互，所以在性能上可以得到更好的表现。但是这种模式也存在一个致命的问题：数据可靠性！因为是异步操作，所以在下一次数据写入DB前，会有一段时间数据仅存在于缓存中，<strong>一旦缓存服务宕机，这部分数据将会丢失</strong>。所以这种模式仅适用于对数据一致性要求不是特别高的场景。</p><h2 id="缓存的优秀实践"><a href="#缓存的优秀实践" class="headerlink" title="缓存的优秀实践"></a>缓存的优秀实践</h2><p><code>缓存</code>与<code>持久化存储</code>的一个很大的不同点就是缓存的定位应该是一种辅助角色，是一种<strong>锦上添花</strong>般的存在。</p><p><code>缓存</code>也是一把<strong>双刃剑</strong>，基于缓存可以大幅提升我们的系统<em>并发</em>与<em>承压</em>能力，但稍不留神也可能会让我们的系统陷入<strong>灭顶之灾</strong>。所以我们在决定使用缓存的时候，需要知晓缓存设计与使用的一些关键要点，才可以让我们在使用的时候更加游刃有余。</p><h3 id="可删除重建"><a href="#可删除重建" class="headerlink" title="可删除重建"></a>可删除重建</h3><p><strong>可删除重建</strong>，这是缓存与持久化存储最大的一个差别。缓存的定位一定是为了辅助业务处理而生的，也就是说缓存有则使用，没有也不会影响到我们具体的业务运转。此外，即使我们的缓存数据除了问题，我们也可以将其删除重建。</p><p>这一点在<code>APP</code>类的产品中体现的会比较明显。比如对于<code>微信APP</code>的缓存，就有明确的提示说缓存可以删除而不会影响其功能使用：</p><p><img src="https://pics.codingcoder.cn/pics/202209301622198.png"></p><p>同样地，我们也可以去放心的清理<code>浏览器</code>的缓存，而不用担心清理之后我们浏览器或者网页的功能会出现异常（最多就是需要重新下载或者重建缓存数据，速度会有一些慢）。</p><p><img src="https://pics.codingcoder.cn/pics/202209301702848.png"></p><p>相同的逻辑，在服务端构建的一些缓存，也应该具备此特性。比如基于内存的缓存，当业务进程重启后，应该有途径可以将缓存重建出来（比如从<code>MySQL</code>中加载数据然后构建缓存，或者是缓存<code>从0开始</code>基于请求触发而构建）。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h3 id="有兜底屏障"><a href="#有兜底屏障" class="headerlink" title="有兜底屏障"></a>有兜底屏障</h3><p>缓存作为高并发类系统中的核心组件，负责抗住大部分的并发请求，一旦缓存组件出问题，往往对整个系统会造成毁灭性的打击。所以我们的缓存在实现的时候必须要有充足且完备的<strong>兜底</strong>与<strong>自恢复</strong>机制。需要做到以下几点：</p><ul><li><p>关注下缓存数据量超出承受范围的处理策略，比如定好数据的<code>淘汰机制</code>。</p></li><li><p>避免缓存集中失效，比如批量加载数据到缓存的时候<code>随机打散</code>过期时间，避免同一时间大批量缓存失效引发<strong>缓存雪崩</strong>问题。</p></li><li><p>有效地<strong>冷数据预热</strong>加载机制，以及<strong>热点数据防过期</strong>机制，避免出现大量对冷数据的请求无法命中缓存或者热点数据突然失效，导致<code>缓存击穿</code>问题。</p></li><li><p>合理的<strong>防身自保</strong>手段，比如采用<code>布隆过滤器</code>机制，避免被恶意请求攻陷，导致<strong>缓存穿透</strong>类的问题。</p></li></ul><p>缓存的可靠性与兜底策略设计，是一个宏大且宽泛的命题，在本系列专栏后续的文章中，我们会逐个深入的探讨。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h3 id="关注缓存的一致性保证"><a href="#关注缓存的一致性保证" class="headerlink" title="关注缓存的一致性保证"></a>关注缓存的一致性保证</h3><p>在高并发类的系统中进行数据更新的时候，缓存与数据库的<code>数据一致性</code>问题，是一个永远无法绕过的话题。对于基于<strong>旁路型缓存</strong>的大部分业务而言，数据更新操作，一般可以组合出几种不同的处理策略：</p><ul><li><p>先更新缓存，再更新数据库</p></li><li><p>先更新数据库， 再更新缓存</p></li><li><p>先删除缓存，再更新数据库</p></li><li><p>先更新数据库，再删除缓存</p></li></ul><p>由于大部分数据库都支持<code>事务</code>，而几乎所有的缓存操作都不具有事务性。所以在一些写操作并发不是特别高且一致性要求不是特别强烈的情况下，可以简单的借助数据库的事务进行控制。比如先更新数据库再更新缓存，如果缓存更新失败则回滚数据库事务。</p><p>然而在一些并发请求特别高的时候，基于事务控制来保证数据一致性往往会对性能造成影响，且事务<code>隔离级别</code>设置的越高影响越大，所以也可以采用一些其它辅助策略，来替代事务的控制，如<code>重试机制</code>、或<code>异步补偿机制</code>、或多者结合方式等。</p><p>比如下图所示的这种策略：</p><p><img src="https://pics.codingcoder.cn/pics/202210041121273.png"></p><p>上图的数据更新处理策略，可以有效地保证数据的最终一致性，降低极端情况可能出现数据不一致的概率，并兜底增加了数据不一致时的自恢复能力。</p><p>数据一致性保证作为缓存的另一个重要命题，我们会在本系列专栏后续的文章中专门进行深入的剖析。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h2 id="总结回顾"><a href="#总结回顾" class="headerlink" title="总结回顾"></a>总结回顾</h2><p>本篇文章的内容中，我们对缓存的各个方面进行了一个简单的阐述与了解，也可以看出缓存对于一个软件系统的重要价值。通过对缓存的合理、充分利用，可以大大的增强我们的系统<code>承压性能</code>、提升产品的<code>用户体验</code>。</p><p>缓存作为<strong>高并发系统</strong>中的<code>神兵利器</code>被广泛使用，堪称<strong>高并发系统的基石之一</strong>。而缓存的内容还远远不止我们本篇文档中所介绍的这些、它是一个非常宏大的命题。</p><p><img src="https://pics.codingcoder.cn/pics/202210050750684.png"></p><p>为了能够将缓存的方方面面彻底的讲透、讲全，在接下来的一段时间里，我会以<strong>系列专栏</strong>的形式，从不同的角度对缓存的方方面面进行探讨。不仅仅着眼于如何去使用缓存、也一起聊聊缓存设计中的一些<code>哲学理念</code> —— 这一点是我觉得更有价值的一点，因为这些理念对提升我们的<strong>软件架构认知</strong>、完善我们的<strong>软件设计思维</strong>有很大的指导与借鉴意义。</p><p>所以，如果你有兴趣，欢迎关注本系列专栏（<a href="https://juejin.cn/column/7140852038258147358">深入理解缓存原理与实战设计</a>），我会以我一贯的行文风格，用<strong>最简单的语言讲透复杂的逻辑</strong>，期待一起切磋、共同成长。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><p><strong>我是悟道，聊技术、又不仅仅聊技术~</strong></p><p>如果觉得有用，请<strong>点赞 + 关注</strong>让我感受到您的支持。也可以关注下我的公众号【架构悟道】，获取更及时的更新。</p><p>期待与你一起探讨，一起成长为更好的自己。</p><p><img src="https://pics.codingcoder.cn/pics/202207091312091.gif"></p><p><img src="https://pics.codingcoder.cn/pics/202207091317876.png"></p>]]></content>
      
      
      <categories>
          
          <category> 缓存原理与实战设计 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JAVA </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spring Data JPA系列5：让IDEA自动帮你写JPA实体定义代码</title>
      <link href="//post/20220628171111.html"/>
      <url>//post/20220628171111.html</url>
      
        <content type="html"><![CDATA[<p><img src="https://pics.codingcoder.cn/pics/202206172121044.png"></p><p>大家好，又见面了。</p><p>这是本系列的最后一篇文档啦，先来回顾下前面几篇：</p><ul><li><p>在第1篇《<a href="https://mp.weixin.qq.com/s/qQR8z3OhwiTxybmEwMME9A">Spring Data JPA系列1：JDBC、ORM、JPA、Spring Data JPA，傻傻分不清楚？给你个选择SpringDataJPA的理由！</a>》中，我们对JPA的整体概念有了全面的了解。</p></li><li><p>在第2篇《<a href="https://mp.weixin.qq.com/s/aUo2HmGI0MO-Nm57TBLUgQ">Spring Data JPA系列2：快速在SpringBoot项目中熟练使用JPA</a>》中也知晓了SpringBoot项目快速集成SpringData JPA以及快速上手使用JPA来进行基本的项目开发的技能。</p></li><li><p>在第3篇《<a href="https://mp.weixin.qq.com/s/NS156Z9aa4mUMbx79-7Z8w">Spring Data JPA系列3：JPA项目中核心场景与进阶用法介绍</a>》进一步的聊一下项目中使用JPA的一些高阶复杂场景的实践指导，覆盖了主要核心的JPA使用场景。</p></li><li><p>在第4篇《<a href="https://mp.weixin.qq.com/s/snjSn0hvG4ARA1vUP_UjNw">Spring Data JPA系列4：Spring声明式事务处理与多数据源支持</a>》我们对数据库事务处理方式以及可能存在的问题等进行了全面的探讨。</p></li></ul><p>通过前面的系列文档，我们一起对SpringData JPA从浅入深的进行了全方位的探讨。正所谓“工欲善其事、必先利其器”，面对一个优秀的框架，如果再结合一些外部的工具，其实可以让我们的开发效率与程序员开发过程的体验更上一层楼的。</p><p>本篇内容，我们就一起来聊一聊这方面。</p><h2 id="借助IDEA提升效率"><a href="#借助IDEA提升效率" class="headerlink" title="借助IDEA提升效率"></a>借助IDEA提升效率</h2><h3 id="IDEA中直接连接数据源"><a href="#IDEA中直接连接数据源" class="headerlink" title="IDEA中直接连接数据源"></a>IDEA中直接连接数据源</h3><p>项目开发的时候，经常需要一边写代码一边看下数据库表数据或者字段，需要在IDEA和数据库客户端之间来回切换，很麻烦。其实，IDEA中可以直接连接数据库，直接在IDEA中查看和执行数据库操作，更加的方便快捷。</p><ol><li>打开View -&gt; Tool Windows -&gt; Database窗口</li></ol><p><img src="https://pics.codingcoder.cn/pics/202206171551412.png"></p><ol start="2"><li>添加数据库连接，点击+号 -&gt; Data Source -&gt; MySQL，如果需要连接其他类型数据库，按需选择</li></ol><p><img src="https://pics.codingcoder.cn/pics/202206171551636.png"></p><ol start="3"><li>填写Host、User、Password、Database等连接信息，填好后点击OK</li></ol><p><img src="https://pics.codingcoder.cn/pics/202206171552381.png"></p><ol start="4"><li>连接完成，可以查看DB中数据，双击表名，可以查看表中数据内容</li></ol><p><img src="https://pics.codingcoder.cn/pics/202206171553602.png"></p><ol start="5"><li>点击打开Console窗口，可以输入SQL语句并执行</li></ol><p><img src="https://pics.codingcoder.cn/pics/202206171610565.png"></p><p>OK, Enjoy it…</p><h3 id="IDEA自动生成实体对象"><a href="#IDEA自动生成实体对象" class="headerlink" title="IDEA自动生成实体对象"></a>IDEA自动生成实体对象</h3><p>数据表定义好了，手动逐个写对应的映射实体Entity，还是很繁琐？教你让IDEA自动给你生成Entity实体类！</p><ol><li>打开IDEA，点击File -&gt; Project Structure菜单</li></ol><p><img src="https://pics.codingcoder.cn/pics/202206171618390.png"></p><ol start="2"><li>打开的窗口中，点击Modules，点击右侧+号按钮，选择JPA菜单</li></ol><p><img src="https://pics.codingcoder.cn/pics/202206171619503.png"></p><ol start="3"><li>选中JPA选项，切换下面Default JPA provider为Hibernate，点击OK</li></ol><p><img src="https://pics.codingcoder.cn/pics/202206171620536.png"></p><ol start="4"><li>IDEA窗口中多了个Persistence窗口，点击打开</li></ol><p><img src="https://pics.codingcoder.cn/pics/202206171622350.png"></p><ol start="5"><li>在Persistence窗口中选择项目名称，右键点击Generate Persistence Mapping -&gt; By Database Schema</li></ol><p><img src="https://pics.codingcoder.cn/pics/202206171622487.png"></p><ol start="6"><li>弹窗中，选择一个数据源（上一章节中讲解的方式配置IDEA与DB的连接），选择代码生成到的代码目标package位置，设定代码生成类名命名规则（prefix或者suffix），然后勾选需要生成对应代码实体的表，勾选左下角Generate JPA Annotations选项，点击OK</li></ol><p><img src="https://pics.codingcoder.cn/pics/202206171625395.png"></p><ol start="7"><li>等一会儿，对应Entity类就会生成到上一步中指定的位置了。</li></ol><p><img src="https://pics.codingcoder.cn/pics/202206171625565.png"></p><ol start="8"><li>后续再需要生成新的表对应实体类的时候，直接执行5~6两个步骤即可。</li></ol><h2 id="后端也想写出完美界面？必须安排！"><a href="#后端也想写出完美界面？必须安排！" class="headerlink" title="后端也想写出完美界面？必须安排！"></a>后端也想写出完美界面？必须安排！</h2><p> 不知道大家有没有过这种经历：</p><ul><li>作为一名后端程序员，往往有一个很好的idea，想自己开发个小系统或者小项目，但苦于自己只能写后端服务，没法配上一个美美的web界面。花了点时间学了下Vue或者React等前端脚手架之后，勉强写出来的界面又丑又难用，而且同时维护前后端太耗费精力，最后很多优秀的idea都消失在岁月的洪流中。</li><li>小型团队，人力有限，没有配齐前后端人员，让后端人员开发蹩脚前端portal，导致整体体验感较差</li><li>…</li></ul><p>这里开源项目Erupt就要登场了，可以完美解决上述问题，堪称后端程序员的福音。</p><p>为什么在SpringData JPA相关教程中提到这个问题呢？因为Erupt的实现思路与JPA ORM的思路非常相似，对于SpringData JPA做数据处理的项目而言，可以非常简单的几个操作就对接到Erupt上！</p><p>详细了解的话，可以去开源项目地址了解下，<a href="https://gitee.com/erupt/erupt">点此了解</a></p><ul><li>Erupt的架构图如下：</li></ul><p><img src="https://pics.codingcoder.cn/pics/202206141805299.png"></p><ul><li>Erupt界面效果如下：</li></ul><p><img src="https://pics.codingcoder.cn/pics/202206141804830.png"></p><p><img src="https://pics.codingcoder.cn/pics/202206141804634.png"></p><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>好啦，本篇内容就介绍到这里。</p><p>至此，本系列的教程就全部结束啦。通过本系列的几篇文档，为大家由浅入深的对JPA进行了全面的探讨，希望能够让大家对SpringData JPA的学习与使用有一定的帮助。也祝愿大家能够在实际项目中，感受到JPA给我们开发过程带来的便捷。</p><p>如果对本文有自己的见解，或者有任何的疑问或建议，都可以留言，我们一起探讨、共同进步。</p><hr><blockquote><p><strong>补充</strong></p><p><code>Spring Data JPA</code>作为<code>Spring Data</code>中对于关系型数据库支持的一种框架技术，属于<code>ORM</code>的一种，通过得当的使用，可以大大简化开发过程中对于数据操作的复杂度。</p><p>本文档隶属于《<code>Spring Data JPA</code>用法与技能探究》系列的第5篇。本系列文档规划对<code>Spring Data JPA</code>进行全方位的使用介绍，一共分为<strong>5篇</strong>文档，如果感兴趣，欢迎关注交流。</p><p>《Spring Data JPA用法与技能探究》系列涵盖内容：</p><ul><li>开篇介绍 —— 《<a href="https://mp.weixin.qq.com/s/qQR8z3OhwiTxybmEwMME9A">Spring Data JPA系列1：JDBC、ORM、JPA、Spring Data JPA，傻傻分不清楚？给你个选择SpringDataJPA的理由！</a>》</li><li>快速上手 —— 《<a href="https://mp.weixin.qq.com/s/aUo2HmGI0MO-Nm57TBLUgQ">Spring Data JPA系列2：SpringBoot集成JPA详细教程，快速在项目中熟练使用JPA</a>》</li><li>深度进阶 —— 《<a href="https://mp.weixin.qq.com/s/NS156Z9aa4mUMbx79-7Z8w">Spring Data JPA系列3：JPA项目中核心场景与进阶用法介绍</a>》</li><li>可靠保障 —— 《<a href="https://mp.weixin.qq.com/s/snjSn0hvG4ARA1vUP_UjNw">Spring Data JPA系列4：Spring声明式事务处理与多数据源支持</a>》</li><li>周边扩展 —— 《<a href="https://mp.weixin.qq.com/s/kexKHZ8jiB1Nr99iaz1eTw">Spring Data JPA系列5：让IDEA自动帮你写JPA实体定义代码</a>》</li></ul></blockquote><hr><p><strong>我是悟道，聊技术、又不仅仅聊技术~</strong></p><p>如果觉得有用，请点个关注，也可以关注下我的公众号【架构悟道】，获取更及时的更新。</p><p>期待与你一起探讨，一起成长为更好的自己。</p><p><img src="https://pics.codingcoder.cn/pics/202207091312656.gif"></p>]]></content>
      
      
      <categories>
          
          <category> Spring Data JPA系列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spring Data JPA </tag>
            
            <tag> JAVA </tag>
            
            <tag> IDEA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spring Data JPA系列4：Spring声明式事务处理与多数据源支持</title>
      <link href="//post/20220625213411.html"/>
      <url>//post/20220625213411.html</url>
      
        <content type="html"><![CDATA[<p><img src="https://pics.codingcoder.cn/pics/202206172105608.png"></p><p><img src="https://pics.codingcoder.cn/pics/202206251959155.png"></p><p>大家好，又见面了。</p><p>到这里呢，已经是本<code>SpringData JPA</code>系列文档的第四篇了，先来回顾下前面三篇：</p><ul><li><p>在第1篇《<a href="https://mp.weixin.qq.com/s/qQR8z3OhwiTxybmEwMME9A">Spring Data JPA系列1：JDBC、ORM、JPA、Spring Data JPA，傻傻分不清楚？给你个选择SpringDataJPA的理由！</a>》中，我们对JPA的整体概念有了全面的了解。</p></li><li><p>在第2篇《<a href="https://mp.weixin.qq.com/s/aUo2HmGI0MO-Nm57TBLUgQ">Spring Data JPA系列2：快速在SpringBoot项目中熟练使用JPA</a>》中也知晓了SpringBoot项目快速集成SpringData JPA以及快速上手使用JPA来进行基本的项目开发的技能。</p></li><li><p>在第3篇《<a href="https://mp.weixin.qq.com/s/NS156Z9aa4mUMbx79-7Z8w">Spring Data JPA系列3：JPA项目中核心场景与进阶用法介绍</a>》进一步的聊一下项目中使用JPA的一些高阶复杂场景的实践指导，覆盖了主要核心的JPA使用场景。</p></li></ul><p>本篇在前面几篇的基础上，再来聊一下数据库相关操作经常会涉及的事务问题与多数据源支持问题。</p><p>在大部分涉及到数据库操作的项目里面，事务控制、事务处理都是一个无法回避的问题。得益于Spring框架的封装，业务代码中进行事务控制操作起来也很简单，直接加个@Transactional注解即可，大大简化了对业务代码的侵入性。那么对@Transactional事务注解了解的够全面吗？知道有哪些场景可能会导致@Transactional注解并不会如你预期的方式生效吗？知道应该怎么使用@Transactional才能保证对性能的影响最小化吗？</p><p>下面我们一起探讨下这些问题。</p><h2 id="先看下JDBC的事务处理"><a href="#先看下JDBC的事务处理" class="headerlink" title="先看下JDBC的事务处理"></a>先看下JDBC的事务处理</h2><p>基于JDBC进行数据库操作的时候，如果需要进行事务的控制与处理，整体的一个处理流程如下图所示：</p><p><img src="https://pics.codingcoder.cn/pics/202206162112637.png"></p><p>其中蓝色的部分为需要开发人员去进行实现的，也即JDBC场景下的事务保护与处理，整个事务过程的处理都是需要开发人员进行关注与处理的。</p><p>按照这个流程的逻辑，写一下对应的实现代码：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public void testJdbcTransactional(DataSource dataSource) &#123;    Connection conn &#x3D; null;    int result &#x3D; 0;    try &#123;        &#x2F;&#x2F; 获取链接        conn &#x3D; dataSource.getConnection();        &#x2F;&#x2F; 禁用自动事务提交，改为手动控制        conn.setAutoCommit(false);        &#x2F;&#x2F; 设置事务隔离级别        conn.setTransactionIsolation(            TransactionIoslationLevel.READ_COMMITTED.getLevel()        );        &#x2F;&#x2F; 执行SQL        PreparedStatement ps &#x3D;             conn.prepareStatement(&quot;insert into user (id, name) values (?, ?)&quot;);        ps.setString(1, &quot;123456&quot;);        ps.setString(2, &quot;Tom&quot;);        result &#x3D; ps.executeUpdate();        &#x2F;&#x2F; 执行成功，手动提交事务        conn.commit();    &#125; catch (Exception e) &#123;        &#x2F;&#x2F; 出现异常，手动回滚事务        if (conn !&#x3D; null) &#123;            try &#123;                conn.rollback();            &#125; catch (Exception e) &#123;                &#x2F;&#x2F; write log...            &#125;        &#125;    &#125; finally &#123;        &#x2F;&#x2F; 执行结束，最终不管成功还是失败，都要释放资源，断开连接        try &#123;            if (conn !&#x3D; null &amp;&amp; !conn.isClosed()) &#123;                conn.close();            &#125;        &#125; catch (Exception e) &#123;             &#x2F;&#x2F; write log...        &#125;    &#125;&#125;</code></pre><h2 id="Spring声明式事务处理机制"><a href="#Spring声明式事务处理机制" class="headerlink" title="Spring声明式事务处理机制"></a>Spring声明式事务处理机制</h2><p>Spring数据库事务约定处理逻辑流程如下：</p><p><img src="https://pics.codingcoder.cn/pics/202206162109156.png"></p><p>对比上一章节的JDBC的事务处理，Spring场景下，事务的处理操作交给了Spring框架处理，开发人员仅需要实现自己的业务逻辑即可，大大简化了事务方面的处理投入。</p><p>基于Spring事务机制，实现上述DB操作事务控制的代码，可以按照如下方式：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">@Transactionalpublic void insertUser() &#123;    userDao.insertUser();&#125;</code></pre><p>与JDBC事务实现代码相比，基于Spring的方式只需要添加一个@Transactional注解即可，代码中只需要实现业务逻辑即可，实现了事务控制机制对业务代码的低侵入性。</p><p>Spring支持的基于Spring AOP实现的声明式事务功能，所谓声明式事务，即使用@Transactional注解进行声明标注，告诉Spring框架在什么地方启用数据库事务控制能力。@Transactional注解，可以添加在类或者方法上。如果其添加在类上时，表明此类中所有的public非静态方法都将启用事务控制能力。</p><h2 id="Transactional注解说明"><a href="#Transactional注解说明" class="headerlink" title="@Transactional注解说明"></a>@Transactional注解说明</h2><p><img src="https://pics.codingcoder.cn/pics/202206252028747.png"></p><h3 id="主要可选配置"><a href="#主要可选配置" class="headerlink" title="主要可选配置"></a>主要可选配置</h3><h4 id="readOnly"><a href="#readOnly" class="headerlink" title="readOnly"></a>readOnly</h4><p>指定当前事务是否为一个只读事务。设置为true标识此事务是个只读事务，默认情况为false。</p><p><strong>只读事务</strong><br>在多条查询语句一起执行的场景里面会涉及到的概念。表示在事务设置的那一刻开始，到整个事务执行结束的过程中，其他事务所提交的写操作数据，对该事务都不可见。</p><p>举个例子：<br>现在有一个复合查询操作，包含2条SQL查询操作：先获取用户表count数，再获取用户表中所有数据。<br>执行过程：</p><blockquote><p>(1) 先执行完获取用户表count数，得到结果10<br>(2) 在还没开始执行后一条语句的时候，另一个进程操作了DB并往用户表中插入一条新数据<br>(3) 复合操作的第二条SQL语句，获取用户列表的操作被执行，返回了11条记录</p></blockquote><p>很明显，复合操作中的两条SQL语句获取的数据结果无法匹配上。</p><p>为了避免此情况的发生，可以给复合查询操作添加上只读事务，这样事务控制范围内，事务外的写操作就不可见，这样就保证了事务内多条查询语句执行结果的一致性。</p><p><img src="https://pics.codingcoder.cn/pics/202206171429654.png"></p><p>那为什么要设置为只读事务、而不是常规的事务呢？<br>主要是从执行效率角度的考虑。因为这个里的操作都是一些只读操作，所以设置为只读事务，数据库会为只读事务提供一些优化手段，比如不启动回滚段、不记录回滚log之类的。</p><h4 id="rollbackFor-amp-rollbackForClassName"><a href="#rollbackFor-amp-rollbackForClassName" class="headerlink" title="rollbackFor &amp; rollbackForClassName"></a>rollbackFor &amp; rollbackForClassName</h4><p>用于指定需要回滚的特定异常类型，可以指定一个或者多个。当指定rollbackFor或者rollbackForClassName之后，方法执行逻辑中只有抛出指定的异常类型，才会触发事务回滚。</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">&#x2F;&#x2F; 指定单个异常@Transactional(rollbackFor &#x3D; DemoException.class)public void insertUser() &#123;    &#x2F;&#x2F; do something here&#125;&#x2F;&#x2F; 指定多个异常@Transactional(rollbackFor &#x3D; &#123;DemoException.class, DemoException2.class&#125;)public void insertUser2() &#123;    &#x2F;&#x2F; do something here&#125;</code></pre><p>rollbackFor和rollbackForClassName作用相同，只是提供了2个不同的指定方法，允许执行Class类型或者ClassName字符串。</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">&#x2F;&#x2F; 指定异常名称@Transactional(rollbackForClassName &#x3D; &#123;&quot;DemoException&quot;&#125;)public void insertUser() &#123;    &#x2F;&#x2F; do something here&#125;</code></pre><h4 id="noRollbackFor-amp-noRollbackForClassName"><a href="#noRollbackFor-amp-noRollbackForClassName" class="headerlink" title="noRollbackFor &amp; noRollbackForClassName"></a>noRollbackFor &amp; noRollbackForClassName</h4><p>用于指定不需要进行回滚的异常类型，当方法中抛出指定类型的异常时，不进行事务回滚。</p><h4 id="timeout"><a href="#timeout" class="headerlink" title="timeout"></a>timeout</h4><p>用于设置事务的超时秒数，默认值为-1，表示永不超时。</p><h4 id="propagation"><a href="#propagation" class="headerlink" title="propagation"></a>propagation</h4><p>用于指定此事务对应的传播类型。所谓的事务传播类型，即当前已经在一个事务的上下文中时，又需要开始一个事务，这个时候来处理这个将要开启的新事务的处理策略。</p><p>主要有7种类型的事务传播类型：</p><blockquote><ul><li>REQUIRED：如果当前存在事务，则加入该事务；如果当前没有事务，则创建一个新的事务。</li><li>SUPPORTS：如果当前存在事务，则加入该事务；如果当前没有事务，则以非事务的方式继续运行。</li><li>MANDATORY：如果当前存在事务，则加入该事务；如果当前没有事务，则抛出异常。</li><li>REQUIRES_NEW：创建一个新的事务，如果当前存在事务，则把当前事务挂起。</li><li>NOT_SUPPORTED：以非事务方式运行，如果当前存在事务，则把当前事务挂起。</li><li>NEVER：以非事务方式运行，如果当前存在事务，则抛出异常。</li><li>NESTED：如果当前存在事务，则创建一个事务作为当前事务的嵌套事务来运行；如果当前没有事务，则该取值等价于REQUIRED。</li></ul></blockquote><p>实际编码的时候，可以通过@Transactional注解中的<code>propagation</code>参数来指定具体的传播类型，取值由<code>org.springframework.transaction.annotation.Propagation</code>枚举类提供。如果不指定，则默认取值为<code>Propagation.REQUIRED</code>，也即如果当前存在事务，则加入该事务，如果当前没有事务，则创建一个新的事务。</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">&#x2F;** * The transaction propagation type. * &lt;p&gt;Defaults to &#123;@link Propagation#REQUIRED&#125;. * @see org.springframework.transaction.interceptor.TransactionAttribute#getPropagationBehavior() *&#x2F;Propagation propagation() default Propagation.REQUIRED;    </code></pre><h3 id="Transactional失效场景避坑"><a href="#Transactional失效场景避坑" class="headerlink" title="@Transactional失效场景避坑"></a>@Transactional失效场景避坑</h3><p><img src="https://pics.codingcoder.cn/pics/202206252042392.png"></p><h4 id="同一个类中方法间调用"><a href="#同一个类中方法间调用" class="headerlink" title="同一个类中方法间调用"></a>同一个类中方法间调用</h4><p>Spring的事务实现原理是AOP，而AOP的原理是动态代理。</p><p>在类内部方法之间相互调用的时候，本质上是类对象自身的调用，而不是使用代理对象去调用，也就不会触发AOP，这样其实Spring也就无法将事务控制的代码逻辑织入到调用代码流程中，所以这里的事务控制就无法生效。</p><p>所以遇到同一个类中多个方法之间相互调用，且调用的方法需要做事务控制的时候需要特别注意下这个问题。解决方式，可以建2个不同的类，然后将方法放到两个类中，这样跨类调用，Spring事务机制就可以生效。</p><h4 id="添加在非public方法上"><a href="#添加在非public方法上" class="headerlink" title="添加在非public方法上"></a>添加在非public方法上</h4><p>如果将@Transactional注解添加在protected、private修饰的方法上，虽然代码不会有任何的报错，但是实际上注解是不会生效的。</p><h4 id="方法内部Try-Catch吞掉相关异常"><a href="#方法内部Try-Catch吞掉相关异常" class="headerlink" title="方法内部Try Catch吞掉相关异常"></a>方法内部Try Catch吞掉相关异常</h4><p>这个其实很容易理解，业务代码中将所有的异常给catch并吞掉了，等同于业务代码认为被捕获的异常不需要去触发回滚。对框架而言，因为异常被捕获了，业务逻辑执行都在正常往下运行，所以也不会触发异常回滚机制。</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">&#x2F;&#x2F; catch了可能的异常，导致DB操作失败的时候事务不会触发回滚@Transactionalpublic void insertUser() &#123;    try &#123;        &#x2F;&#x2F; do something here...        userRepository.save(user);    &#125; catch (Exception e) &#123;        log.error(&quot;failed to create user&quot;);        &#x2F;&#x2F; 直接吞掉了异常，这样不会触发事务回滚机制    &#125;&#125;</code></pre><p>在业务处理逻辑中，如果确实需要知晓并捕获相关处理的异常进行一些额外的业务逻辑处理，如果要保证事务回滚机制生效，最后需要往外抛出RuntimeException异常，或者是继承RuntimeException实现的业务自定义异常。如下：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">&#x2F;&#x2F; catch了可能的异常，对外抛出RuntimeException或者其子类,可触发事务回滚@Transactionalpublic void insertUser() &#123;    try &#123;        &#x2F;&#x2F; do something here...        userRepository.save(user);    &#125; catch (Exception e) &#123;        log.error(&quot;failed to create user&quot;);        &#x2F;&#x2F; @Transactional没有指定rollbackFor，所以抛出RuntimeException或者其子类，可触发事务回滚机制        throw new RuntimeException(e);    &#125;&#125;</code></pre><p>当然，如果@Transactional注解指定了rollbackFor为某个具体的异常类型，则最终需要保证异常时对外抛出相匹配的异常类型，才可以触发事务处理逻辑。如下：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">&#x2F;&#x2F; catch了指定异常，对外抛出对应类型的异常,可触发事务回滚@Transactional(rollbackFor &#x3D; DemoException.class)public void insertUser() &#123;    try &#123;        &#x2F;&#x2F; do something here...        userRepository.save(user);    &#125; catch (Exception e) &#123;        log.error(&quot;failed to create user&quot;);        &#x2F;&#x2F; @Transactional有指定rollbackFor，抛出异常要与rollbackFor指定异常类型一致        throw new DemoException();    &#125;&#125;</code></pre><h4 id="对应数据库引擎类型不支持事务"><a href="#对应数据库引擎类型不支持事务" class="headerlink" title="对应数据库引擎类型不支持事务"></a>对应数据库引擎类型不支持事务</h4><p>以MySQL数据库而言，常见的数据库引擎有InnoDB和Myisam等类型，但是MYISAM引擎类型是不支持事务的。所以如果建表时设置的引擎类型设置为MYISAM的话，即使代码里面添加了@Transactional最终事务也不会生效的。</p><h3 id="Transactional使用策略"><a href="#Transactional使用策略" class="headerlink" title="@Transactional使用策略"></a>@Transactional使用策略</h3><p><img src="https://pics.codingcoder.cn/pics/202206252035966.png"></p><p>因为事务处理对性能会有一定的影响，所以事务也不是说任何地方都可以随便添加的。对于一些性能敏感场景，需要注意几点：</p><ol><li>仅在必要的场合添加事务控制</li></ol><blockquote><p>（1）不含有DB操作相关，无需添加事务控制<br>（2）单条查询语句，没必要添加事务控制<br>（3）仅有查询操作的多条SQL执行场景，可以添加只读事务控制<br>（4）单条insert&#x2F;update&#x2F;delete语句，其实也不需要添加@Transactional事务处理，因为单条语句执行其实数据库有隐性事务控制机制，如果执行失败，是属于SQL报错，数据不会更新成功，自然也无需回滚。</p></blockquote><ol start="2"><li>尽可能缩小事务控制的代码段处理范围</li></ol><blockquote><p>主要从性能层面考虑，事务机制，类似于并发场景的加锁处理，范围越大对性能影响越明显</p></blockquote><ol start="3"><li>事务控制范围内的业务逻辑尽可能简单、避免非事务相关耗时处理逻辑</li></ol><blockquote><p>也是从性能层面考虑，尽量将耗时的逻辑放到事务控制之外执行，事务内仅保留与DB操作切实相关的逻辑</p></blockquote><h2 id="DataSource数据源配置"><a href="#DataSource数据源配置" class="headerlink" title="DataSource数据源配置"></a>DataSource数据源配置</h2><p><img src="https://pics.codingcoder.cn/pics/202206252048416.png"></p><h3 id="DataSource整体情况"><a href="#DataSource整体情况" class="headerlink" title="DataSource整体情况"></a>DataSource整体情况</h3><p>SpringBoot为DataSource提供了两种最为常见的默认配置：</p><ul><li>面向TomcatT的JDBC</li><li>面向Apache的DBCP</li></ul><p>至于具体使用哪一个，主要是看项目pom.xml中引入了哪个jar了。<br>对于使用SpringBoot默认配置的项目而言，SpringBoot默认使用的是Tomcat容器，所以默认情况也是使用的Tomcat的JDBC的DataSource及其连接池。</p><p>看一下配置数据加载类DataSourceProperties的写法：</p><p><img src="https://pics.codingcoder.cn/pics/202206221406624.png"></p><p>所以我们的数据源配置信息，相关配置项需要以<code>spring.datasource</code>开头，如下：</p><pre class="line-numbers language-properties" data-language="properties"><code class="language-properties">spring.datasource.url&#x3D;jdbc:mysql:&#x2F;&#x2F;&lt;ip&gt;:&lt;port&gt;&#x2F;vzn-demo?useUnicode&#x3D;true&amp;characterEncoding&#x3D;UTF-8&amp;rewriteBatchedStatements&#x3D;true&amp;serverTimezone&#x3D;Asia&#x2F;Shanghaispring.datasource.username&#x3D;vzn-demospring.datasource.password&#x3D;&lt;password&gt;</code></pre><p>除了SpringBoot自带的DataSource类型，还有一些其他三方提供的DataSource。项目开发工作中比较常用的有AliDruid DataSource，这里也介绍下。</p><ul><li>pom.xml中需要引入相关依赖</li></ul><pre class="line-numbers language-markup" data-language="markup"><code class="language-markup">&lt;dependency&gt;    &lt;groupId&gt;com.alibaba&lt;&#x2F;groupId&gt;    &lt;artifactId&gt;druid-spring-boot-starter&lt;&#x2F;artifactId&gt;    &lt;version&gt;1.1.22&lt;&#x2F;version&gt;&lt;&#x2F;dependency&gt;</code></pre><ul><li>application.properties中增加连接信息配置</li></ul><pre class="line-numbers language-properties" data-language="properties"><code class="language-properties"># 数据库连接信息spring.datasource.druid.url&#x3D;jdbc:mysql:&#x2F;&#x2F;&lt;ip&gt;:&lt;port&gt;&#x2F;&lt;db-name&gt;?useUnicode&#x3D;true&amp;characterEncoding&#x3D;UTF-8&amp;rewriteBatchedStatements&#x3D;true&amp;serverTimezone&#x3D;Asia&#x2F;Shanghaispring.datasource.druid.username&#x3D;&lt;userName&gt;# 可以设置配置的密码是否加密spring.datasource.druid.connect-properties.config.decrypt&#x3D;falsespring.datasource.druid.password&#x3D;&lt;password&gt;</code></pre><h3 id="配置多数据源"><a href="#配置多数据源" class="headerlink" title="配置多数据源"></a>配置多数据源</h3><p>在大型的项目中，可能会涉及到服务需要同时连接多个数据库进行数据操作的场景，这里就会涉及到多个DataSource的配置。</p><p>举个例子，现在有一个社交论坛服务，其发帖（Post）和评论（Comment）分别对应两个DB，使用AliDruidDataSource的情况下，应该如何配置呢？</p><ul><li>首先配置application.properties</li></ul><p>前面内容有提过，所有的数据源相关配置项需要以<code>spring.datasource</code>开头。而我们使用AliDruid进行多个数据源的配置时，我们需要设定各个数据源的若干配置都以<code>spring.datasource.druid.&#123;xxx&#125;</code>开头。比如本例中，我们可以对发帖DB、评论DB两个数据源约定前缀分别为<code>spring.datasource.druid.post</code>以及<code>spring.datasource.druid.comment</code>。</p><p>在application.properties中配置两个数据源的信息：</p><pre class="line-numbers language-properties" data-language="properties"><code class="language-properties"># Post数据源信息spring.datasource.druid.post.url&#x3D;jdbc:mysql:&#x2F;&#x2F;&lt;ip&gt;:&lt;port&gt;&#x2F;&lt;db-name&gt;?useUnicode&#x3D;true&amp;characterEncoding&#x3D;UTF-8&amp;rewriteBatchedStatements&#x3D;true&amp;serverTimezone&#x3D;Asia&#x2F;Shanghaispring.datasource.druid.post.username&#x3D;&lt;userName&gt;spring.datasource.druid.post.connect-properties.config.decrypt&#x3D;falsespring.datasource.druid.post.password&#x3D;&lt;password&gt;# Comment数据源信息spring.datasource.druid.comment.url&#x3D;jdbc:mysql:&#x2F;&#x2F;&lt;ip&gt;:&lt;port&gt;&#x2F;&lt;db-name&gt;?useUnicode&#x3D;true&amp;characterEncoding&#x3D;UTF-8&amp;rewriteBatchedStatements&#x3D;true&amp;serverTimezone&#x3D;Asia&#x2F;Shanghaispring.datasource.druid.comment.username&#x3D;&lt;userName&gt;spring.datasource.druid.comment.connect-properties.config.decrypt&#x3D;falsespring.datasource.druid.comment.password&#x3D;&lt;password&gt;</code></pre><ul><li>其次自定义实现两个DataSourceConfig类</li></ul><p>接前面的例子，在application.properties中配置了两个数据源之后，需要实现两个JAVA类用于读取配置并做相关的配置处理。</p><p>针对Post数据源：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">@Configuration@EnableTransactionManagement@EnableConfigurationProperties(JpaProperties.class)@EnableJpaRepositories(        entityManagerFactoryRef&#x3D;&quot;entityManagerFactoryPost&quot;,        transactionManagerRef&#x3D;&quot;transactionManagerPost&quot;,         basePackages &#x3D; &#123;&quot;com.vzn.demo.post.repository&quot;&#125; &#x2F;&#x2F; 设置哪些package下面的repository使用此数据源)public class DataSourcePostConfig &#123;    @Primary    @Bean    @ConfigurationProperties(&quot;spring.datasource.druid.post&quot;)    public DataSource dataSourcePost() &#123;        return DruidDataSourceBuilder.create().build();    &#125;    @Autowired    private DataSource dataSourcePost;    @Primary    @Bean    public LocalContainerEntityManagerFactoryBean entityManagerFactoryPost(EntityManagerFactoryBuilder builder) &#123;        return builder            .dataSource(dataSourcePost)            .packages(&quot;com.vzn.demo.post.entity&quot;) &#x2F;&#x2F; 设置哪些package下面的实体使用此数据源            .build();    &#125;    @Primary    @Bean    public EntityManager entityManagerPost(EntityManagerFactoryBuilder builder) &#123;        return entityManagerFactoryPost(builder).getObject().createEntityManager();    &#125;    @Autowired    private JpaProperties jpaProperties;        @Primary    @Bean    public PlatformTransactionManager transactionManagerPost(EntityManagerFactoryBuilder builder) &#123;        return new JpaTransactionManager(entityManagerFactoryPost(builder).getObject());    &#125;&#125;</code></pre><p>针对Comment数据源：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">@Configuration@EnableTransactionManagement@EnableConfigurationProperties(JpaProperties.class)@EnableJpaRepositories(        entityManagerFactoryRef&#x3D;&quot;entityManagerFactoryComment&quot;,        transactionManagerRef&#x3D;&quot;transactionManagerComment&quot;,         basePackages &#x3D; &#123;&quot;com.vzn.demo.comment.repository&quot;&#125; &#x2F;&#x2F; 设置哪些package下面的repository使用此数据源)public class DataSourceCommentConfig &#123;    @Primary    @Bean    @ConfigurationProperties(&quot;spring.datasource.druid.comment&quot;)    public DataSource dataSourceComment() &#123;        return DruidDataSourceBuilder.create().build();    &#125;    @Autowired    private DataSource dataSourceComment;    @Primary    @Bean    public LocalContainerEntityManagerFactoryBean entityManagerFactoryComment(EntityManagerFactoryBuilder builder) &#123;        return builder            .dataSource(dataSourceComment)            .packages(&quot;com.vzn.demo.comment.entity&quot;) &#x2F;&#x2F; 设置哪些package下面的实体使用此数据源            .build();    &#125;    @Primary    @Bean    public EntityManager entityManagerComment(EntityManagerFactoryBuilder builder) &#123;        return entityManagerFactoryComment(builder).getObject().createEntityManager();    &#125;    @Autowired    private JpaProperties jpaProperties;        @Primary    @Bean    public PlatformTransactionManager transactionManagerPost(EntityManagerFactoryBuilder builder) &#123;        return new JpaTransactionManager(entityManagerFactoryPost(builder).getObject());    &#125;&#125;</code></pre><p>上述数据源配置类中，有指定了不同package下面的代码，使用对应不同的DataSource，所以具体使用的时候与正常情况无异，按照约定将不同数据源对应处理DAO类放到各自指定的package下即可，service层代码可以按照正常逻辑调用，无需感知DAO层的数据源差异。当然，如果某些例外场景下，可以通过<code>@Transactional(rollbackFor = Exception.class, transactionManager= &quot;transactionManagerPost&quot;)</code>这种方式显式的指定要使用某个具体数据源。</p><p>虽然，对于多数据源有明确的处理与支持手段，但是多数据源加剧了代码维护的难度与开发过程中的复杂度，所以笔者认为代码架构层面需要多一些思考与优化，可以通过微服务化拆分的方式来尽量避免出现多数据源的场景。</p><h2 id="小结，承上启下"><a href="#小结，承上启下" class="headerlink" title="小结，承上启下"></a>小结，承上启下</h2><p>好啦，本篇内容就介绍到这里。</p><p>通过本篇的内容，我们对Spring项目里面的数据库事务处理相关的概念有了一个相对全面的了解，也知道了一些可能导致Spring事务失效的因素。</p><p>通过前面的系列文档，我们一起对SpringData JPA从浅入深的进行了全方位的探讨。正所谓“工欲善其事、必先利其器”，面对一个优秀的框架，如果再结合一些外部的工具，其实可以让我们的开发效率与程序员开发过程的体验更上一层楼的。在下一篇文档里，我们将一起聊聊如何利用工具来让我们的开发过程进一步的简化。</p><p>如果对本文有自己的见解，或者有任何的疑问或建议，都可以留言，我们一起探讨、共同进步。</p><hr><blockquote><p><strong>补充</strong></p><p><code>Spring Data JPA</code>作为<code>Spring Data</code>中对于关系型数据库支持的一种框架技术，属于<code>ORM</code>的一种，通过得当的使用，可以大大简化开发过程中对于数据操作的复杂度。</p><p>本文档隶属于《<code>Spring Data JPA</code>用法与技能探究》系列的第4篇。本系列文档规划对<code>Spring Data JPA</code>进行全方位的使用介绍，一共分为<strong>5篇</strong>文档，如果感兴趣，欢迎关注交流。</p><p>《Spring Data JPA用法与技能探究》系列涵盖内容：</p><ul><li>开篇介绍 —— 《<a href="https://mp.weixin.qq.com/s/qQR8z3OhwiTxybmEwMME9A">Spring Data JPA系列1：JDBC、ORM、JPA、Spring Data JPA，傻傻分不清楚？给你个选择SpringDataJPA的理由！</a>》</li><li>快速上手 —— 《<a href="https://mp.weixin.qq.com/s/aUo2HmGI0MO-Nm57TBLUgQ">Spring Data JPA系列2：SpringBoot集成JPA详细教程，快速在项目中熟练使用JPA</a>》</li><li>深度进阶 —— 《<a href="https://mp.weixin.qq.com/s/NS156Z9aa4mUMbx79-7Z8w">Spring Data JPA系列3：JPA项目中核心场景与进阶用法介绍</a>》</li><li>可靠保障 —— 《Spring Data JPA系列4——Spring声明式事务处理与多数据源支持》</li><li>周边扩展 —— 《JPA开发辅助效率提升方案介绍》</li></ul></blockquote><hr><p><strong>我是悟道，聊技术、又不仅仅聊技术~</strong></p><p>如果觉得有用，请点个关注，也可以关注下我的公众号【架构悟道】，获取更及时的更新。</p><p>期待与你一起探讨，一起成长为更好的自己。</p><p><img src="https://pics.codingcoder.cn/pics/202207091312656.gif"></p>]]></content>
      
      
      <categories>
          
          <category> Spring Data JPA系列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spring Data JPA </tag>
            
            <tag> JAVA </tag>
            
            <tag> Spring </tag>
            
            <tag> 事务 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spring Data JPA系列3：JPA项目中核心场景与进阶用法介绍</title>
      <link href="//post/20220624161616.html"/>
      <url>//post/20220624161616.html</url>
      
        <content type="html"><![CDATA[<p><img src="https://pics.codingcoder.cn/pics/202301292149805.png"></p><p>大家好，又见面了。</p><p>到这里呢，已经是本<code>SpringData JPA</code>系列文档的第三篇了，先来回顾下前面两篇：</p><ul><li><p>在第1篇《<a href="https://mp.weixin.qq.com/s/qQR8z3OhwiTxybmEwMME9A">Spring Data JPA系列1：JDBC、ORM、JPA、Spring Data JPA，傻傻分不清楚？给你个选择SpringDataJPA的理由！</a>》中，我们对JPA的整体概念有了全面的了解。</p></li><li><p>在第2篇《<a href="https://mp.weixin.qq.com/s/aUo2HmGI0MO-Nm57TBLUgQ">Spring Data JPA系列2：快速在SpringBoot项目中熟练使用JPA</a>》中也知晓了SpringBoot项目快速集成SpringData JPA以及快速上手使用JPA来进行基本的项目开发的技能。</p></li></ul><p>本篇内容将在上一篇已有的内容基础上，进一步的聊一下项目中使用JPA的一些高阶复杂场景的实践指导，覆盖了主要核心的JPA使用场景，可以让你在需求开发的时候对JPA的使用更加的游刃有余。</p><h2 id="Repository"><a href="#Repository" class="headerlink" title="Repository"></a>Repository</h2><p>上一篇文档中，我们知道业务代码中直接调用<code>Repository</code>层中默认提供的方法或者是自己自定义的接口方法，便可以进行DB的相关操作。这里我们再对repository的整体实现情况进一步探索下。</p><h3 id="repository全貌梳理"><a href="#repository全貌梳理" class="headerlink" title="repository全貌梳理"></a>repository全貌梳理</h3><p>先看下Repository相关的类图：</p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/c800b97762af4754acd2e09442097a7f~tplv-k3u1fbpfcp-zoom-1.image"></p><p>整体类图虽然咋看上去很庞杂，但其实主线脉络还是比较清晰的。</p><blockquote><ul><li>先看下蓝色的部分其实就是Repository的一整个接口定义链条，而橙色的则是我们自己自定义的一些Repository接口类，继承父层接口的所有已有能力。</li><li>左侧的类图与接口，其实都是JPA提供的一些用于实现或者定制查询操作的一些辅助实现类，后面章节中会看到他们的身影。</li></ul></blockquote><p>对主体repository层级提供的主要方法进行简单的梳理，如下：</p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/f8f96c7018534c5b8f229b873f5147f8~tplv-k3u1fbpfcp-zoom-1.image"></p><p>下面对各个repository接口进行简单的独立介绍。</p><h3 id="JpaRepository与它的父类们"><a href="#JpaRepository与它的父类们" class="headerlink" title="JpaRepository与它的父类们"></a>JpaRepository与它的父类们</h3><ul><li><code>Repository</code>位于<code>Spring Data Common</code>的lib里面，是Spring Data 里面做数据库操作的最底层的抽象接口、最顶级的父类，源码里面其实什么方法都没有，仅仅起到一个标识作用。</li><li><code>CrudRepository</code>作为直接继承<code>Repository</code>的次顶层接口类，看名字也可以大致猜测出其主要作用就是封装提供基础CRUD操作。</li><li><code>PagingAndSortingRepository</code>继承自<code>CrudRepository</code>，自然也就具备了<code>CrudRepository</code>提供的全部接口能力。此外，从其自身新提供的接口来看，增加了排序和分页查询列表的能力，非常符合其类名的含义。</li></ul><p><code>JpaRepository</code>与其前面的几个父类相比是个特殊的存在，其中补充添加了一组JPA规范的接口方法。前面的几个接口类都是Spring Data为了兼容NoSQL而进行的一些抽象封装（因为SpringData项目是一个庞大的家族，支持各种SQL与NoSQL的数据库，SpringData JPA是SpringData家族中面向SQL数据库的一个子分支项目），从<code>JpaRepository</code>开始是对关系型数据库进行抽象封装。</p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/9c4e4c00c7a64047b819874635b4f7f9~tplv-k3u1fbpfcp-zoom-1.image"></p><p>从类图可以看得出来它继承了<code>PagingAndSortingRepository</code>类，也就继承了其所有方法，并且实现类也是<code>SimpleJpaRepository</code>。从类图上还可以看出<code>JpaRepository</code>继承和拥有了<code>QueryByExampleExecutor</code>的相关方法。</p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/412eab393e7f423294371b538bce1d22~tplv-k3u1fbpfcp-zoom-1.image"></p><p>通过源码和<code>CrudRepository</code>相比较，它支持Query By Example，批量删除，提高删除效率，手动刷新数据库的更改方法，并将默认实现的查询结果变成了List。</p><p>额外补充一句：</p><blockquote><p>实际的项目编码中，大部分的场景中，我们自定义Repository都是继承<code>JpaRepository</code>来实现的。</p></blockquote><h3 id="自定义Repository"><a href="#自定义Repository" class="headerlink" title="自定义Repository"></a>自定义Repository</h3><p>先看个自定义Repository的例子，如下：</p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/bee5dc26d29745ce9000aaca80599021~tplv-k3u1fbpfcp-zoom-1.image"></p><p>看下对应类图结构，自定义Repository继承了JpaRepository，具备了其父系所有的操作接口，此外，额外扩展了业务层面自定义的一些接口方法：</p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/1b7f39b6f19c498e9ceb623a3fe5520b~tplv-k3u1fbpfcp-zoom-1.image"></p><p><code>自定义Repository</code>的时候，继承JpaRepository需要传入两个泛型：</p><ul><li>此Repository需要操作的具体Entity对象（Entity与具体DB中表映射，所以指定Entity也等同于指定了此Repository所对应的目标操作Table），</li><li>此Entity实体的主键数据类型（也就是第一个参数指定的Entity类中以@Id注解标识的字段的类型）</li></ul><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/01d2752a1bf6461daa344823de9c42da~tplv-k3u1fbpfcp-zoom-1.image"></p><h2 id="分页、排序，一招搞定"><a href="#分页、排序，一招搞定" class="headerlink" title="分页、排序，一招搞定"></a>分页、排序，一招搞定</h2><p>分页，排序使用<code>Pageable</code>对象进行传递，其中包含<code>Page</code>和<code>Sort</code>参数对象。</p><p>查询的时候，直接传递<code>Pageable</code>参数即可（注意下，如果是用原生SQL查询的方式，此法行不通，后文有详细说明）。</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">&#x2F;&#x2F; 定义repository接口的时候，直接传入Pageable参数即可List&lt;UserEntity&gt; findAllByDepartment(DepartmentEntity department, Pageable pageable);</code></pre><p>还有一种特殊的分页场景。比如，DB表中有100w条记录，然后现在需要将这些数据全量的加载到ES中。如果逐条查询然后插入ES，显然效率太慢；如果一次性全部查询出来然后直接往ES写，服务端内存可能会爆掉。</p><p>这种场景，其实可以基于<code>Slice</code>结果对象进行实现。Slice的作用是，只知道是否有下一个<code>Slice</code>可用，不会执行count，所以当查询较大的结果集时，只知道数据是足够的就可以了，而且相关的业务场景也不用关心一共有多少页。</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">private &lt;T extends EsDocument, F&gt; void fullLoadToEs(IESLoadService&lt;T, F&gt; esLoadService) &#123;    try &#123;        final int batchHandleSize &#x3D; 10000;        Pageable pageable &#x3D; PageRequest.of(0, batchHandleSize);        do &#123;            &#x2F;&#x2F; 批量加载数据，返回Slice类型结果            Slice&lt;F&gt; entitySilce &#x3D; esLoadService.slicePageQueryData(pageable);            &#x2F;&#x2F; 具体业务处理逻辑            List&lt;T&gt; esDocumentData &#x3D; esLoadService.buildEsDocumentData(entitySilce);            esUtil.batchSaveOrUpdateAsync(esDocumentData);            &#x2F;&#x2F; 获取本次实际上加载到的具体数据量            int pageLoadedCount &#x3D; entitySilce.getNumberOfElements();            if (!entitySilce.hasNext()) &#123;                break;            &#125;            &#x2F;&#x2F; 自动重置page分页参数，继续拉取下一批数据            pageable &#x3D; entitySilce.nextPageable();        &#125; while (true);    &#125; catch (Exception e) &#123;        log.error(&quot;error occurred when load data into es&quot;, e);    &#125;&#125;</code></pre><h2 id="复杂搜索，其实不复杂"><a href="#复杂搜索，其实不复杂" class="headerlink" title="复杂搜索，其实不复杂"></a>复杂搜索，其实不复杂</h2><p>按照条件进行搜索查询，是项目中遇到的非常典型且常用的场景。但是条件搜索也分几种场景，下面分开说下。</p><h3 id="简单固定场景"><a href="#简单固定场景" class="headerlink" title="简单固定场景"></a>简单固定场景</h3><p>所谓简单固定，即查询条件就是固定的1个字段或者若干个字段，且查询字段数量不会变，比如根据部门查询具体人员列表这种。<br>这种情况，我们可以简单的直接在repository中，根据命名规范定义一个接口即可。</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">@Repositorypublic interface UserRepository extends JpaRepository&lt;UserEntity, Long&gt; &#123;    &#x2F;&#x2F; 根据一个固定字段查询    List&lt;UserEntity&gt; findAllByDepartment(DepartmentEntity department);    &#x2F;&#x2F; 根据多个固定字段组合查询    UserEntity findFirstByWorkIdAndUserNameAndDepartment(String workId, String userName, DepartmentEntity department);&#125;</code></pre><h3 id="简单不固定场景"><a href="#简单不固定场景" class="headerlink" title="简单不固定场景"></a>简单不固定场景</h3><p>考虑一种场景，界面上需要做一个用户搜索的能力，要求支持根据用户名、工号、部门、性别、年龄、职务等等若干个字段中的1个或者多个的组合来查询符合条件的用户信息。<br>显然，上述通过直接在repository中按照命名规则定义接口的方式行不通了。这个时候，<code>Example</code>对象便排上用场了。</p><p>其实在前面整体介绍Repository的UML图中，就已经有了<code>Example</code>的身影了，虽然这个名字起的很敷衍，但其功能确是挺实在的。</p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/ba91cb364cfa40abb65cca32ce5e042d~tplv-k3u1fbpfcp-zoom-1.image"></p><p>看下具体用法：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public Page&lt;UserEntity&gt; queryUsers(Request request, UserEntity queryParams) &#123;    &#x2F;&#x2F; 查询条件构造出对应Entity对象，转为Example查询条件    Example&lt;UserEntity&gt; example &#x3D; Example.of(queryParams);    &#x2F;&#x2F; 构造分页参数    Pageable pageable &#x3D; PageHelper.buildPageable(request);        &#x2F;&#x2F; 按照条件查询，并分页返回结果    return userRepository.findAll(example, pageable);&#125;</code></pre><h3 id="复杂场景"><a href="#复杂场景" class="headerlink" title="复杂场景"></a>复杂场景</h3><p>如果是一些自定义的复杂查询场景，可以通过定制SQL语句的方式来实现。</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">@Repositorypublic interface UserRepository extends JpaRepository&lt;UserEntity, Long&gt; &#123;    @Query(        value &#x3D; &quot;select t.*,(select group_concat(a.assigner_name) from workflow_task a where a.state&#x3D;&#39;R&#39; and a.proc_inst_id&#x3D;t.proc_inst_id) deal_person,&quot;            + &quot; (select a.task_name from workflow_task a where a.state&#x3D;&#39;R&#39; and a.proc_inst_id&#x3D;t.proc_inst_id limit 1) cur_step &quot;            + &quot;   from workflow_info t where t.state&#x3D;&#39;R&#39;  and t.type in (?1) &quot;            + &quot;and exists(select 1 from workflow_task b where b.assigner&#x3D;?2 and b.state&#x3D;&#39;R&#39; and b.proc_inst_id&#x3D;t.proc_inst_id) order by t.create_time desc&quot;,        countQuery &#x3D; &quot;select count(1) from workflow_info t where t.state&#x3D;&#39;R&#39;  and t.type in (?1) &quot;            + &quot;and exists(select 1 from workflow_task b where b.assigner&#x3D;?2 and b.state&#x3D;&#39;R&#39; and b.proc_inst_id&#x3D;t.proc_inst_id) &quot;,        nativeQuery &#x3D; true)    Page&lt;FlowResource&gt; queryResource(List&lt;String&gt; type, String workId, Pageable pageable);&#125;</code></pre><p>此外，还可以基于<code>JpaSpecificationExecutor</code>提供的能力接口来实现。<br>自定义接口需要增加<code>JpaSpecificationExecutor</code>的继承，然后利用<code>Page&lt;T&gt; findAll(@Nullable Specification&lt;T&gt; spec, Pageable pageable);</code>接口来实现复杂查询能力。</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">&#x2F;&#x2F; 增加对JpaSpecificationExecutor的继承@Repositorypublic interface UserRepository extends JpaRepository&lt;UserEntity, Long&gt;, JpaSpecificationExecutor&lt;UserEntity&gt; &#123;&#125;</code></pre><pre class="line-numbers language-java" data-language="java"><code class="language-java">public List&lt;UserEntity&gt; queryUsers(QueryParams queryParams) &#123;    &#x2F;&#x2F; 构造Specification查询条件    Specification&lt;UserEntity&gt; specification &#x3D;        (root, query, cb) -&gt; &#123;            List&lt;Predicate&gt; predicates &#x3D; new ArrayList&lt;&gt;();            &#x2F;&#x2F; 范围查询条件构造            predicates.add(cb.greaterThanOrEqualTo(root.get(&quot;age&quot;), queryParams.getMinAge()));            predicates.add(cb.lessThanOrEqualTo(root.get(&quot;age&quot;), queryParams.getMaxAge()));            &#x2F;&#x2F; 精确匹配查询条件构造            predicates.add(cb.equal(root.get(&quot;department&quot;), queryParams.getDepartment()));            &#x2F;&#x2F; 关键字模糊匹配条件构造            if (Objects.nonNull(queryParams.getNameKeyword())) &#123;                predicates.add(cb.like(root.get(&quot;userName&quot;), &quot;%&quot; + queryParams.getNameKeyword() + &quot;%&quot;));            &#125;            return query.where(predicates.toArray(new Predicate[0])).getRestriction();        &#125;;    &#x2F;&#x2F; 执行复杂查询条件    return userRepository.findAll(specification);&#125;</code></pre><h2 id="自定义Listener，玩出花样"><a href="#自定义Listener，玩出花样" class="headerlink" title="自定义Listener，玩出花样"></a>自定义Listener，玩出花样</h2><p>实际项目中，经常会有一种场景，就是需要监听某个数据的变更然后做一些额外的处理逻辑。一种逻辑，是写操作的时候顺便调用下相关业务的处理API，这样会造成业务间耦合加深；优化点的策略是搞个MQ队列，然后在这个写DB操作的同时发个消息到MQ里面，然后一堆的consumer会监听MQ并去做对应的处理逻辑，这样引入个消息队列代价也有点高。</p><p>这个时候，我们可以借助JPA的自定义<code>EntityListener</code>功能来完美解决。通过监听某个Entity表的变更情况，通知或者调用相关其他的业务代码处理，完美实现了与主体业务逻辑的解耦，也无需引入其他组件。</p><p>举个例子：现有一个论坛发帖系统，发帖Post和评论Comment属于两个相对独立又有点关系的数据，现在需要检测当评论变化的时候，需要更新下Post对应记录的评论数字段。下面演示下具体实现。</p><ul><li>首先，定制一个Listener类，并指定Callbacks注解</li></ul><pre class="line-numbers language-java" data-language="java"><code class="language-java">public class CommentCountAuditListener &#123;    &#x2F;**     *  当Comment表有新增数据的操作时，触发此方法的调用     *&#x2F;    @PostPersist    public void postPersist(CommentEntity entity) &#123;        &#x2F;&#x2F; 执行Post表中评论数字段的更新        &#x2F;&#x2F; do something here...    &#125;    &#x2F;**     *  当Comment表有删除数据的操作时，触发此方法的调用     *&#x2F;    @PostRemove    public void postRemove(CommentEntity entity) &#123;        &#x2F;&#x2F; 执行Post表中评论数字段的更新        &#x2F;&#x2F; do something here...    &#125;    &#x2F;**     *  当Comment表有更新数据的操作时，触发此方法的调用     *&#x2F;    @PostUpdate    public void postUpdate(CommentEntity entity) &#123;        &#x2F;&#x2F; 执行Post表中评论数字段的更新        &#x2F;&#x2F; do something here...    &#125;    &#125;</code></pre><ul><li>其次，在评论实体CommentEntity上，加上自定义Listener信息</li></ul><pre class="line-numbers language-java" data-language="java"><code class="language-java">@Entity@Table(&quot;t_comment&quot;)&#x2F;&#x2F; 指定前面定制的Listener@EntityListeners(&#123;CommentCountAuditListener.class&#125;)public class CommentEntity extends AbstractAuditable &#123;    &#x2F;&#x2F; ...&#125;</code></pre><p>这样就搞定了。</p><p>自定义Listener还有个典型的使用场景，就是可以统一的记录DB数据的操作日志。</p><h2 id="定制化SQL，随心所欲"><a href="#定制化SQL，随心所欲" class="headerlink" title="定制化SQL，随心所欲"></a>定制化SQL，随心所欲</h2><p>JPA提供@Query注解，可以实现自定义SQL语句的能力。比如：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">@Query(value &#x3D; &quot;select * from user &quot; +        &quot;where work_id in (?1) &quot; +        &quot;and department_id &#x3D; 0 &quot; +        &quot;order by CREATE_TIME desc &quot;,        nativeQuery &#x3D; true)List&lt;OssFileInfoEntity&gt; queryUsersByWorkIdIn(List&lt;String&gt; workIds);</code></pre><p>如果需要执行写操作SQL的时候，需要额外增加@Modifying注解标识，如下：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">@Modifying@Query(value &#x3D; &quot;insert into user (work_id, user_name) values (?1, ?2)&quot;,        nativeQuery &#x3D; true)int createUser(String workId, String userName);</code></pre><p>其中，<code>nativeQuery = true</code>表示<code>@Query</code>注解中提供的value值为原生SQL语句。如果<code>nativeQuery</code>未设置或者设置为false，则表示将使用<code>JPQL</code>语言来执行。所谓JPQL，即JAVA持久化查询语句，是一种类似SQL的语法，不同点在于其使用类名来替代表名，使用类字段来替代表字段名。比如：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">@Query(&quot;SELECT u FROM com.vzn.demo.UserInfo u WHERE u.userName &#x3D; ?1&quot;)public UserInfo getUserInfoByName(String name);</code></pre><p>几个关注点要特别阐述下：</p><ul><li>like查询的时候，参数前后的<code>%</code>需要手动添加，系统是不会自动加上的</li></ul><pre class="line-numbers language-java" data-language="java"><code class="language-java">&#x2F;&#x2F; like 需要手动添加百分号@Query(&quot;SELECT u FROM com.vzn.demo.UserInfo u WHERE u.userName like %?1&quot;)public UserInfo getUserInfoByName(String name);</code></pre><ul><li>使用<code>nativeQuery=true</code>查询的时候（原生SQL方式），不支持API接口里面传入Sort对象然后进行混合执行</li></ul><pre class="line-numbers language-java" data-language="java"><code class="language-java">&#x2F;&#x2F; 错误示范：  自定义sql与API中Sort参数不可同时混用@Query(&quot;SELECT * FROM t_user u WHERE u.user_name &#x3D; ?1&quot;, nativeQuery&#x3D;true)public UserInfo getUserInfoByName(String name, Sort sort);&#x2F;&#x2F; 正确示范：  自定义SQL完成对应sort操作@Query(&quot;SELECT * FROM t_user u WHERE u.user_name &#x3D; ?1 order by ?2&quot;, nativeQuery&#x3D;true)public UserInfo getUserInfoByName(String name, String sortColumn);</code></pre><ul><li>未指定<code>nativeQuery=true</code>查询的时候(JPQL方式)，支持API接口里面传入<code>Sort</code>、<code>PageRequest</code>等对象然后进行混合执行，来完成排序、分页等操作</li></ul><pre class="line-numbers language-java" data-language="java"><code class="language-java">&#x2F;&#x2F; 正确：自定义jpql与API中Sort参数不可同时混用@Query(&quot;SELECT u FROM com.vzn.demo.UserInfo u WHERE u.userName &#x3D; ?1&quot;)public UserInfo getUserInfoByName(String name, Sort sort);</code></pre><ul><li>支持使用参数名作为<code>@Query</code>查询中的SQL或者JPQL语句的入参，取代参数顺序占位符</li></ul><p>默认情况下，参数是通过顺序绑定在自定义执行语句上的，这样如果API接口传参顺序或者位置改变，极易引起自定义查询传参出问题，为了解决此问题，我们可以使用<code>@Param</code>注解来绑定一个具体的参数名称，然后以参数名称的形式替代位置顺序占位符，这也是比较推荐的一种做法。</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">&#x2F;&#x2F; 默认的顺序位置传参@Query(&quot;SELECT * FROM t_user u WHERE u.user_name &#x3D; ?1 order by ?2&quot;, nativeQuery&#x3D;true)public UserInfo getUserInfoByName(String name, String sortColumn);&#x2F;&#x2F; 使用参数名称传参@Query(&quot;SELECT * FROM t_user u WHERE u.user_name &#x3D; :name order by :sortColumn&quot;, nativeQuery&#x3D;true)public UserInfo getUserInfoByName(@Param(&quot;name&quot;) String name, @Param(&quot;sortColumn&quot;) String sortColumn);</code></pre><h2 id="字段命名映射策略"><a href="#字段命名映射策略" class="headerlink" title="字段命名映射策略"></a>字段命名映射策略</h2><p>一般而言，JAVA的编码规范都要求filed字段命名需要遵循小驼峰命名的规范，比如userName，而DB中column命名的时候，很多人习惯于使用下划线分隔的方式命名，比如<code>user_name</code>这种。这样就涉及到一个映射的策略问题，需要让JPA知道代码里面的userName就对应着DB中的<code>user_name</code>。</p><p>这里就会涉及到对命名映射策略的映射。主要有两种映射配置，下面分别阐述下。</p><ul><li>implicit-strategy</li></ul><p>配置项key值：</p><pre class="line-numbers language-none"><code class="language-none">spring.jpa.hibernate.naming.implicit-strategy&#x3D;xxxxx</code></pre><p>取值说明：</p><table><thead><tr><th>值</th><th>映射规则说明</th></tr></thead><tbody><tr><td>org.hibernate.boot.model.naming.ImplicitNamingStrategyJpaCompliantImp</td><td>默认的命名策略，兼容JPA2.0规范</td></tr><tr><td>org.hibernate.boot.model.naming.ImplicitNamingStrategyLegacyHbmImpl</td><td>兼容老版本Hibernate的命名规范</td></tr><tr><td>org.hibernate.boot.model.naming.ImplicitNamingStrategyComponentPathImpl</td><td>与ImplicitNamingStrategyJpaCompliantImp基本相同</td></tr><tr><td>org.hibernate.boot.model.naming.ImplicitNamingStrategyLegacyJpaImpl</td><td>兼容JPA 1.0规范中的命名规范。</td></tr><tr><td>org.hibernate.boot.model.naming.SpringImplicitNamingStrategy</td><td>继承ImplicitNamingStrategyJpaCompliantImpl，对外键、链表查询、索引如果未定义，都有下划线的处理策略，而table和column名字都默认与字段一样</td></tr></tbody></table><ul><li>physical-strategy</li></ul><p>配置项key值：</p><pre class="line-numbers language-none"><code class="language-none">spring.jpa.hibernate.naming.physical-strategy&#x3D;xxxxx</code></pre><p>取值说明：</p><table><thead><tr><th>值</th><th>映射规则说明</th></tr></thead><tbody><tr><td>org.hibernate.boot.model.naming.PhysicalNamingStrategyStandardImpl</td><td>默认字符串一致映射，不做任何转换处理，比如java类中userName，映射到table中列名也叫userName</td></tr><tr><td>org.springframework.boot.orm.jpa.hibernate.SpringPhysicalNamingStrategy</td><td>java类中filed名称小写字母进行映射到DB表column名称，遇大写字母时转为分隔符”_”命名格式，比如java类中userName字段，映射到DB表column名称叫user_name</td></tr></tbody></table><ul><li>physical-strategy与implicit-strategy</li></ul><p>SpringData JPA只是对JPA规范的二次封装，其底层使用的是<code>Hibernate</code>，所以此处涉及到Hibernate提供的一些处理策略。Hibernate将对象模型映射到关系数据库分为两个步骤：</p><ol><li>从对象模型中确定逻辑名称。逻辑名可以由用户显式指定(使用<code>@Column</code>或<code>@Table</code>),也可以隐式指定。</li><li>将逻辑名称映射到物理名称，也就是数据库中使用的名称。</li></ol><p>这里，<code>implicit-strategy</code>用于第一步隐式指定逻辑名称，而<code>physical-strategy</code>则用于第二步中逻辑名称到物理名称的映射。</p><p>注意：<br>当没有使用<code>@Table</code>和<code>@Column</code>注解时，<code>implicit-strategy</code>配置项才会被使用，即<code>implicit-strategy</code>定义的是一种缺省场景的处理策略；而<code>physical-strategy</code>属于一种高优先级的策略，只要设置就会被执行，而不管是否有<code>@Table</code>和<code>@Column</code>注解。</p><h2 id="小结，承上启下"><a href="#小结，承上启下" class="headerlink" title="小结，承上启下"></a>小结，承上启下</h2><p>好啦，本篇内容就介绍到这里。</p><p>通过本篇的内容，我们对于如何在项目中使用<code>Spring Data JPA</code>来进行一些较为复杂场景的处理方案与策略有了进一步的了解，再结合本系列此前的内容，到此掌握的JPA的相关技能已经足以应付大部分项目开发场景。</p><p>在实际项目中，为了保障数据操作的可靠、避免脏数据的产生，需要在代码中加入对数据库操作的事务控制。在下一篇文档中，我们将一起聊一聊Spring Data JPA业务代码开发中关于数据库事务的控制，以及编码中存在哪些可能会导致事务失效的场景等等。</p><p>如果对本文有自己的见解，或者有任何的疑问或建议，都可以留言，我们一起探讨、共同进步。</p><hr><blockquote><p><strong>补充</strong></p><p><code>Spring Data JPA</code>作为<code>Spring Data</code>中对于关系型数据库支持的一种框架技术，属于<code>ORM</code>的一种，通过得当的使用，可以大大简化开发过程中对于数据操作的复杂度。</p><p>本文档隶属于《<code>Spring Data JPA</code>用法与技能探究》系列的第3篇。本系列文档规划对<code>Spring Data JPA</code>进行全方位的使用介绍，一共分为<strong>5篇</strong>文档，如果感兴趣，欢迎关注交流。</p><p>《Spring Data JPA用法与技能探究》系列涵盖内容：</p><ul><li>开篇介绍 —— 《<a href="https://mp.weixin.qq.com/s/qQR8z3OhwiTxybmEwMME9A">Spring Data JPA系列1：JDBC、ORM、JPA、Spring Data JPA，傻傻分不清楚？给你个选择SpringDataJPA的理由！</a>》</li><li>快速上手 —— 《<a href="https://mp.weixin.qq.com/s/aUo2HmGI0MO-Nm57TBLUgQ">Spring Data JPA系列2：SpringBoot集成JPA详细教程，快速在项目中熟练使用JPA</a>》</li><li>深度进阶 —— 《<a href="https://mp.weixin.qq.com/s/NS156Z9aa4mUMbx79-7Z8w">Spring Data JPA系列3：JPA项目中核心场景与进阶用法介绍</a>》</li><li>可靠保障 —— 《聊一聊数据库的事务，以及Spring体系下对事务的使用》</li><li>周边扩展 —— 《JPA开发辅助效率提升方案介绍》</li></ul></blockquote><hr><p><strong>我是悟道，聊技术、又不仅仅聊技术~</strong></p><p>如果觉得有用，请点个关注，也可以关注下我的公众号【架构悟道】，获取更及时的更新。</p><p>期待与你一起探讨，一起成长为更好的自己。</p><p><img src="https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/ec7dd2aa21d14a9daa6fdc7472ab0051~tplv-k3u1fbpfcp-zoom-1.image"></p>]]></content>
      
      
      <categories>
          
          <category> Spring Data JPA系列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spring Data JPA </tag>
            
            <tag> JAVA </tag>
            
            <tag> Spring </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spring Data JPA系列2：SpringBoot集成JPA详细教程，快速在项目中熟练使用JPA</title>
      <link href="//post/20220623164616.html"/>
      <url>//post/20220623164616.html</url>
      
        <content type="html"><![CDATA[<p><img src="https://pics.codingcoder.cn/pics/202206172113780.png"></p><p>大家好，又见面了。</p><p>这是Spring Data JPA系列的第2篇，在上一篇《<a href="https://mp.weixin.qq.com/s/qQR8z3OhwiTxybmEwMME9A">Spring Data JPA系列1：JDBC、ORM、JPA、Spring Data JPA，傻傻分不清楚？给你个选择SpringDataJPA的理由！</a>》中，我们对JPA的基本概念有了一个整体的了解，也对JAVA中进行DB操作的一些周边框架、概念等有了初步的感知。同时也给出了SpringData JPA与MyBatis的选择判断依据。</p><p>那么，如果你已经决定使用SpringData JPA来作为项目中DB操作的框架，具体应该如何去做呢？</p><p>作为SpringData JPA系列内容的第二篇，此处以SpringBoot项目为基准，讲一下集成SpringData JPA的相关要点，带你快速的上手SpringData JPA，并用实例演示常见的DB操作场景，让你分分钟轻松玩转JPA。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h2 id="SpringBoot集成SpringData-JPA"><a href="#SpringBoot集成SpringData-JPA" class="headerlink" title="SpringBoot集成SpringData JPA"></a>SpringBoot集成SpringData JPA</h2><h3 id="依赖引入"><a href="#依赖引入" class="headerlink" title="依赖引入"></a>依赖引入</h3><p>SpringBoot项目工程，在pom.xml中引入相关依赖包即可：</p><pre class="line-numbers language-markup" data-language="markup"><code class="language-markup">&lt;!-- 数据库相关操作 --&gt;&lt;dependency&gt;    &lt;groupId&gt;org.springframework.boot&lt;&#x2F;groupId&gt;    &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;&#x2F;artifactId&gt;&lt;&#x2F;dependency&gt;&lt;dependency&gt;    &lt;groupId&gt;mysql&lt;&#x2F;groupId&gt;    &lt;artifactId&gt;mysql-connector-java&lt;&#x2F;artifactId&gt;    &lt;scope&gt;runtime&lt;&#x2F;scope&gt;&lt;&#x2F;dependency&gt;</code></pre><h3 id="入口注解"><a href="#入口注解" class="headerlink" title="入口注解"></a>入口注解</h3><p>SpringData JPA提供了部分注解，可以添加在Application入口程序类上方，来满足相关诉求。当然如果没有额外的特殊诉求，则可以什么都不需要加。</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">@SpringBootApplication&#x2F;&#x2F; 可选，指定扫描的表映射实体Entity的目录，如果不指定，会扫描全部目录&#x2F;&#x2F;@EntityScan(&quot;com.veezean.demo.entity&quot;)&#x2F;&#x2F; 可选，指定扫描的表repository目录，如果不指定，会扫描全部目录&#x2F;&#x2F;@EnableJpaRepositories(basePackages &#x3D; &#123;&quot;com.veezean.demo.repository&quot;&#125;)&#x2F;&#x2F; 可选，开启JPA auditing能力，可以自动赋值一些字段，比如创建时间、最后一次修改时间等等@EnableJpaAuditingpublic class Application &#123;    public static void main(String[] args) &#123;        SpringApplication.run(Application.class, args);    &#125;&#125;</code></pre><p>这里<code>@EntityScan</code>和<code>@EnableJpaRepositories</code>被注释掉了，且默认的情况下是不需要添加这个配置的，JPA会自动扫描程序所在包内的所有定义的Entity和Repository对象并加载。但是，某些比较大型的项目里面，我们可能会封装一个common jar作为项目公共依赖，然后再分出若干子项目，每个子项目里面依赖common jar，这个时候如果想要加载common jar里面定义的Entity和Repository，就需要用到这两个注解。</p><h3 id="参数配置"><a href="#参数配置" class="headerlink" title="参数配置"></a>参数配置</h3><p>在application.properties中配置一些数据库连接信息,如下：</p><pre class="line-numbers language-properties" data-language="properties"><code class="language-properties">spring.datasource.url&#x3D;jdbc:mysql:&#x2F;&#x2F;&lt;ip&gt;:&lt;port&gt;&#x2F;vzn-demo?useUnicode&#x3D;true&amp;characterEncoding&#x3D;UTF-8&amp;rewriteBatchedStatements&#x3D;true&amp;serverTimezone&#x3D;Asia&#x2F;Shanghaispring.datasource.username&#x3D;vzn-demospring.datasource.password&#x3D;&lt;password&gt;#Java代码实体字段命名与数据库表结构字段之间的名称映射策略spring.jpa.hibernate.naming.implicit-strategy&#x3D;org.hibernate.boot.model.naming.ImplicitNamingStrategyLegacyJpaImpl#下面配置开启后，会禁止将驼峰转为下划线#spring.jpa.hibernate.naming.physical-strategy&#x3D;org.hibernate.boot.model.naming.PhysicalNamingStrategyStandardImplspring.jpa.open-in-view&#x3D;falsespring.jpa.properties.hibernate.enable_lazy_load_no_trans&#x3D;true# 控制是否可以基于程序中Entity的定义自动创建或者修改DB中表结构spring.jpa.properties.hibernate.hbm2ddl.auto&#x3D;update# 控制是否打印运行时的SQL语句与参数信息spring.jpa.show-sql&#x3D;truespring.datasource.driver-class-name&#x3D;com.mysql.cj.jdbc.Driverspring.datasource.type&#x3D;com.zaxxer.hikari.HikariDataSourcespring.datasource.hikari.minimum-idle&#x3D;10spring.datasource.hikari.maximum-pool-size&#x3D;20spring.datasource.hikari.idle-timeout&#x3D;600000spring.datasource.hikari.max-life-time&#x3D;1800000</code></pre><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h2 id="基础编码实操"><a href="#基础编码实操" class="headerlink" title="基础编码实操"></a>基础编码实操</h2><p>通过前面的几个步骤的操作，便完成了SpringData JPA与项目的集成对接。本章节介绍下在业务代码里面应该如何使用SpringData JPA来完成一些DB交互操作。</p><h3 id="Table对应Entity编写"><a href="#Table对应Entity编写" class="headerlink" title="Table对应Entity编写"></a>Table对应Entity编写</h3><p>编写数据库中Table对应的JAVA实体映射类，并通过相关注解，来描述字段的一些附加约束信息。</p><ul><li>用户表实体</li></ul><pre class="line-numbers language-java" data-language="java"><code class="language-java">@Data@Entity@Table(name &#x3D; &quot;user&quot;)@EntityListeners(value &#x3D; AuditingEntityListener.class)public class UserEntity &#123;    @Id    @GeneratedValue(strategy &#x3D; GenerationType.IDENTITY)    private Long id;    private String workId;    private String userName;    @ManyToOne(optional &#x3D; false)    @JoinColumn(name &#x3D; &quot;department&quot;)    private DepartmentEntity department;    @CreatedDate    private Date createTime;    @LastModifiedDate    private Date updateTime;&#125;</code></pre><ul><li>部门表实体</li></ul><pre class="line-numbers language-java" data-language="java"><code class="language-java">@Data@Entity@Table(name &#x3D; &quot;department&quot;)@EntityListeners(value &#x3D; AuditingEntityListener.class)public class DepartmentEntity &#123;    @Id    @GeneratedValue(strategy &#x3D; GenerationType.IDENTITY)    private Long id;    private String deptName;    @CreatedDate    private Date createTime;    @LastModifiedDate    private Date updateTime;&#125;</code></pre><p>这里可以看到，所谓的Entity，其实也就是一个普通的JAVA数据类，只是与普通的JAVA数据类相比，多了一些注解。没错！SpringData JPA正式通过各种注解，来完成对各个字段的定义与行为约束，以及完成表间关联关系（比如外键）。</p><blockquote><p>常见的一些注解以及含义功能说明，在本文的末尾表格里面进行了梳理，此处不赘述。</p></blockquote><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h3 id="自定义Repository编写"><a href="#自定义Repository编写" class="headerlink" title="自定义Repository编写"></a>自定义Repository编写</h3><p>继承JpaRepository接口提供自定义Repository接口类，在自定义接口类中，添加业务需要的定制化的DB操作接口。这里定制的时候，可以基于SpringData JPA的命名规范进行接口方法的命名即可，无需关注其具体实现，也不需要提供实现类。</p><ul><li>用户repository</li></ul><pre class="line-numbers language-java" data-language="java"><code class="language-java">@Repositorypublic interface UserRepository extends JpaRepository&lt;UserEntity, Long&gt; &#123;    List&lt;UserEntity&gt; findAllByDepartment(DepartmentEntity department);    UserEntity findFirstByWorkId(String workId);    List&lt;UserEntity&gt; findAllByDepartmentInAndUserNameLike(List&lt;DepartmentEntity&gt; departmentIds, String userName);    @Query(value &#x3D; &quot;select * from user where user_name like ?1&quot;, nativeQuery &#x3D; true)    List&lt;UserEntity&gt; fuzzyQueryByName(String userName);&#125;</code></pre><p>上述代码里面，演示了2种自定义接口的策略：</p><ul><li>基于SpringData JPA的命名规范，直接定义接口</li><li>使用自定义的SQL语句进行个性化定制，这种适用于一些需要高度定制化处理的场景</li></ul><blockquote><p>JPA中支持的一些命名关键字与命名示例，参见本文后面梳理的表格。</p></blockquote><h3 id="业务层执行DB操作"><a href="#业务层执行DB操作" class="headerlink" title="业务层执行DB操作"></a>业务层执行DB操作</h3><h4 id="写入数据"><a href="#写入数据" class="headerlink" title="写入数据"></a>写入数据</h4><p>SpringData JPA写操作逻辑很简单，只有一个save方法即可，如果批量写入操作，使用saveAll方法即可。</p><ul><li>会判断ID，如果唯一ID已存在，则按照update逻辑执行；</li><li>如果唯一ID记录不存在，则按照insert逻辑执行。</li></ul><pre class="line-numbers language-java" data-language="java"><code class="language-java">public void testUser() &#123;    DepartmentEntity deptEntity1 &#x3D; new DepartmentEntity();    deptEntity1.setDeptName(&quot;研发部门&quot;);    deptEntity1.setId(1L);    DepartmentEntity deptEntity2 &#x3D; new DepartmentEntity();    deptEntity2.setDeptName(&quot;产品部门&quot;);    deptEntity2.setId(2L);     &#x2F;&#x2F; 写入部门信息    departmentRepository.save(deptEntity1);    departmentRepository.save(deptEntity2);    departmentRepository.flush();       UserEntity entity1 &#x3D; new UserEntity();    entity1.setWorkId(&quot;123456&quot;);    entity1.setDepartment(deptEntity1);    entity1.setUserName(&quot;王小二&quot;);    UserEntity entity2 &#x3D; new UserEntity();    entity2.setWorkId(&quot;234567&quot;);    entity2.setDepartment(deptEntity1);    entity2.setUserName(&quot;王小五&quot;);    UserEntity entity3 &#x3D; new UserEntity();    entity3.setWorkId(&quot;345678&quot;);    entity3.setDepartment(deptEntity1);    entity3.setUserName(&quot;刘大壮&quot;);    UserEntity entity4 &#x3D; new UserEntity();    entity4.setWorkId(&quot;345678&quot;);    entity4.setDepartment(deptEntity2);    entity4.setUserName(&quot;张三&quot;);     &#x2F;&#x2F; 写入用户信息    userRepository.saveAll(Stream.of(entity1, entity2, entity3, entity4).collect(Collectors.toList()));    userRepository.flush();&#125;</code></pre><p>执行调用后，查看数据库，可见数据已经写入DB中：</p><ul><li>Department表</li></ul><p><img src="https://pics.codingcoder.cn/pics/202206141442275.png"></p><ul><li>User表</li></ul><p><img src="https://pics.codingcoder.cn/pics/202206141442342.png"></p><p>从上面可以看出，代码里面其实并没有对create_time和update_time字段进行赋值，但是数据存储到DB的时候，这两个字段被自动赋值了，这个主要是因为开启了自动Audit能力，主要2个地方的代码有关系：</p><pre class="line-numbers language-none"><code class="language-none">1、Application启动类上的注解，开启允许JPA自动Audit能力@EnableJpaAuditing2、Entity类上添加注解@EntityListeners(value &#x3D; AuditingEntityListener.class)3、Entity中具体字段上加上对应注解：@CreatedDateprivate Date createTime;@LastModifiedDateprivate Date updateTime;</code></pre><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h4 id="查询数据"><a href="#查询数据" class="headerlink" title="查询数据"></a>查询数据</h4><p>常见的数据查询操作，代码层面实现调用如下：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">public void testUser() &#123;    DepartmentEntity deptEntity1 &#x3D; new DepartmentEntity();    deptEntity1.setDeptName(&quot;研发部门&quot;);    deptEntity1.setId(1L);    DepartmentEntity deptEntity2 &#x3D; new DepartmentEntity();    deptEntity2.setDeptName(&quot;产品部门&quot;);    deptEntity2.setId(2L);    &#x2F;&#x2F; 获取所有用户列表 --- JPA默认提供的方法    List&lt;UserEntity&gt; userEntities &#x3D; userRepository.findAll();    log.info(&quot;findAll result :&#123;&#125;&quot;, userEntities);    &#x2F;&#x2F; 获取符合条件用户列表 --- 定制方法： 根据部门字段查询符合条件列表    List&lt;UserEntity&gt; userEntitiesInDept &#x3D; userRepository.findAllByDepartment(deptEntity1);    log.info(&quot;findAllByDepartment result count:&#123;&#125;&quot;, userEntitiesInDept);    &#x2F;&#x2F; 获取符合条件用户 --- 定制方法： 根据工号查询用户信息    UserEntity userEntity &#x3D; userRepository.findFirstByWorkId(&quot;123456&quot;);    log.info(&quot;findFirstByWorkId result: &#123;&#125;&quot;, userEntity);    &#x2F;&#x2F; 多条件查询符合条件用户列表 --- 定制方法： 根据部门与名称字段复合查询    List&lt;UserEntity&gt; fuzzyQueryUsers &#x3D; userRepository.findAllByDepartmentInAndUserNameLike(Stream.of(deptEntity1,            deptEntity2).collect(Collectors.toList()),            &quot;王%&quot;);    log.info(&quot;findAllByDepartmentInAndUserNameLike result count: &#123;&#125;&quot;, fuzzyQueryUsers);&#125;</code></pre><p>从上面的演示代码可以看出，SpringData JPA的一个很大的优势，就是Repository层可以简化大部分场景的代码编码事务，遵循一定的方法命名规范，即可实现相关的能力。</p><p>比如：</p><pre class="line-numbers language-none"><code class="language-none">List&lt;UserEntity&gt; findAllByDepartmentInAndUserNameLike(List&lt;DepartmentEntity&gt; departmentIds, String userName);</code></pre><p>看方法名就直接可以知道这个具体的DB操作逻辑：在给定的部门列表里面查询所有名称可以模糊匹配上的人员列表！至于如何去具体实现，这个开发人员无需关注、也不需要去写对应SQL语句！</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h2 id="藏在配置中的小技能"><a href="#藏在配置中的小技能" class="headerlink" title="藏在配置中的小技能"></a>藏在配置中的小技能</h2><p>在前面章节中有介绍集成SpringData JPA涉及到的一些常见配置，此处对其中部分配置的含义与功能进行一个补充介绍。</p><h3 id="控制是否自动基于代码Entity定义自动创建变更数据库表结构"><a href="#控制是否自动基于代码Entity定义自动创建变更数据库表结构" class="headerlink" title="控制是否自动基于代码Entity定义自动创建变更数据库表结构"></a>控制是否自动基于代码Entity定义自动创建变更数据库表结构</h3><pre class="line-numbers language-none"><code class="language-none">spring.jpa.properties.hibernate.hbm2ddl.auto&#x3D;update</code></pre><p>如果设置为update，程序运行之后，会自动在DB中将Table创建出来，并且相关约束条件（比如自增主键、关联外键之类的）也会一并创建并设置上去，如下示意，左侧的代码自动创建出右侧DB中的表结构：</p><p><img src="https://pics.codingcoder.cn/pics/202206141327981.png"></p><p><strong>补充说明</strong>：</p><p>虽然这个功能比较方便，但是强烈建议在生产环境上关闭此功能。因为DB表结构改动变更，对于生产环境而言，是一个非常重大的操作，一旦出问题甚至会影响到实际数据。为了避免造成不可逆的危害，保险起见，还是人工手动操作变更下比较好。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h3 id="控制是否打印相关操作的SQL语句"><a href="#控制是否打印相关操作的SQL语句" class="headerlink" title="控制是否打印相关操作的SQL语句"></a>控制是否打印相关操作的SQL语句</h3><pre class="line-numbers language-none"><code class="language-none">spring.jpa.show-sql&#x3D;true</code></pre><p>如果设置为true，则会在日志中打印每次DB操作所执行的最终SQL语句内容，这个比较适合与开发过程中的问题定位分析，生产环境上建议关闭（影响性能）。</p><p>如果开启后，打印的日志示例如下：</p><pre class="line-numbers language-none"><code class="language-none">2022-06-14 14:30:50.329  INFO 23380 --- [io-48080-exec-3] o.a.c.c.C.[.[localhost].[&#x2F;veezean-demo]  : Initializing Spring DispatcherServlet &#39;dispatcherServlet&#39;2022-06-14 14:30:50.329  INFO 23380 --- [io-48080-exec-3] o.s.web.servlet.DispatcherServlet        : Initializing Servlet &#39;dispatcherServlet&#39;2022-06-14 14:30:50.337  INFO 23380 --- [io-48080-exec-3] o.s.web.servlet.DispatcherServlet        : Completed initialization in 8 msHibernate: insert into department (create_time, dept_name, update_time) values (?, ?, ?)Hibernate: insert into department (create_time, dept_name, update_time) values (?, ?, ?)Hibernate: insert into user (create_time, department, update_time, user_name, work_id) values (?, ?, ?, ?, ?)Hibernate: insert into user (create_time, department, update_time, user_name, work_id) values (?, ?, ?, ?, ?)Hibernate: insert into user (create_time, department, update_time, user_name, work_id) values (?, ?, ?, ?, ?)Hibernate: insert into user (create_time, department, update_time, user_name, work_id) values (?, ?, ?, ?, ?)2022-06-14 14:30:50.544  INFO 23380 --- [io-48080-exec-3] o.h.h.i.QueryTranslatorFactoryInitiator  : HHH000397: Using ASTQueryTranslatorFactory</code></pre><h2 id="了解几个”常识”概念"><a href="#了解几个”常识”概念" class="headerlink" title="了解几个”常识”概念"></a>了解几个”常识”概念</h2><p>通过前面内容的介绍以及相关示例代码的演示，可以看出SpringData JPA中有很多情况都是借助不同注解来约定一些属性或者处理逻辑策略的，且在自定义接口方法的时候，需要遵循SpringData JPA固有的一套命名规范才行。</p><p>这里对一些高频易用的注解与常见的接口方法命名规范进行梳理介绍。</p><h3 id="常用注解"><a href="#常用注解" class="headerlink" title="常用注解"></a>常用注解</h3><p><img src="https://pics.codingcoder.cn/pics/202206141751215.png"></p><p><img src="https://pics.codingcoder.cn/pics/202206141751020.png"></p><p><img src="https://pics.codingcoder.cn/pics/202206141752957.png"></p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h3 id="Repository方法命名约定"><a href="#Repository方法命名约定" class="headerlink" title="Repository方法命名约定"></a>Repository方法命名约定</h3><p>DB里面一些关键字对应的SpringData JPA中命名关键字列举如下：</p><p><img src="https://pics.codingcoder.cn/pics/202206141757397.png"></p><p><img src="https://pics.codingcoder.cn/pics/202206141758546.png"></p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h2 id="小结，承上启下"><a href="#小结，承上启下" class="headerlink" title="小结，承上启下"></a>小结，承上启下</h2><p>好啦，本篇内容就介绍到这里。</p><p>跟着本篇内容，可以让你顺利的完成SpringBoot项目与JPA的集成配置，以及对项目中如何使用JPA进行代码开发有了个整体的感知，可以应付大部分场景的基础业务代码开发诉求。</p><p>本系列教程是按照由面到点、由浅入深的逻辑进行内容编排的。在本系列的下一篇内容中，我会进一步对SpringData JPA中的一些核心类型与核心方法进行剖析，让你不仅仅停留在简单使用层面，更能对JPA有个深度的了解、达到精通级别。如果感兴趣的话，欢迎关注我的后续系列文档。</p><p>如果对本文有自己的见解，或者有任何的疑问或建议，都可以留言，我们一起探讨、共同进步。</p><hr><blockquote><p><strong>补充</strong></p><p><code>Spring Data JPA</code>作为<code>Spring Data</code>中对于关系型数据库支持的一种框架技术，属于<code>ORM</code>的一种，通过得当的使用，可以大大简化开发过程中对于数据操作的复杂度。</p><p>本文档隶属于《<code>Spring Data JPA</code>用法与技能探究》系列的第2篇。本系列文档规划对<code>Spring Data JPA</code>进行全方位的使用介绍，一共分为<strong>5篇</strong>文档，如果感兴趣，欢迎关注交流。</p><p>《Spring Data JPA用法与技能探究》系列涵盖内容：</p><ul><li>开篇介绍 —— 《<a href="https://mp.weixin.qq.com/s/qQR8z3OhwiTxybmEwMME9A">Spring Data JPA系列1：JDBC、ORM、JPA、Spring Data JPA，傻傻分不清楚？给你个选择SpringDataJPA的理由！</a>》</li><li>快速上手 —— 《<a href="https://mp.weixin.qq.com/s/aUo2HmGI0MO-Nm57TBLUgQ">Spring Data JPA系列2：SpringBoot集成JPA详细教程，快速在项目中熟练使用JPA</a>》</li><li>深度进阶 —— 《JPA核心类型与用法介绍》</li><li>可靠保障 —— 《聊一聊数据库的事务，以及Spring体系下对事务的使用》</li><li>周边扩展 —— 《JPA开发辅助效率提升方案介绍》</li></ul></blockquote><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><p><strong>我是悟道，聊技术、又不仅仅聊技术~</strong></p><p>如果觉得有用，请点个关注，也可以关注下我的公众号【架构悟道】，获取更及时的更新。</p><p>期待与你一起探讨，一起成长为更好的自己。</p><p><img src="https://pics.codingcoder.cn/pics/202207091312656.gif"></p>]]></content>
      
      
      <categories>
          
          <category> Spring Data JPA系列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SpringBoot </tag>
            
            <tag> Spring Data JPA </tag>
            
            <tag> JAVA </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spring Data JPA系列1——JDBC、ORM、JPA、Spring Data JPA，傻傻分不清楚？一文带你厘清个中曲直，给你个选择SpringDataJPA的理由！</title>
      <link href="//post/20220621125417.html"/>
      <url>//post/20220621125417.html</url>
      
        <content type="html"><![CDATA[<p><img src="https://pics.codingcoder.cn/pics/202206132103053.png"></p><p>大家好，又见面了。</p><p>本篇主要对Spring Data JPA的整体情况以及与其相关的一些概念进行一个简单的介绍。</p><p>在具体介绍Spring Data JPA之前，我们可以先来思考一个问题： 在JAVA中，如果需要操作DB，应该怎么做？</p><p>很多人可能首先想到的就是集成一些框架然后去操作就行了、比如mybatis、Hibernate框架之类的。<br>当然，也可能会有人想起JDBC。</p><p>再往深入想一下：</p><ul><li>JAVA里面的写的一段DB操作逻辑，是如何一步步被传递到DB中执行了的呢？</li><li>为什么JAVA里面可以去对接不同产商的DB产品？</li><li>为什么有JDBC、还会有各种mybatis或者诸如Hibernate等ORM框架呢？</li><li>这些JDBC、JPA、ORM、Hibernate等等相互之间啥关系？</li><li>除了MyBatis、Hibernate等习以为常的内容，是否还有其他操作DB的方案呢？</li><li>…</li></ul><p>带着这些问题，我们接下来一步步的进行探讨，先树立对Spring Data JPA的正确印象。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h2 id="需要厘清的若干概念"><a href="#需要厘清的若干概念" class="headerlink" title="需要厘清的若干概念"></a>需要厘清的若干概念</h2><h3 id="JDBC"><a href="#JDBC" class="headerlink" title="JDBC"></a>JDBC</h3><p>谈到JAVA操作数据库相关的概念，JDBC是绕不过去的一个概念。</p><p>先来介绍下JDBC究竟是个什么概念。</p><p>JDBC（Java DataBase Connectivity），是java连接数据库操作的原生接口。<br>JDBC对Java程序员而言是API，为数据库访问提供标准的接口。由各个数据库厂商及第三方中间件厂商依照JDBC规范为数据库的连接提供的标准方法。</p><p><img src="https://pics.codingcoder.cn/pics/202206131411437.png"></p><p>概念阐述的可能稍微有点抽象，说的直白点可以这么理解：各个产商的DB产品很多，JAVA联合各个DB产商定了个规范，JAVA可以按照规范去编写代码，就可以用相同的操作方法去操作不同产商的DB了。也就是说JDBC是JAVA与各个DB产商之间的一个约定规范、约束的是DB产商的实现规范。</p><p>基于JDBC，我们可以在JAVA代码中去执行DB操作，如下示意：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">package com.txw.jdbc;import java.sql.Connection;import java.sql.DriverManager;import java.sql.PreparedStatement;import java.sql.ResultSet;@SuppressWarnings(&quot;all&quot;)   &#x2F;&#x2F; 注解警告信息public class JdbcTest01 &#123;    public static void main(String[] args) throws Exception &#123;        &#x2F;&#x2F; 1.加载驱动        Class.forName(&quot;com.mysql.cj.jdbc.Driver&quot;);        &#x2F;&#x2F; 2 创建和数据库之间的连接        String username &#x3D; &quot;testdb&quot;;        String password &#x3D; &quot;testxxxxxx&quot;;        String url &#x3D; &quot;jdbc:mysql:&#x2F;&#x2F;127.0.0.1:3306&#x2F;test?useUnicode&#x3D;true&amp;characterEncoding&#x3D;UTF-8&amp;useSSL&#x3D;false&amp;serverTimezone&#x3D;Asia&#x2F;Shanghai&quot;;        Connection conn &#x3D; DriverManager.getConnection(url,username,password);        &#x2F;&#x2F; 3.准备发送SQL        String sql &#x3D; &quot;select * from t_person&quot;;        PreparedStatement pstm &#x3D; conn.prepareStatement(sql);        &#x2F;&#x2F; 4.执行SQL，接收结果集        ResultSet rs &#x3D; pstm.executeQuery();        &#x2F;&#x2F; 5 处理结果集        while(rs.next())&#123;            int personId1 &#x3D; rs.getInt(&quot;person_id&quot;);            String personName1 &#x3D; rs.getString(&quot;person_name&quot;);            int age1 &#x3D; rs.getInt(&quot;age&quot;);            String sex1 &#x3D; rs.getString(&quot;sex&quot;);            String mobile1 &#x3D; rs.getString(&quot;mobile&quot;);            String address1 &#x3D; rs.getString(&quot;address&quot;);            System.out.println(&quot;personId&#x3D;&quot;+personId1+&quot;,personName&#x3D;&quot;+personName1                    +&quot;,age&#x3D;&quot;+age1+&quot;,sex&#x3D;&quot;+sex1+&quot;,mobile&#x3D;&quot;+mobile1+&quot;,address&#x3D;&quot;+address1);        &#125;        &#x2F;&#x2F; 6.释放资源        rs.close();        pstm.close();        conn.close();    &#125;&#125;</code></pre><p>从上面代码示例中可以看出JDBC的几个操作关键环节：</p><ol><li>根据使用的DB类型不同，加载对应的JdbcDriver</li><li>连接DB</li><li>编写SQL语句</li><li>发送到DB中执行，并接收结果返回</li><li>对结果进行处理解析</li><li>释放过程中的连接资源</li></ol><p>从演示代码里面，还可以看出，直接基于JDBC进行操作DB的时候，其弊端还是比较明显的：</p><ol><li>业务代码里面耦合了字符串格式SQL语句，复杂场景维护起来比较麻烦；</li><li>非结构化的key-value映射方式处理结果，操作过于复杂，且不符合JAVA面向对象的思想；</li><li>需要关注过程资源的释放、操作不当容易造成泄露。</li></ol><p>也正是由于JDBC上述比较明显的弊端，纯基于JDBC操作DB一般仅用于一些小型简单的场景，正式大型项目中，往往很少有直接基于JDBC进行编码开发的，而是借助一些封装框架来实现。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h3 id="ORM框架"><a href="#ORM框架" class="headerlink" title="ORM框架"></a>ORM框架</h3><p>对象-关系映射（Object-Relational Mapping，简称ORM）。ORM框架中贯穿着JAVA面向对象编程的思想，是面向对象编程的优秀代言人。</p><p>直白点说，ORM就是将代码里面的JAVA类与DB中的table表进行映射，代码中对相关JAVA类的操作，即体现为DB中对相关Table的操作。</p><p>ORM框架很好的解决了JDBC存在的一系列问题，简化了JAVA开发人员的编码复杂度。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h3 id="JPA介绍"><a href="#JPA介绍" class="headerlink" title="JPA介绍"></a>JPA介绍</h3><p><code>JPA</code>， 即 <code>Java Persistence API</code>的缩写，也即 <code>JAVA</code>持久化层API，这个并非是一个新的概念，其实在JDK5.x版本中就已经引入的一个概念。其宗旨是为 <code>POJO</code>提供一个基于 <code>ORM</code>的持久化操作的标准规范。</p><p>涵盖几个方面：</p><ul><li><strong>一套标准API</strong><br>在javax.persistence的包下面提供，用来操作实体对象，执行CRUD操作，将开发者从烦琐的JDBC和SQL代码中解脱出来，按照JAVA思路去编写代码操作DB。</li><li><strong>面向对象操作语言</strong><br>通过面向对象的思路，避免代码与SQL的深度耦合。</li><li><strong>ORM元数据映射</strong><br>ORM，即Object Relation Mapping，对象关系映射。</li></ul><p>JAVA应用程序，可以通过JPA规范，利用一些常见的基于JPA规范的框架来实现对DB的操作。而常见的一些ORM框架，比如 <code>Hibernate</code>、<code>EclipseLink</code>、<code>OpenJPA</code>等等，其实都是提供了对JPA规范的支持，是JPA规范的具体实现提供者，用于辅助JAVA程序对数据库数据的操作。</p><p><img src="https://pics.codingcoder.cn/pics/202206131358853.png"></p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h3 id="Spring-Data-JPA"><a href="#Spring-Data-JPA" class="headerlink" title="Spring Data JPA"></a>Spring Data JPA</h3><p>基于前面介绍，我们了解到JPA的基本概念，知晓JPA其实是一个基于ORM的JAVA API规范定义，那么这里提及的 <code>Spring Data JPA</code>又是什么呢？其与 <code>JPA</code>之间的关系又是如何呢？</p><p><code>Spirng Data JPA</code>是 <code>Spring</code>提供的一套简化 <code>JPA</code>开发的框架，按照约定好的【方法命名规则】写 <code>DAO</code>层接口，就可以在不写接口实现的情况下，实现对数据库的访问和操作，同时提供了很多除了CRUD之外的功能，如分页、排序、复杂查询等等。</p><p><img src="https://pics.codingcoder.cn/pics/202206131843635.png"></p><p><strong>注意</strong><br>Spring Data JPA不是一个完整JPA规范的实现，它只是一个代码抽象层，主要用于减少为各种持久层存储实现数据访问层所需的代码量。其底层依旧是 <code>Hibernate</code>。</p><p>可以把 <code>Spring Data JPA</code>理解为 <code>JPA</code>规范的再次封装抽象。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h3 id="Hibernate"><a href="#Hibernate" class="headerlink" title="Hibernate"></a>Hibernate</h3><p>hibernate是一个标准的orm框架，实现jpa接口。</p><h3 id="JDBC，ORM，JPA，Spring-Data-JPA之间到底啥关系"><a href="#JDBC，ORM，JPA，Spring-Data-JPA之间到底啥关系" class="headerlink" title="JDBC，ORM，JPA，Spring Data JPA之间到底啥关系"></a>JDBC，ORM，JPA，Spring Data JPA之间到底啥关系</h3><p>一个简单粗暴的理解方式：</p><ol><li>JDBC是JAVA操作最终数据库的底层接口，JDBC是与各个DB产商之间约定的协议规范，基于这些规范，可在JAVA代码中往DB执行SQL操作。</li><li>因为JDBC负责将SQL语句执行到DB中，属于相对原始的接口，业务代码里面需要构建拼接出SQL语句，然后基于JDBC去DB中执行对应SQL语句。这样存在的问题会比较明显，JAVA代码中需要耦合大量的SQL语句、且因为缺少封装，实际业务编码使用时会比较繁琐、维护复杂。</li><li>为了能够将代码与SQL语句分离开，以一种更符合JAVA面向对象编程思维的方式来操作DB，诞生了ORM（Object Relation Mapping， 对象关系映射）概念，ORM将JAVA的Object与DB中的Table进行映射起来，管理Object也等同于对Table的管理与操作，这样就可以实现没有SQL的情况下实现对DB的操作。常见的ORM框架有 <code>Hibernate</code>、<code>EclipseLink</code>、<code>OpenJPA</code>等等。</li><li>为了规范ORM的具体使用，JAVA 5.x开始制定了基于ORM思想的Java持久化层操作API规范，也即JPA（注意，JPA只是一个基于ORM的JAVA API规范，供各个ORM框架提供API时遵循），当前主流ORM框架都是支持JPA规范的。</li><li>Spring框架盛行的时代，为了能够更好适配，Spring Data JPA诞生， 这个可以理解为对JPA规范的二次封装（可以这么理解：Spring Data JPA不是一个完整JPA规范的实现，它只是一个代码抽象层，主要用于减少为各种持久层存储实现数据访问层所需的代码量），其底层使用的依旧是常规ORM框架（Hibernate）。</li></ol><p>相互之间的关系详解，见下图示意。</p><p><img src="https://pics.codingcoder.cn/pics/202206131451061.png"></p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h2 id="选择Spring-Data-JPA的理由"><a href="#选择Spring-Data-JPA的理由" class="headerlink" title="选择Spring Data JPA的理由"></a>选择Spring Data JPA的理由</h2><h3 id="Spring-Data-JPA的优势"><a href="#Spring-Data-JPA的优势" class="headerlink" title="Spring Data JPA的优势"></a>Spring Data JPA的优势</h3><p>在介绍Spring Data JPA的优势前，先看个代码例子。</p><p>场景：<br>一张用户表（UserEntity），信息如下：</p><table><thead><tr><th>ID</th><th>UserName</th><th>Department</th><th>Role</th></tr></thead><tbody><tr><td>1</td><td>Jack</td><td>DevDept</td><td>Normal</td></tr><tr><td>2</td><td>Tom</td><td>DevDept</td><td>Admin</td></tr><tr><td>3</td><td>Tony</td><td>SaleDept</td><td>Normal</td></tr></tbody></table><p>代码中实现如下诉求：<br>（1）获取所有研发部门的人员：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">List&lt;UserEntity&gt; users &#x3D; userReposity.findAllByDepartment(&quot;DevDept&quot;);</code></pre><p>（2）获取研发部门的管理员：</p><pre class="line-numbers language-java" data-language="java"><code class="language-java">List&lt;UserEntity&gt; users &#x3D; userReposity.findAllByDepartmentAndRole(&quot;DevDept&quot;, &quot;Admin&quot;);</code></pre><p>看完上面的例子，一个最直观的感受是什么？<br>简单！</p><p>没错，“简单”就是Spring Data JPA最大的优势！</p><p>对于大部分的常规操作，基于Spring Data JPA，开发人员可以更加专注于业务逻辑的开发，而不用花费太多的精力去关注DB层面的封装处理以及SQL的编写维护，甚至在DAO层都不需要去定义接口。</p><p>除了简化开发，JPA还有的另一个比较大的优势，就是其可移植性比较好，因为其通过JPQL的方式进行操作，与原生SQL之间几乎没有耦合，所以可以方便的将底层DB切换到别的类型。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h3 id="Spring-Data-JPA整体实现逻辑"><a href="#Spring-Data-JPA整体实现逻辑" class="headerlink" title="Spring Data JPA整体实现逻辑"></a>Spring Data JPA整体实现逻辑</h3><p>基于前面的介绍，我们可以这样理解，JAVA业务层调用SpringData JPA二次封装提供的Repository层接口，进而基于JPA标准API进行处理，基于Hibernate提供的JPA具体实现，接着基于JDBC标准API接口，完成与实际DB之间的请求交互。整体的处理逻辑全貌图如下：</p><p><img src="https://pics.codingcoder.cn/pics/202206132123401.png"></p><p>这里可以看出，JPA、Hibernate、SpringData JPA三者之间的关系：</p><ul><li>JPA（Java Persistence API）是规范，它指明了持久化、读取和管理 Java 对象映射到数据库表时的规范。</li><li>Hibernate 则是一个 ORM 框架，它实现了 Java 对象到数据库表的映射。也就是说，Hibernate 提供了 JPA 的一种实现。</li><li>Spring Data JPA 是 Spring Framework 的一部分。它不是 JPA 的实现，而是在 JPA 之上提供更高层次的抽象，可以减少很多模板代码。而 Spring Data JAP 的默认实现是 Hibernate，当然也可以其他的 JPA Provider。</li></ul><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h3 id="Spring-Data-JPA还是MyBatis？如何抉择"><a href="#Spring-Data-JPA还是MyBatis？如何抉择" class="headerlink" title="Spring Data JPA还是MyBatis？如何抉择"></a>Spring Data JPA还是MyBatis？如何抉择</h3><p>提到JPA， 那么MyBatis绝对是无法回避的一个内容。的确，作为JAVA持久化层的优秀框架，MyBatis甚至是很多开发人员在项目构建初期脑海中唯一的选型方案。那么，JPA想要从MyBatis占领地中分一杯羹，究竟是具有哪方面的优势呢？</p><p>先来了解下MyBatis。<br>MyBatis是一款优秀的持久层框架，它支持定制化SQL、存储过程以及高级映射。MyBatis 避免了几乎全部的JDBC代码和手动设置参数以及获取结果集。MyBatis可使用简单的XML或注解来配置和映射原生信息，将接口和Java的POJOs(Plain Old Java Objects,普通的 Java对象)映射成数据库中的记录。<br>优势：</p><ul><li>MyBatis则是一个可以灵活编写sql语句</li><li>MyBatis避免了几乎全部的JDBC代码和手动设置参数以及获取结果集，相比JDBC更方便</li></ul><p>MyBatis与JPA的差异点：</p><ul><li>设计哲学不同，MyBatis偏向于面向过程，JPA则将面向对象发挥到极致；</li><li>MyBatis定制起来更加灵活，支持高度定制化的sql语句，支持任意编写sql语句；JPA相对更注重对已有高频简单操作场景的封装，简化开发人员的重复操作，虽然JPA也支持定制SQL语句，但是相比MyBatis灵活度略差。</li></ul><p>至此，到底如何在JPA与MyBatis之间抉择，就比较清晰了：</p><ul><li>如果你的系统中对DB的操作没有太多额外的深度定制、对DB的执行性能也不是极度敏感、不需要基于SQL语句做一些深度的优化，大部分场景都是一些基础CRUD操作，则无疑Spring Data JPA是比较理想的选择，它将大大降低开发人员在DB操作层面的投入精力。</li><li>如果你的业务中对DB高阶逻辑依赖太深，比如大部分场景都需要额外定制复杂SQL语句来实现，或者系统对性能及其敏感，需要基于Table甚至column维度进行深度优化，或者数据量特别巨大的场景，则相比较而言，MyBatis提供的调优定制灵活性上要更有优势一些。</li></ul><p>综上分析，其实MyBatis与Spring Data JPA其实没有一个绝对的维度来评价谁更优一些，具体需要结合自身的实际诉求来选择。</p><p>再看个有意思的数据，此前有人统计过使用百度、谷歌等搜素引擎搜素JPA与Mybatis关键字的搜索热度与区域的数据，如下所示：</p><p><img src="https://pics.codingcoder.cn/pics/202206131831564.png"></p><p>从图中可以看出，MyBatis在中国地区相对更受欢迎一些，但是在国外JPA的受欢迎度要更高一些。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><h2 id="小结，承上启下"><a href="#小结，承上启下" class="headerlink" title="小结，承上启下"></a>小结，承上启下</h2><p>好啦，本篇内容就介绍到这里。</p><p>通过本篇内容，对JAVA体系中DB操作相关的组件、规范等有了一定初步的了解，也大致了解了应该如何选择是使用JPA还是MyBatis选型。</p><p>后续几篇系列文章中，将会一步步的介绍下Spring Data JPA的核心内容与具体项目实现，一步步的揭开JPA的庐山真面目。</p><p>如果通过本文介绍，你对JPA也有进一步了解的兴趣，欢迎关注我的后续系列文档。<br>如果对本文有自己的见解，或者有任何的疑问或建议，都可以留言，我们一起探讨、共同进步。</p><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><blockquote><p><strong>补充</strong></p><p><code>Spring Data JPA</code>作为 <code>Spring Data</code>中对于关系型数据库支持的一种框架技术，属于 <code>ORM</code>的一种，通过得当的使用，可以大大简化开发过程中对于数据操作的复杂度。</p><p>本文档隶属于《<code>Spring Data JPA</code>用法与技能探究》系列的第1篇。本系列文档规划对 <code>Spring Data JPA</code>进行全方位的使用介绍，一共分为<strong>5篇</strong>文档，如果感兴趣，欢迎关注交流。</p><p>《Spring Data JPA用法与技能探究》系列涵盖内容：</p><ul><li>开篇介绍 —— 《<a href="https://mp.weixin.qq.com/s/qQR8z3OhwiTxybmEwMME9A">Spring Data JPA系列1：JDBC、ORM、JPA、Spring Data JPA，傻傻分不清楚？给你个选择SpringDataJPA的理由！</a>》</li><li>快速上手 —— 《<a href="https://mp.weixin.qq.com/s/aUo2HmGI0MO-Nm57TBLUgQ">Spring Data JPA系列2：SpringBoot集成JPA详细教程，快速在项目中熟练使用JPA</a>》</li><li>深度进阶 —— 《JPA核心类型与用法介绍》</li><li>可靠保障 —— 《聊一聊数据库的事务，以及Spring体系下对事务的使用》</li><li>周边扩展 —— 《JPA开发辅助效率提升方案介绍》</li></ul></blockquote><p><img src="https://pics.codingcoder.cn/pics/202207102124124.gif"></p><p><strong>我是悟道，聊技术、又不仅仅聊技术~</strong></p><p>如果觉得有用，请点个关注，也可以关注下我的公众号【架构悟道】，获取更及时的更新。</p><p>期待与你一起探讨，一起成长为更好的自己。</p><p><img src="https://pics.codingcoder.cn/pics/202207091312656.gif"></p>]]></content>
      
      
      <categories>
          
          <category> Spring Data JPA系列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SpringBoot </tag>
            
            <tag> Spring Data JPA </tag>
            
            <tag> JAVA </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
